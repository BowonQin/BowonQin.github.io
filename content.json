{"meta":{"title":"Bowon Qin","subtitle":"Bowon Qin 的Blog","description":"java后端相关技术栈","author":"Bowon Qin","url":"https://bowonqin.github.io","root":"/"},"pages":[{"title":"404","date":"2019-08-10T08:41:10.000Z","updated":"2021-12-16T06:00:51.035Z","comments":true,"path":"404.html","permalink":"https://bowonqin.github.io/404.html","excerpt":"","text":""},{"title":"archives","date":"2019-10-24T16:00:00.000Z","updated":"2021-12-16T06:00:51.251Z","comments":true,"path":"archives/index.html","permalink":"https://bowonqin.github.io/archives/index.html","excerpt":"","text":""},{"title":"about","date":"2019-10-24T16:00:00.000Z","updated":"2021-12-16T06:00:51.250Z","comments":true,"path":"about/index.html","permalink":"https://bowonqin.github.io/about/index.html","excerpt":"","text":""},{"title":"categories","date":"2021-10-24T16:00:00.000Z","updated":"2021-12-16T11:07:27.488Z","comments":true,"path":"categories/index.html","permalink":"https://bowonqin.github.io/categories/index.html","excerpt":"","text":""},{"title":"资源分享","date":"2019-07-19T08:40:27.000Z","updated":"2021-12-16T06:00:51.257Z","comments":true,"path":"resource/index.html","permalink":"https://bowonqin.github.io/resource/index.html","excerpt":"","text":""},{"title":"友链","date":"2019-07-19T08:42:10.000Z","updated":"2021-12-16T06:00:51.255Z","comments":true,"path":"friends/index.html","permalink":"https://bowonqin.github.io/friends/index.html","excerpt":"","text":""},{"title":"tags","date":"2019-07-19T08:40:27.000Z","updated":"2021-12-16T06:00:51.257Z","comments":true,"path":"tags/index.html","permalink":"https://bowonqin.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"SpringCloud-消息中间件(RabbitMQ)","slug":"微服务/SpringCloud-消息中间件","date":"2022-04-15T13:27:15.000Z","updated":"2022-04-15T13:45:09.254Z","comments":true,"path":"posts/springcloud-xiao-xi-zhong-jian-jian-rabbitmq.html","link":"","permalink":"https://bowonqin.github.io/posts/springcloud-xiao-xi-zhong-jian-jian-rabbitmq.html","excerpt":"","text":"本文为b站黑马程序员SpringCloud的学习笔记，网址为:SpringCloud SpringCloud-消息中间件(RabbitMQ)1.初识MQ1.1 同步和异步通讯微服务间通讯有同步和异步两种方式： 同步通讯：就像打电话，需要实时响应。 异步通讯：就像发邮件，不需要马上回复。 两种方式各有优劣，打电话可以立即得到响应，但是你却不能跟多个人同时通话。发送邮件可以同时与多个人收发邮件，但是往往响应会有延迟。 1.1.1 同步通讯Feign调用就属于同步方式，虽然调用可以实时得到结果，但存在下面的问题： 总结： 同步调用的优点： 时效性较强，可以立即得到结果 同步调用的问题： 耦合度高 性能和吞吐能力下降 有额外的资源消耗 有级联失败问题 1.1.2 异步通讯异步调用则可以避免上述问题： 我们以购买商品为例，用户支付后需要调用订单服务完成订单状态修改，调用物流服务，从仓库分配响应的库存并准备发货。 在事件模式中，支付服务是事件发布者（publisher），在支付完成后只需要发布一个支付成功的事件（event），事件中带上订单id。 订单服务和物流服务是事件订阅者（Consumer），订阅支付成功的事件，监听到事件后完成自己业务即可。 为了解除事件发布者与订阅者之间的耦合，两者并不是直接通信，而是有一个中间人（Broker）。发布者发布事件到Broker，不关心谁来订阅事件。订阅者从Broker订阅事件，不关心谁发来的消息。 Broker 是一个像数据总线一样的东西，所有的服务要接收数据和发送数据都发到这个总线上，这个总线就像协议一样，让服务间的通讯变得标准和可控。 好处： 吞吐量提升：无需等待订阅者处理完成，响应更快速 故障隔离：服务没有直接调用，不存在级联失败问题 调用间没有阻塞，不会造成无效的资源占用 耦合度极低，每个服务都可以灵活插拔，可替换 流量削峰：不管发布事件的流量波动多大，都由Broker接收，订阅者可以按照自己的速度去处理事件 缺点： 架构复杂了，业务没有明显的流程线，不好管理 需要依赖于Broker的可靠、安全、性能 好在现在开源软件或云平台上 Broker 的软件是非常成熟的，比较常见的一种就是我们今天要学习的MQ技术。 1.2 技术对比MQ，中文是消息队列（MessageQueue），字面来看就是存放消息的队列。也就是事件驱动架构中的Broker。 比较常见的MQ实现： ActiveMQ RabbitMQ RocketMQ Kafka 几种常见MQ的对比： RabbitMQ ActiveMQ RocketMQ Kafka 公司/社区 Rabbit Apache 阿里 Apache 开发语言 Erlang Java Java Scala&amp;Java 协议支持 AMQP，XMPP，SMTP，STOMP OpenWire,STOMP，REST,XMPP,AMQP 自定义协议 自定义协议 可用性 高 一般 高 高 单机吞吐量 一般 差 高 非常高 消息延迟 微秒级 毫秒级 毫秒级 毫秒以内 消息可靠性 高 一般 高 一般 追求可用性：Kafka、 RocketMQ 、RabbitMQ 追求可靠性：RabbitMQ、RocketMQ 追求吞吐能力：RocketMQ、Kafka 追求消息低延迟：RabbitMQ、Kafka 2. 快速入门2.1 安装RabbitMQ2.1.1 单机部署我们在Centos7虚拟机中使用Docker来安装。 方式一：在线拉取 docker pull rabbitmq:3-management 方式二： 从本地加载 将mq.tar包上传到虚拟机中后，使用命令加载镜像即可： docker load -i mq.tar 安装MQ 执行下面的命令来运行MQ容器： docker run \\ -e RABBITMQ_DEFAULT_USER=itcast \\ -e RABBITMQ_DEFAULT_PASS=123321 \\ --name mq \\ --hostname mq1 \\ -p 15672:15672 \\ -p 5672:5672 \\ -d \\ rabbitmq:3-management 2.1.2 集群部署在RabbitMQ的官方文档中，讲述了两种集群的配置方式： 普通模式：普通模式集群不进行数据同步，每个MQ都有自己的队列、数据信息（其它元数据信息如交换机等会同步）。例如我们有2个MQ：mq1，和mq2，如果你的消息在mq1，而你连接到了mq2，那么mq2会去mq1拉取消息，然后返回给你。如果mq1宕机，消息就会丢失。 镜像模式：与普通模式不同，队列会在各个mq的镜像节点之间同步，因此你连接到任何一个镜像节点，均可获取到消息。而且如果一个节点宕机，并不会导致数据丢失。不过，这种方式增加了数据同步的带宽消耗。","categories":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://bowonqin.github.io/categories/SpringCloud/"},{"name":"消息中间件","slug":"SpringCloud/消息中间件","permalink":"https://bowonqin.github.io/categories/SpringCloud/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/"}],"tags":[{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"https://bowonqin.github.io/tags/RabbitMQ/"}],"author":"qxd"},{"title":"SpringCloud-网关","slug":"微服务/SpringCloud-网关","date":"2022-04-15T08:52:15.000Z","updated":"2022-04-15T13:36:40.949Z","comments":true,"path":"posts/springcloud-wang-guan.html","link":"","permalink":"https://bowonqin.github.io/posts/springcloud-wang-guan.html","excerpt":"","text":"本文为b站黑马程序员SpringCloud的学习笔记，网址为:SpringCloud SpringCloud-Gateway服务网关Spring Cloud Gateway 是 Spring Cloud 的一个全新项目，该项目是基于 Spring 5.0，Spring Boot 2.0 和 Project Reactor 等响应式编程和事件流技术开发的网关，它旨在为微服务架构提供一种简单有效的统一的 API 路由管理方式。 1.1 为什么需要网关Gateway网关是我们服务的守门神，所有微服务的统一入口。 网关的核心功能特性： 请求路由 权限控制 限流 架构图： 引入依赖： &lt;!--网关--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-gateway&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--nacos服务发现依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;/dependency&gt; 2）编写启动类package cn.itcast.gateway; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; @SpringBootApplication public class GatewayApplication { public static void main(String[] args) { SpringApplication.run(GatewayApplication.class, args); } } 3）编写基础配置和路由规则创建application.yml文件，内容如下： server: port: 10010 # 网关端口 spring: application: name: gateway # 服务名称 cloud: nacos: server-addr: localhost:8848 # nacos地址 gateway: routes: # 网关路由配置 - id: user-service # 路由id，自定义，只要唯一即可 # uri: http://127.0.0.1:8081 # 路由的目标地址 http就是固定地址 uri: lb://userservice # 路由的目标地址 lb就是负载均衡，后面跟服务名称 predicates: # 路由断言，也就是判断请求是否符合路由规则的条件 - Path=/user/** # 这个是按照路径匹配，只要以/user/开头就符合要求 我们将符合Path 规则的一切请求，都代理到 uri参数指定的地址。 本例中，我们将 /user/**开头的请求，代理到lb://userservice，lb是负载均衡，根据服务名拉取服务列表，实现负载均衡。 4）重启测试重启网关，访问http://localhost:10010/user/1时，符合`/user/**`规则，请求转发到uri：http://userservice/user/1，得到了结果： 5）网关路由的流程图整个访问的流程如下： 总结： 网关搭建步骤： 创建项目，引入nacos服务发现和gateway依赖 配置application.yml，包括服务基本信息、nacos地址、路由 路由配置包括： 路由id：路由的唯一标示 路由目标（uri）：路由的目标地址，http代表固定地址，lb代表根据服务名负载均衡 路由断言（predicates）：判断路由的规则， 路由过滤器（filters）：对请求或响应做处理 接下来，就重点来学习路由断言和路由过滤器的详细知识 1.3 断言工厂我们在配置文件中写的断言规则只是字符串，这些字符串会被Predicate Factory读取并处理，转变为路由判断的条件 例如Path=/user/**是按照路径匹配，这个规则是由 org.springframework.cloud.gateway.handler.predicate.PathRoutePredicateFactory类来 处理的，像这样的断言工厂在SpringCloudGateway还有十几个: 名称 说明 示例 After 是某个时间点后的请求 - After=2037-01-20T17:42:47.789-07:00[America/Denver] Before 是某个时间点之前的请求 - Before=2031-04-13T15:14:47.433+08:00[Asia/Shanghai] Between 是某两个时间点之前的请求 - Between=2037-01-20T17:42:47.789-07:00[America/Denver], 2037-01-21T17:42:47.789-07:00[America/Denver] Cookie 请求必须包含某些cookie - Cookie=chocolate, ch.p Header 请求必须包含某些header - Header=X-Request-Id, \\d+ Host 请求必须是访问某个host（域名） - Host=.somehost.org,.anotherhost.org Method 请求方式必须是指定方式 - Method=GET,POST Path 请求路径必须符合指定规则 - Path=/red/{segment},/blue/** Query 请求参数必须包含指定参数 - Query=name, Jack或者- Query=name RemoteAddr 请求者的ip必须是指定范围 - RemoteAddr=192.168.1.1/24 Weight 权重处理 我们只需要掌握Path这种路由工程就可以了。 1.4 过滤器工厂GatewayFilter是网关中提供的一种过滤器，可以对进入网关的请求和微服务返回的响应做处理： 1.4.1 路由过滤器的种类Spring提供了31种不同的路由过滤器工厂。例如： 名称 说明 AddRequestHeader 给当前请求添加一个请求头 RemoveRequestHeader 移除请求中的一个请求头 AddResponseHeader 给响应结果中添加一个响应头 RemoveResponseHeader 从响应结果中移除有一个响应头 RequestRateLimiter 限制请求的流量 1.4.2 请求头过滤器下面我们以AddRequestHeader 为例来讲解。 需求：给所有进入userservice的请求添加一个请求头：Truth=itcast is freaking awesome! 只需要修改gateway服务的application.yml文件，添加路由过滤即可： spring: cloud: gateway: routes: - id: user-service uri: lb://userservice predicates: - Path=/user/** filters: # 过滤器 - AddRequestHeader=Truth, Itcast is freaking awesome! # 添加请求头 1.4.3.默认过滤器如果要对所有的路由都生效，则可以将过滤器工厂写到default下。格式如下： spring: cloud: gateway: routes: - id: user-service uri: lb://userservice predicates: - Path=/user/** default-filters: # 默认过滤项 - AddRequestHeader=Truth, Itcast is freaking awesome! 1.4.4.总结过滤器的作用是什么？ ① 对路由的请求或响应做加工处理，比如添加请求头 ② 配置在路由下的过滤器只对当前路由的请求生效 defaultFilters的作用是什么？ ① 对所有路由都生效的过滤器 1.5 全局过滤器学习的过滤器，网关提供了31种，但每一种过滤器的作用都是固定的。如果我们希望拦截请求，做自己的业务逻辑则没办法实现。 1.5.1 全局过滤器作用全局过滤器的作用也是处理一切进入网关的请求和微服务响应，与GatewayFilter的作用一样。区别在于GatewayFilter通过配置定义，处理逻辑是固定的；而GlobalFilter的逻辑需要自己写代码实现。 定义方式是实现GlobalFilter接口。 public interface GlobalFilter { /** * 处理当前请求，有必要的话通过{@link GatewayFilterChain}将请求交给下一个过滤器处理 * * @param exchange 请求上下文，里面可以获取Request、Response等信息 * @param chain 用来把请求委托给下一个过滤器 * @return {@code Mono&lt;Void&gt;} 返回标示当前过滤器业务结束 */ Mono&lt;Void&gt; filter(ServerWebExchange exchange, GatewayFilterChain chain); } 在filter中编写自定义逻辑，可以实现下列功能： 登录状态判断 权限校验 请求限流等 1.5.2 自定义全局过滤器需求：定义全局过滤器，拦截请求，判断请求的参数是否满足下面条件： 参数中是否有authorization， authorization参数值是否为admin 如果同时满足则放行，否则拦截 实现： 在gateway中定义一个过滤器： package cn.itcast.gateway.filters; import org.springframework.cloud.gateway.filter.GatewayFilterChain; import org.springframework.cloud.gateway.filter.GlobalFilter; import org.springframework.core.annotation.Order; import org.springframework.http.HttpStatus; import org.springframework.stereotype.Component; import org.springframework.web.server.ServerWebExchange; import reactor.core.publisher.Mono; @Order(-1) @Component public class AuthorizeFilter implements GlobalFilter { @Override public Mono&lt;Void&gt; filter(ServerWebExchange exchange, GatewayFilterChain chain) { // 1.获取请求参数 MultiValueMap&lt;String, String&gt; params = exchange.getRequest().getQueryParams(); // 2.获取authorization参数 String auth = params.getFirst(\"authorization\"); // 3.校验 if (\"admin\".equals(auth)) { // 放行 return chain.filter(exchange); } // 4.拦截 // 4.1.禁止访问，设置状态码 exchange.getResponse().setStatusCode(HttpStatus.FORBIDDEN); // 4.2.结束处理 return exchange.getResponse().setComplete(); } } 1.5.3.过滤器执行顺序请求进入网关会碰到三类过滤器：当前路由的过滤器、DefaultFilter、GlobalFilter 请求路由后，会将当前路由过滤器和DefaultFilter、GlobalFilter，合并到一个过滤器链（集合）中，排序后依次执行每个过滤器：","categories":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://bowonqin.github.io/categories/SpringCloud/"}],"tags":[{"name":"网关","slug":"网关","permalink":"https://bowonqin.github.io/tags/%E7%BD%91%E5%85%B3/"}],"author":"qxd"},{"title":"如何判断线程安全","slug":"多线程/如何判断线程安全","date":"2022-04-15T01:19:49.000Z","updated":"2022-04-15T02:27:30.085Z","comments":true,"path":"posts/xian-cheng-an-quan.html","link":"","permalink":"https://bowonqin.github.io/posts/xian-cheng-an-quan.html","excerpt":"","text":"如何判断书写的代码是否线程安全1. 变量的线程安全分析1.1 成员变量和静态变量是否线程安全 如果它们没有共享，则线程安全 如果它们被共享了，根据它们的状态是否能够改变，又分两种情况 如果只有读操作，则线程安全 如果有读写操作，则这段代码是临界区，需要考虑线程安全 1.2 局部变量是否线程安全 局部变量是线程安全的 但局部变量引用的对象则未必 如果该对象没有逃离方法的作用访问，它是线程安全的 如果该对象逃离方法的作用范围，需要考虑线程安全 总结下来就是： 共享+读写+多线程 1.3 局部变量的线程安全分析public static void test1() { int i = 10; i++; } 每个线程调用 test1() 方法时局部变量 i，会在每个线程的栈帧内存中被创建多份，因此不存在共享 局部变量的引用稍有不同 先看一个成员变量的例子 class ThreadUnsafe { ArrayList&lt;String&gt; list = new ArrayList&lt;&gt;(); public void method1(int loopNumber) { for (int i = 0; i &lt; loopNumber; i++) { // { 临界区, 会产生竞态条件 method2(); method3(); // } 临界区 } } private void method2() { list.add(\"1\"); } private void method3() { list.remove(0); } } 执行 public class TestThreadSafe { static final int THREAD_NUMBER = 2; static final int LOOP_NUMBER = 200; public static void main(String[] args) { ThreadUnsafe test = new ThreadUnsafe(); for (int i = 0; i &lt; THREAD_NUMBER; i++) { new Thread(() -&gt; { test.method1(LOOP_NUMBER); }, \"Thread\" + (i+1)).start(); } } } 其中一种情况是，如果线程2 还未 add，线程1 remove 就会报错： Exception in thread \"Thread1\" java.lang.IndexOutOfBoundsException: Index: 0, Size: 0 at java.util.ArrayList.rangeCheck(ArrayList.java:653) at java.util.ArrayList.remove(ArrayList.java:492) at cn.itcast.n4.ThreadUnsafe.method3(TestThreadSafe.java:33) at cn.itcast.n4.ThreadUnsafe.method1(TestThreadSafe.java:24) at cn.itcast.n4.TestThreadSafe.lambda$main$0(TestThreadSafe.java:14) at java.lang.Thread.run(Thread.java:748) 分析： 无论哪个线程中的 method2 引用的都是同一个对象中的 list 成员变量 method3 与 method2 分析相同 将 list 修改为局部变量 class ThreadSafe { public final void method1(int loopNumber) { ArrayList&lt;String&gt; list = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; loopNumber; i++) { method2(list); method3(list); } } public void method2(ArrayList&lt;String&gt; list) { list.add(\"1\"); } private void method3(ArrayList&lt;String&gt; list) { System.out.println(1); list.remove(0); } 那么就不会有上述问题了 分析： list 是局部变量，每个线程调用时会创建其不同实例，没有共享 而 method2 的参数是从 method1 中传递过来的，与 method1 中引用同一个对象 method3 的参数分析与 method2 相同 方法访问修饰符带来的思考，如果把 method2 和 method3 的方法修改为 public 会不会代理线程安全问题？ 情况1：有其它线程调用 method2 和 method3 情况2：在 情况1 的基础上，为 ThreadSafe 类添加子类，子类覆盖 method2 或 method3 方法，即 class ThreadSafeSubClass extends ThreadSafe{ @Override public void method3(ArrayList&lt;String&gt; list) { System.out.println(2); new Thread(() -&gt; { list.remove(0); }).start(); } } 结果可能出现 Exception in thread \"Thread-389\" java.lang.IndexOutOfBoundsException: Index: 0, Size: 0 at java.util.ArrayList.rangeCheck(ArrayList.java:653) at java.util.ArrayList.remove(ArrayList.java:492) at cn.itcast.n4.ThreadSafeSubClass.lambda$method3$0(TestThreadSafe.java:62) at java.lang.Thread.run(Thread.java:748) 从这个例子可以看出 private 或 fifinal 提供【安全】的意义所在，请体会开闭原则中的【闭】 2. 常见线程安全类2.1 线程安全类 String Integer StringBuffer Random Vector HashTable java.util.concurrent 包下的类 这里说它们是线程安全的是指，多个线程调用它们同一个实例的某个方法时，是线程安全的。也可以理解为 Hashtable table = new Hashtable(); new Thread(()-&gt;{ table.put(\"key\", \"value1\"); }).start(); new Thread(()-&gt;{ table.put(\"key\", \"value2\"); }).start(); 它们的每个方法是原子的 但注意它们多个方法的组合不是原子的，见后面分析 3. 案例分析例1： public class MyServlet extends HttpServlet { // 是否安全？ // 不是线程安全的 Map&lt;String,Object&gt; map = new HashMap&lt;&gt;(); // 是否安全？ // 是的 String S1 = \"...\"; // 是否安全？ // 是的 final String S2 = \"...\"; // 是否安全？ // 不是 Date D1 = new Date(); // 是否安全？ // 不是线程安全的，final只能保证引用不可变，不能保证Date()里面的属性不能变 final Date D2 = new Date(); public void doGet(HttpServletRequest request, HttpServletResponse response) { // 使用上述变量 } } 例2：不是线程安全的，存在多线程共享使用的问题 public class MyServlet extends HttpServlet { // 是否安全？ private UserService userService = new UserServiceImpl(); public void doGet(HttpServletRequest request, HttpServletResponse response) { userService.update(...); } } public class UserServiceImpl implements UserService { // 记录调用次数 private int count = 0; public void update() { // ... count++; } } 例3： 不是线程安全的 改进方法： 使用环绕通知解决，把成员变量变成局部变量 @Aspect @Component public class MyAspect { // 是否安全？ private long start = 0L; @Before(\"execution(* *(..))\") public void before() { start = System.nanoTime(); } @After(\"execution(* *(..))\") public void after() { long end = System.nanoTime(); System.out.println(\"cost time:\" + (end-start)); } } 例4： 线程安全的 public class MyServlet extends HttpServlet { // 是否安全 private UserService userService = new UserServiceImpl(); public void doGet(HttpServletRequest request, HttpServletResponse response) { userService.update(...); } } public class UserServiceImpl implements UserService { // 是否安全 private UserDao userDao = new UserDaoImpl(); public void update() { userDao.update(); } } public class UserDaoImpl implements UserDao { public void update() { String sql = \"update user set password = ? where username = ?\"; // 是否安全 try (Connection conn = DriverManager.getConnection(\"\",\"\",\"\")){ // ... } catch (Exception e) { // ... } } } 例5： 不是线程安全的，存在共享变量conn public class MyServlet extends HttpServlet { // 是否安全 private UserService userService = new UserServiceImpl(); public void doGet(HttpServletRequest request, HttpServletResponse response) { userService.update(...); } } public class UserServiceImpl implements UserService { // 是否安全 private UserDao userDao = new UserDaoImpl(); public void update() { userDao.update(); } } public class UserDaoImpl implements UserDao { // 是否安全 private Connection conn = null; public void update() throws SQLException { String sql = \"update user set password = ? where username = ?\"; conn = DriverManager.getConnection(\"\",\"\",\"\"); // ... conn.close(); } } 例六：线程安全的，但是不推荐 public class MyServlet extends HttpServlet { // 是否安全 private UserService userService = new UserServiceImpl(); public void doGet(HttpServletRequest request, HttpServletResponse response) { userService.update(...); } } public class UserServiceImpl implements UserService { public void update() { UserDao userDao = new UserDaoImpl(); userDao.update(); } } public class UserDaoImpl implements UserDao { // 是否安全 private Connection = null; public void update() throws SQLException { String sql = \"update user set password = ? where username = ?\"; conn = DriverManager.getConnection(\"\",\"\",\"\"); // ... conn.close(); } } 例七：不是线程安全的 public abstract class Test { public void bar() { // 是否安全 SimpleDateFormat sdf = new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\"); foo(sdf); } public abstract foo(SimpleDateFormat sdf); public static void main(String[] args) { new Test().bar(); } } 其中 foo 的行为是不确定的，可能导致不安全的发生，被称之为外星方法 public void foo(SimpleDateFormat sdf) { String dateStr = \"1999-10-11 00:00:00\"; for (int i = 0; i &lt; 20; i++) { new Thread(() -&gt; { try { sdf.parse(dateStr); } catch (ParseException e) { e.printStackTrace(); } }).start(); } } 请比较 JDK 中 String 类的实现","categories":[{"name":"多线程","slug":"多线程","permalink":"https://bowonqin.github.io/categories/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}],"tags":[{"name":"多线程","slug":"多线程","permalink":"https://bowonqin.github.io/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}],"author":"qxd"},{"title":"数值计算的经度问题","slug":"java业务开发遇到的坑/9.数值计算的精度问题","date":"2022-03-16T14:12:15.000Z","updated":"2022-03-16T12:35:59.863Z","comments":true,"path":"posts/shu-zhi-ji-suan-de-jing-du-wen-ti.html","link":"","permalink":"https://bowonqin.github.io/posts/shu-zhi-ji-suan-de-jing-du-wen-ti.html","excerpt":"","text":"数值计算的经度问题中间的一些知识来自项目和极客时间 1. 关于Double从简单的反直觉的四则运算看起。对几个简单的浮点数进行加减乘除运算： System.out.println(0.1+0.2); System.out.println(1.0-0.8); System.out.println(4.015*100); System.out.println(123.3/100); double amount1 = 2.15; double amount2 = 1.10; if (amount1 - amount2 == 1.05) System.out.println(\"OK\"); 结果： 0.30000000000000004 0.19999999999999996 401.49999999999994 1.2329999999999999 这和我们预期的结果不一样。 比如，0.1 的二进制表示为 0.0 0011 0011 0011… （0011 无限循环)，再转换为十进制就是 0.1000000000000000055511151231257827021181583404541015625。对于计算机而言，0.1 无法精确表达，这是浮点数计算造成精度损失的根源。 你可能会说，以 0.1 为例，其十进制和二进制间转换后相差非常小，不会对计算产生什么影响。但，所谓积土成山，如果大量使用 double 来作大量的金钱计算，最终损失的精度就是大量的资金出入。比如，每天有一百万次交易，每次交易都差一分钱，一个月下来就差 30 万。这就不是小事儿了。那，如何解决这个问题呢？ 我们大都听说过 BigDecimal 类型，浮点数精确表达和运算的场景，一定要使用这个类型。不过，在使用 BigDecimal 时有几个坑需要避开。我们用 BigDecimal 把之前的四则运算改一下： System.out.println(new BigDecimal(0.1).add(new BigDecimal(0.2))); System.out.println(new BigDecimal(1.0).subtract(new BigDecimal(0.8))); System.out.println(new BigDecimal(4.015).multiply(new BigDecimal(100))); System.out.println(new BigDecimal(123.3).divide(new BigDecimal(100))); 结果： 0.3000000000000000166533453693773481063544750213623046875 0.1999999999999999555910790149937383830547332763671875 401.49999999999996802557689079549163579940795898437500 1.232999999999999971578290569595992565155029296875 可以看到，运算结果还是不精确，只不过是精度高了而已。这里给出浮点数运算避坑第一原则：使用 BigDecimal 表示和计算浮点数，且务必使用字符串的构造方法来初始化 BigDecimal： System.out.println(new BigDecimal(\"0.1\").add(new BigDecimal(\"0.2\"))); System.out.println(new BigDecimal(\"1.0\").subtract(new BigDecimal(\"0.8\"))); System.out.println(new BigDecimal(\"4.015\").multiply(new BigDecimal(\"100\"))); System.out.println(new BigDecimal(\"123.3\").divide(new BigDecimal(\"100\"))); 结果： 0.3 0.2 401.500 1.233 结果正确 试试用 Double.toString 把 double 转换为字符串，看看行不行？ System.out.println(new BigDecimal(\"4.015\").multiply(new BigDecimal(Double.toString(100)))); 结果 401.5000 输出为 401.5000。与上面字符串初始化 100 和 4.015 相乘得到的结果 401.500 相比，这里为什么多了 1 个 0 呢？原因就是，BigDecimal 有 scale 和 precision 的概念，scale 表示小数点右边的位数，而 precision 表示精度，也就是有效数字的长度。 new BigDecimal(Double.toString(100)) 得到的 BigDecimal 的 scale=1、precision=4；而 new BigDecimal(“100”) 得到的 BigDecimal 的 scale=0、precision=3。 对于 BigDecimal 乘法操作，返回值的 scale 是两个数的 scale 相加。所以，初始化 100 的两种不同方式，导致最后结果的 scale 分别是 4 和 3： private static void testScale() { BigDecimal bigDecimal1 = new BigDecimal(\"100\"); BigDecimal bigDecimal2 = new BigDecimal(String.valueOf(100d)); BigDecimal bigDecimal3 = new BigDecimal(String.valueOf(100)); BigDecimal bigDecimal4 = BigDecimal.valueOf(100d); BigDecimal bigDecimal5 = new BigDecimal(Double.toString(100)); print(bigDecimal1); //scale 0 precision 3 result 401.500 print(bigDecimal2); //scale 1 precision 4 result 401.5000 print(bigDecimal3); //scale 0 precision 3 result 401.500 print(bigDecimal4); //scale 1 precision 4 result 401.5000 print(bigDecimal5); //scale 1 precision 4 result 401.5000 } private static void print(BigDecimal bigDecimal) { log.info(\"scale {} precision {} result {}\", bigDecimal.scale(), bigDecimal.precision(), bigDecimal.multiply(new BigDecimal(\"4.015\"))); } 结果 09:12:40.519 [main] INFO com.qxd.numeralcalculations.dangerousdouble.CommonMistakesApplication - scale 0 precision 3 result 401.500 09:12:40.524 [main] INFO com.qxd.numeralcalculations.dangerousdouble.CommonMistakesApplication - scale 1 precision 4 result 401.5000 09:12:40.524 [main] INFO com.qxd.numeralcalculations.dangerousdouble.CommonMistakesApplication - scale 0 precision 3 result 401.500 09:12:40.524 [main] INFO com.qxd.numeralcalculations.dangerousdouble.CommonMistakesApplication - scale 1 precision 4 result 401.5000 09:12:40.524 [main] INFO com.qxd.numeralcalculations.dangerousdouble.CommonMistakesApplication - scale 1 precision 4 result 401.5000 2. 考虑浮点数舍入和格式化的方式除了使用 Double 保存浮点数可能带来精度问题外，更匪夷所思的是这种精度问题，加上 String.format 的格式化舍入方式，可能得到让人摸不着头脑的结果。 首先用 double 和 float 初始化两个 3.35 的浮点数，然后通过 String.format 使用 %.1f 来格式化这 2 个数字： double num1 = 3.35; float num2 = 3.35f; System.out.println(String.format(\"%.1f\", num1));//四舍五入 System.out.println(String.format(\"%.1f\", num2)); 结果： 3.4 3.3 这就是由精度问题和舍入方式共同导致的，double 和 float 的 3.35 其实相当于 3.350xxx 和 3.349xxx： 3.350000000000000088817841970012523233890533447265625 3.349999904632568359375 String.format 采用四舍五入的方式进行舍入，取 1 位小数，double 的 3.350 四舍五入为 3.4，而 float 的 3.349 四舍五入为 3.3。 Formatter 类的相关源码，可以发现使用的舍入模式是 HALF_UP（代码第 11 行）： else if (c == Conversion.DECIMAL_FLOAT) { // Create a new BigDecimal with the desired precision. int prec = (precision == -1 ? 6 : precision); int scale = value.scale(); if (scale &gt; prec) { // more \"scale\" digits than the requested \"precision\" int compPrec = value.precision(); if (compPrec &lt;= scale) { // case of 0.xxxxxx value = value.setScale(prec, RoundingMode.HALF_UP); } else { compPrec -= (scale - prec); value = new BigDecimal(value.unscaledValue(), scale, new MathContext(compPrec)); } } 如果我们希望使用其他舍入方式来格式化字符串的话，可以设置 DecimalFormat，如下代码所示： double num1 = 3.35; float num2 = 3.35f; DecimalFormat format = new DecimalFormat(\"#.##\"); format.setRoundingMode(RoundingMode.DOWN); System.out.println(format.format(num1)); format.setRoundingMode(RoundingMode.DOWN); System.out.println(format.format(num2)); 结果 3.35 3.34 因此，即使通过 DecimalFormat 来精确控制舍入方式，double 和 float 的问题也可能产生意想不到的结果，所以浮点数避坑第二原则：浮点数的字符串格式化也要通过 BigDecimal 进行 比如下面这段代码，使用 BigDecimal 来格式化数字 3.35，分别使用向下舍入和四舍五入方式取 1 位小数进行格式化： BigDecimal num1 = new BigDecimal(\"3.35\"); BigDecimal num2 = num1.setScale(1, BigDecimal.ROUND_DOWN); System.out.println(num2); BigDecimal num3 = num1.setScale(1, BigDecimal.ROUND_HALF_UP); System.out.println(num3); 结果: 3.3 3.4 符合预期 3. 用 equals 做判等的坑包装类的比较要通过 equals 进行，而不能使用 ==。那么，使用 equals 方法对两个 BigDecimal 判等，一定能得到我们想要的结果吗？ 使用 equals 方法比较 1.0 和 1 这两个 BigDecimal： System.out.println(new BigDecimal(\"1.0\").equals(new BigDecimal(\"1\"))) 结果: false BigDecimal的equals方法源码： @Override public boolean equals(Object x) { if (!(x instanceof BigDecimal)) return false; BigDecimal xDec = (BigDecimal) x; if (x == this) return true; if (scale != xDec.scale) return false; long s = this.intCompact; long xs = xDec.intCompact; if (s != INFLATED) { if (xs == INFLATED) xs = compactValFor(xDec.intVal); return xs == s; } else if (xs != INFLATED) return xs == compactValFor(this.intVal); return this.inflated().equals(xDec.inflated()); } 可以看出第8行有对scale的比较。 BigDecimal 的 equals 方法的注释中说明了原因，equals 比较的是 BigDecimal 的 value 和 scale，1.0 的 scale 是 1，1 的 scale 是 0，所以结果一定是 false： 如果我们希望只比较 BigDecimal 的 value，可以使用 compareTo 方法，修改后代码如下： System.out.println(new BigDecimal(\"1.0\").compareTo(new BigDecimal(\"1\"))==0); BigDecimal 的 equals 和 hashCode 方法会同时考虑 value 和 scale，如果结合 HashSet 或 HashMap 使用的话就可能会出现麻烦。比如，我们把值为 1.0 的 BigDecimal 加入 HashSet，然后判断其是否存在值为 1 的 BigDecimal，得到的结果是 false： Set&lt;BigDecimal&gt; hashSet1 = new HashSet&lt;&gt;(); hashSet1.add(new BigDecimal(\"1.0\")); System.out.println(hashSet1.contains(new BigDecimal(\"1\")));//返回false 解决这个问题的办法有两个： 第一个方法是，使用 TreeSet 替换 HashSet。TreeSet 不使用 hashCode 方法，也不使用 equals 比较元素，而是使用 compareTo 方法，所以不会有问题。 Set&lt;BigDecimal&gt; treeSet = new TreeSet&lt;&gt;(); treeSet.add(new BigDecimal(\"1.0\")); System.out.println(treeSet.contains(new BigDecimal(\"1\")));//返回true 第二个方法是，把 BigDecimal 存入 HashSet 或 HashMap 前，先使用 stripTrailingZeros 方法去掉尾部的零，比较的时候也去掉尾部的 0，确保 value 相同的 BigDecimal，scale 也是一致的： Set&lt;BigDecimal&gt; hashSet2 = new HashSet&lt;&gt;(); hashSet2.add(new BigDecimal(\"1.0\").stripTrailingZeros()); System.out.println(hashSet2.contains(new BigDecimal(\"1.000\").stripTrailingZeros()));//返回true 4. 数值溢出数值计算还有一个要小心的点是溢出，不管是 int 还是 long，所有的基本数值类型都有超出表达范围的可能性。 比如，对 Long 的最大值进行 +1 操作： long l = Long.MAX_VALUE; System.out.println(l + 1); System.out.println(l + 1 == Long.MIN_VALUE); 结果: -9223372036854775808 true 显然上述的结果出现了溢出 方法一是，考虑使用 Math 类的 addExact、subtractExact 等 xxExact 方法进行数值运算，这些方法可以在数值溢出时主动抛出异常。使用 Math.addExact 对 Long 最大值做 +1 操作： try { long l = Long.MAX_VALUE; System.out.println(Math.addExact(l, 1)); } catch (Exception ex) { ex.printStackTrace(); } 结果： java.lang.ArithmeticException: long overflow at java.lang.Math.addExact(Math.java:809) at org.geekbang.time.commonmistakes.numeralcalculations.demo3.CommonMistakesApplication.right2(CommonMistakesApplication.java:25) at org.geekbang.time.commonmistakes.numeralcalculations.demo3.CommonMistakesApplication.main(CommonMistakesApplication.java:13) 方法二是，使用大数类 BigInteger。BigDecimal 是处理浮点数的专家，而 BigInteger 则是对大数进行科学计算的专家。 BigInteger i = new BigInteger(String.valueOf(Long.MAX_VALUE)); System.out.println(i.add(BigInteger.ONE).toString()); try { long l = i.add(BigInteger.ONE).longValueExact(); } catch (Exception ex) { ex.printStackTrace(); } 输出结果如下： 9223372036854775808 java.lang.ArithmeticException: BigInteger out of long range at java.math.BigInteger.longValueExact(BigInteger.java:4632) at org.geekbang.time.commonmistakes.numeralcalculations.demo3.CommonMistakesApplication.right1(CommonMistakesApplication.java:37) at org.geekbang.time.commonmistakes.numeralcalculations.demo3.CommonMistakesApplication.main(CommonMistakesApplication.java:11) 5. 重点回顾第一，切记，要精确表示浮点数应该使用 BigDecimal。并且，使用 BigDecimal 的 Double 入参的构造方法同样存在精度丢失问题，应该使用 String 入参的构造方法或者 BigDecimal.valueOf 方法来初始化。 第二，对浮点数做精确计算，参与计算的各种数值应该始终使用 BigDecimal，所有的计算都要通过 BigDecimal 的方法进行，切勿只是让 BigDecimal 来走过场。任何一个环节出现精度损失，最后的计算结果可能都会出现误差。 第三，对于浮点数的格式化，如果使用 String.format 的话，需要认识到它使用的是四舍五入，可以考虑使用 DecimalFormat 来明确指定舍入方式。但考虑到精度问题，我更建议使用 BigDecimal 来表示浮点数，并使用其 setScale 方法指定舍入的位数和方式。 第四，进行数值运算时要小心溢出问题，虽然溢出后不会出现异常，但得到的计算结果是完全错误的。我们考虑使用 Math.xxxExact 方法来进行运算，在溢出时能抛出异常，更建议对于可能会出现溢出的大数运算使用 BigInteger 类。 总之，对于金融、科学计算等场景，请尽可能使用 BigDecimal 和 BigInteger，避免由精度和溢出问题引发难以发现，但影响重大的 Bug。 比如现在手里的一个项目使用数采仪采集数据得到的数据所需要精度非常高，所以在做科学计算的时候需要充分考虑以上因素。","categories":[{"name":"java业务","slug":"java业务","permalink":"https://bowonqin.github.io/categories/java%E4%B8%9A%E5%8A%A1/"}],"tags":[{"name":"java基础","slug":"java基础","permalink":"https://bowonqin.github.io/tags/java%E5%9F%BA%E7%A1%80/"},{"name":"java业务","slug":"java业务","permalink":"https://bowonqin.github.io/tags/java%E4%B8%9A%E5%8A%A1/"}],"author":"qxd"},{"title":"程序中的判等问题中的一些思考","slug":"java业务开发遇到的坑/8.程序中的判等问题","date":"2022-03-16T13:02:34.000Z","updated":"2022-03-16T12:34:35.058Z","comments":true,"path":"posts/cheng-xu-zhong-de-pan-deng-wen-ti-zhong-de-yi-xie-si-kao.html","link":"","permalink":"https://bowonqin.github.io/posts/cheng-xu-zhong-de-pan-deng-wen-ti-zhong-de-yi-xie-si-kao.html","excerpt":"","text":"程序中的判等问题中的一些思考中间的一些知识来自项目和极客时间 1. 注意 equals 和 == 的区别在业务代码中，我们通常使用 equals 或 == 进行判等操作。equals 是方法而 == 是操作符，它们的使用是有区别的： 对基本类型，比如 int、long，进行判等，只能使用 ==，比较的是直接值。因为基本类型的值就是其数值。 对引用类型，比如 Integer、Long 和 String，进行判等，需要使用 equals 进行内容判等。因为引用类型的直接值是指针，使用 == 的话，比较的是指针，也就是两个对象在内存中的地址，即比较它们是不是同一个对象，而不是比较对象的内容。 这就引出了我们必须必须要知道的第一个结论：比较值的内容，除了基本类型只能使用 == 外，其他类型都需要使用 equals。 这里需要注意包装类，因为包装类中使用到了数据缓存 我们用下面的测试用例深入研究下： 使用 == 对两个值为 127 的直接赋值的 Integer 对象判等； 使用 == 对两个值为 128 的直接赋值的 Integer 对象判等； 使用 == 对一个值为 127 的直接赋值的 Integer 和另一个通过 new Integer 声明的值为 127 的对象判等； 使用 == 对两个通过 new Integer 声明的值为 127 的对象判等； 使用 == 对一个值为 128 的直接赋值的 Integer 对象和另一个值为 128 的 int 基本类型判等。 Integer a = 127; //Integer.valueOf(127) Integer b = 127; //Integer.valueOf(127) log.info(\"\\nInteger a = 127;\\n\" + \"Integer b = 127;\\n\" + \"a == b ? {}\",a == b); // true Integer c = 128; //Integer.valueOf(128) Integer d = 128; //Integer.valueOf(128) log.info(\"\\nInteger c = 128;\\n\" + \"Integer d = 128;\\n\" + \"c == d ? {}\", c == d); //false Integer e = 127; //Integer.valueOf(127) Integer f = new Integer(127); //new instance log.info(\"\\nInteger e = 127;\\n\" + \"Integer f = new Integer(127);\\n\" + \"e == f ? {}\", e == f); //false Integer g = new Integer(127); //new instance Integer h = new Integer(127); //new instance log.info(\"\\nInteger g = new Integer(127);\\n\" + \"Integer h = new Integer(127);\\n\" + \"g == h ? {}\", g == h); //false Integer i = 128; //unbox int j = 128; log.info(\"\\nInteger i = 128;\\n\" + \"int j = 128;\\n\" + \"i == j ? {}\", i == j); //true 第一个案例中，编译器会把 Integer a = 127 转换为 Integer.valueOf(127)。查看源码可以发现，这个转换在内部其实做了缓存，使得两个 Integer 指向同一个对象，所以 == 返回 true。 public static Integer valueOf(int i) { if (i &gt;= IntegerCache.low &amp;&amp; i &lt;= IntegerCache.high) return IntegerCache.cache[i + (-IntegerCache.low)]; return new Integer(i); } 第二个案例中，之所以同样的代码 128 就返回 false 的原因是，默认情况下会缓存[-128, 127]的数值，而 128 处于这个区间之外。设置 JVM 参数加上 -XX:AutoBoxCacheMax=1000 再试试，是不是就返回 true 了呢？ private static class IntegerCache { static final int low = -128; static final int high; static { // high value may be configured by property int h = 127; String integerCacheHighPropValue = sun.misc.VM.getSavedProperty(\"java.lang.Integer.IntegerCache.high\"); if (integerCacheHighPropValue != null) { try { int i = parseInt(integerCacheHighPropValue); i = Math.max(i, 127); // Maximum array size is Integer.MAX_VALUE h = Math.min(i, Integer.MAX_VALUE - (-low) -1); } catch( NumberFormatException nfe) { // If the property cannot be parsed into an int, ignore it. } } high = h; cache = new Integer[(high - low) + 1]; int j = low; for(int k = 0; k &lt; cache.length; k++) cache[k] = new Integer(j++); // range [-128, 127] must be interned (JLS7 5.1.7) assert IntegerCache.high &gt;= 127; } } 第三和第四个案例中，New 出来的 Integer 始终是不走缓存的新对象。比较两个新对象，或者比较一个新对象和一个来自缓存的对象，结果肯定不是相同的对象，因此返回 false。 第五个案例中，我们把装箱的 Integer 和基本类型 int 比较，前者会先拆箱再比较，比较的肯定是数值而不是引用，因此返回 true。 看到这里，对于 Integer 什么时候是相同对象什么时候是不同对象，就很清楚了吧。但知道这些其实意义不大，因为在大多数时候，我们并不关心 Integer 对象是否是同一个，只需要记得比较 Integer 的值请使用 equals，而不是 ==（对于基本类型 int 的比较当然只能使用 ==）。 其实，我们应该都知道这个原则，只是有的时候特别容易忽略。以我之前遇到过的一个生产事故为例，有这么一个枚举定义了订单状态和对于状态的描述： enum StatusEnum { CREATED(1000, \"已创建\"), PAID(1001, \"已支付\"), DELIVERED(1002, \"已送到\"), FINISHED(1003, \"已完成\"); private final Integer status; //注意这里的Integer private final String desc; StatusEnum(Integer status, String desc) { this.status = status; this.desc = desc; } } 在业务代码中，使用了 == 对枚举和入参 OrderQuery 中的 status 属性进行判等： @Data public class OrderQuery { private Integer status; private String name; } @PostMapping(\"enumcompare\") public void enumcompare(@RequestBody OrderQuery orderQuery){ StatusEnum statusEnum = StatusEnum.DELIVERED; log.info(\"orderQuery:{} statusEnum:{} result:{}\", orderQuery, statusEnum, statusEnum.status == orderQuery.getStatus()); } 只看枚举的定义 CREATED(1000, “已创建”)，容易让人误解 status 值是基本类型； 因为有 Integer 缓存机制的存在，所以使用 == 判等并不是所有情况下都有问题。在这次事故中，订单状态的值从 100 开始增长，程序一开始不出问题，直到订单状态超过 127 后才出现 Bug。 在了解清楚为什么 Integer 使用 == 判等有时候也有效的原因之后，我们再来看看为什么 String 也有这个问题。我们使用几个用例来测试下： 对两个直接声明的值都为 1 的 String 使用 == 判等； 对两个 new 出来的值都为 2 的 String 使用 == 判等； 对两个 new 出来的值都为 3 的 String 先进行 intern 操作，再使用 == 判等； 对两个 new 出来的值都为 4 的 String 通过 equals 判等。 String a = \"1\"; String b = \"1\"; log.info(\"\\nString a = \\\"1\\\";\\n\" + \"String b = \\\"1\\\";\\n\" + \"a == b ? {}\", a == b); //true String c = new String(\"2\"); String d = new String(\"2\"); log.info(\"\\nString c = new String(\\\"2\\\");\\n\" + \"String d = new String(\\\"2\\\");\" + \"c == d ? {}\", c == d); //false String e = new String(\"3\").intern(); String f = new String(\"3\").intern(); log.info(\"\\nString e = new String(\\\"3\\\").intern();\\n\" + \"String f = new String(\\\"3\\\").intern();\\n\" + \"e == f ? {}\", e == f); //true String g = new String(\"4\"); String h = new String(\"4\"); log.info(\"\\nString g = new String(\\\"4\\\");\\n\" + \"String h = new String(\\\"4\\\");\\n\" + \"g == h ? {}\", g.equals(h)); //true 这里需要JVM常量池的相关知识，详情请看JVM笔记 在JDK7和JDK8中的使用还不一样 第一个案例返回 true，因为 Java 的字符串驻留机制，直接使用双引号声明出来的两个 String 对象指向常量池中的相同字符串。 第二个案例，new 出来的两个 String 是不同对象，引用当然不同，所以得到 false 的结果。 第三个案例，使用 String 提供的 intern 方法也会走常量池机制，所以同样能得到 true。 第四个案例，通过 equals 对值内容判等，是正确的处理方式，当然会得到 true。 虽然使用 new 声明的字符串调用 intern 方法，也可以让字符串进行驻留，但在业务代码中滥用 intern，可能会产生性能问题。 写代码测试一下，通过循环把 1 到 1000 万之间的数字以字符串形式 intern 后，存入一个 List： List&lt;String&gt; list = new ArrayList&lt;&gt;(); @GetMapping(\"internperformance\") public int internperformance(@RequestParam(value = \"size\", defaultValue = \"10000000\")int size) { //-XX:+PrintStringTableStatistics //-XX:StringTableSize=10000000 long begin = System.currentTimeMillis(); list = IntStream.rangeClosed(1, size) .mapToObj(i-&gt; String.valueOf(i).intern()) .collect(Collectors.toList()); log.info(\"size:{} took:{}\", size, System.currentTimeMillis() - begin); return list.size(); } 在启动程序时设置 JVM 参数 -XX:+PrintStringTableStatistic，程序退出时可以打印出字符串常量表的统计信息。调用接口后关闭程序，输出如下： [11:01:57.770] [http-nio-45678-exec-2] [INFO ] [.t.c.e.d.IntAndStringEqualController:54 ] - size:10000000 took:44907 StringTable statistics: Number of buckets : 60013 = 480104 bytes, avg 8.000 Number of entries : 10030230 = 240725520 bytes, avg 24.000 Number of literals : 10030230 = 563005568 bytes, avg 56.131 Total footprint : = 804211192 bytes Average bucket size : 167.134 Variance of bucket size : 55.808 Std. dev. of bucket size: 7.471 Maximum bucket size : 198 可以看到，1000 万次 intern 操作耗时居然超过了 44 秒。 其实，原因在于字符串常量池是一个固定容量的 Map。如果容量太小（Number of buckets=60013）、字符串太多（1000 万个字符串），那么每一个桶中的字符串数量会非常多，所以搜索起来就很慢。输出结果中的 Average bucket size=167，代表了 Map 中桶的平均长度是 167。 解决方式是，设置 JVM 参数 -XX:StringTableSize，指定更多的桶。设置 -XX:StringTableSize=10000000 后，重启应用： [11:09:04.475] [http-nio-45678-exec-1] [INFO ] [.t.c.e.d.IntAndStringEqualController:54 ] - size:10000000 took:5557 StringTable statistics: Number of buckets : 10000000 = 80000000 bytes, avg 8.000 Number of entries : 10030156 = 240723744 bytes, avg 24.000 Number of literals : 10030156 = 562999472 bytes, avg 56.131 Total footprint : = 883723216 bytes Average bucket size : 1.003 Variance of bucket size : 1.587 Std. dev. of bucket size: 1.260 Maximum bucket size : 10 可以看到，1000 万次调用耗时只有 5.5 秒，Average bucket size 降到了 1，效果明显。 好了，是时候给出第二原则了：没事别轻易用 intern，如果要用一定要注意控制驻留的字符串的数量，并留意常量表的各项指标。 2. 实现一个 equals 没有这么简单如果看过 Object 类源码，你可能就知道，equals 的实现其实是比较对象引用： public boolean equals(Object obj) { return (this == obj); } 之所以 Integer 或 String 能通过 equals 实现内容判等，是因为它们都重写了这个方法。比如，String 的 equals 的实现： public boolean equals(Object anObject) { if (this == anObject) { return true; } if (anObject instanceof String) { String anotherString = (String)anObject; int n = value.length; if (n == anotherString.value.length) { char v1[] = value; char v2[] = anotherString.value; int i = 0; while (n-- != 0) { if (v1[i] != v2[i]) return false; i++; } return true; } } return false; } 对于自定义类型，如果不重写 equals 的话，默认就是使用 Object 基类的按引用的比较方式。我们写一个自定义类测试一下。 假设有这样一个描述点的类 Point，有 x、y 和描述三个属性： class Point { private int x; private int y; private final String desc; public Point(int x, int y, String desc) { this.x = x; this.y = y; this.desc = desc; } } 定义三个点 p1、p2 和 p3，其中 p1 和 p2 的描述属性不同，p1 和 p3 的三个属性完全相同，并写一段代码测试一下默认行为： Point p1 = new Point(1, 2, \"a\"); Point p2 = new Point(1, 2, \"b\"); Point p3 = new Point(1, 2, \"a\"); log.info(\"p1.equals(p2) ? {}\", p1.equals(p2)); log.info(\"p1.equals(p3) ? {}\", p1.equals(p3)); 通过 equals 方法比较 p1 和 p2、p1 和 p3 均得到 false，原因正如刚才所说，我们并没有为 Point 类实现自定义的 equals 方法，Object 超类中的 equals 默认使用 == 判等，比较的是对象的引用。 我们期望的逻辑是，只要 x 和 y 这 2 个属性一致就代表是同一个点，所以写出了如下的改进代码，重写 equals 方法，把参数中的 Object 转换为 Point 比较其 x 和 y 属性： class PointWrong { private int x; private int y; private final String desc; public PointWrong(int x, int y, String desc) { this.x = x; this.y = y; this.desc = desc; } @Override public boolean equals(Object o) { PointWrong that = (PointWrong) o; return x == that.x &amp;&amp; y == that.y; } } 为测试改进后的 Point 是否可以满足需求，我们定义了三个用例： 比较一个 Point 对象和 null； 比较一个 Object 对象和一个 Point 对象； 比较两个 x 和 y 属性值相同的 Point 对象。 PointWrong p1 = new PointWrong(1, 2, \"a\"); try { log.info(\"p1.equals(null) ? {}\", p1.equals(null)); } catch (Exception ex) { log.error(ex.getMessage()); } Object o = new Object(); try { log.info(\"p1.equals(expression) ? {}\", p1.equals(o)); } catch (Exception ex) { log.error(ex.getMessage()); } PointWrong p2 = new PointWrong(1, 2, \"b\"); log.info(\"p1.equals(p2) ? {}\", p1.equals(p2)); 通过日志中的结果可以看到，第一次比较出现了空指针异常，第二次比较出现了类型转换异常，第三次比较符合预期输出了 true。 [17:54:39.120] [http-nio-45678-exec-1] [ERROR] [t.c.e.demo1.EqualityMethodController:32 ] - java.lang.NullPointerException [17:54:39.120] [http-nio-45678-exec-1] [ERROR] [t.c.e.demo1.EqualityMethodController:39 ] - java.lang.ClassCastException: java.lang.Object cannot be cast to org.geekbang.time.commonmistakes.equals.demo1.EqualityMethodController$PointWrong [17:54:39.120] [http-nio-45678-exec-1] [INFO ] [t.c.e.demo1.EqualityMethodController:43 ] - p1.equals(p2) ? true 通过这些失效的用例，我们大概可以总结出实现一个更好的 equals 应该注意的点： 考虑到性能，可以先进行指针判等，如果对象是同一个那么直接返回 true； 需要对另一方进行判空，空对象和自身进行比较，结果一定是 fasle； 需要判断两个对象的类型，如果类型都不同，那么直接返回 false； 确保类型相同的情况下再进行类型强制转换，然后逐一判断所有字段。 修复和改进后的 equals 方法如下： 修复和改进后的 equals 方法如下： @Override public boolean equals(Object o) { if (this == o) return true; if (o == null || getClass() != o.getClass()) return false; PointRight that = (PointRight) o; return x == that.x &amp;&amp; y == that.y; } 3. hashCode 和 equals 要配对实现我们来试试下面这个用例，定义两个 x 和 y 属性值完全一致的 Point 对象 p1 和 p2，把 p1 加入 HashSet，然后判断这个 Set 中是否存在 p2： PointWrong p1 = new PointWrong(1, 2, \"a\"); PointWrong p2 = new PointWrong(1, 2, \"b\"); HashSet&lt;PointWrong&gt; points = new HashSet&lt;&gt;(); points.add(p1); log.info(\"points.contains(p2) ? {}\", points.contains(p2)); 按照改进后的 equals 方法，这 2 个对象可以认为是同一个，Set 中已经存在了 p1 就应该包含 p2，但结果却是 false。 这里需要看HashMap的源码，出现这个 Bug 的原因是，散列表需要使用 hashCode 来定位元素放到哪个桶。如果自定义对象没有实现自定义的 hashCode 方法，就会使用 Object 超类的默认实现，得到的两个 hashCode 是不同的，导致无法满足需求。 要自定义 hashCode，我们可以直接使用 Objects.hash 方法来实现，改进后的 Point 类如下： class PointRight { private final int x; private final int y; private final String desc; ... @Override public boolean equals(Object o) { ... } @Override public int hashCode() { return Objects.hash(x, y); } } 改进 equals 和 hashCode 后，再测试下之前的四个用例，结果全部符合预期。 [18:25:23.091] [http-nio-45678-exec-4] [INFO ] [t.c.e.demo1.EqualityMethodController:54 ] - p1.equals(null) ? false [18:25:23.093] [http-nio-45678-exec-4] [INFO ] [t.c.e.demo1.EqualityMethodController:61 ] - p1.equals(expression) ? false [18:25:23.094] [http-nio-45678-exec-4] [INFO ] [t.c.e.demo1.EqualityMethodController:67 ] - p1.equals(p2) ? true [18:25:23.094] [http-nio-45678-exec-4] [INFO ] [t.c.e.demo1.EqualityMethodController:71 ] - points.contains(p2) ? true 这里equals和hashcode方法可以idea自动生成即可。 4. 注意 compareTo 和 equals 的逻辑一致性除了自定义类型需要确保 equals 和 hashCode 要逻辑一致外，还有一个更容易被忽略的问题，即 compareTo 同样需要和 equals 确保逻辑一致性。 我之前遇到过这么一个问题，代码里本来使用了 ArrayList 的 indexOf 方法进行元素搜索，但是一位好心的开发同学觉得逐一比较的时间复杂度是 O(n)，效率太低了，于是改为了排序后通过 Collections.binarySearch 方法进行搜索，实现了 O(log n) 的时间复杂度。没想到，这么一改却出现了 Bug。 我们来重现下这个问题。首先，定义一个 Student 类，有 id 和 name 两个属性，并实现了一个 Comparable 接口来返回两个 id 的值 @Data @AllArgsConstructor class Student implements Comparable&lt;Student&gt;{ private int id; private String name; @Override public int compareTo(Student other) { int result = Integer.compare(other.id, id); if (result==0) log.info(\"this {} == other {}\", this, other); return result; } } 然后，写一段测试代码分别通过 indexOf 方法和 Collections.binarySearch 方法进行搜索。列表中我们存放了两个学生，第一个学生 id 是 1 叫 zhang，第二个学生 id 是 2 叫 wang，搜索这个列表是否存在一个 id 是 2 叫 li 的学生： @GetMapping(\"wrong\") public void wrong(){ List&lt;Student&gt; list = new ArrayList&lt;&gt;(); list.add(new Student(1, \"zhang\")); list.add(new Student(2, \"wang\")); Student student = new Student(2, \"li\"); log.info(\"ArrayList.indexOf\"); int index1 = list.indexOf(student); Collections.sort(list); log.info(\"Collections.binarySearch\"); int index2 = Collections.binarySearch(list, student); log.info(\"index1 = \" + index1); log.info(\"index2 = \" + index2); } 代码输出的日志如下： [18:46:50.226] [http-nio-45678-exec-1] [INFO ] [t.c.equals.demo2.CompareToController:28 ] - ArrayList.indexOf [18:46:50.226] [http-nio-45678-exec-1] [INFO ] [t.c.equals.demo2.CompareToController:31 ] - Collections.binarySearch [18:46:50.227] [http-nio-45678-exec-1] [INFO ] [t.c.equals.demo2.CompareToController:67 ] - this CompareToController.Student(id=2, name=wang) == other CompareToController.Student(id=2, name=li) [18:46:50.227] [http-nio-45678-exec-1] [INFO ] [t.c.equals.demo2.CompareToController:34 ] - index1 = -1 [18:46:50.227] [http-nio-45678-exec-1] [INFO ] [t.c.equals.demo2.CompareToController:35 ] - index2 = 1 我们注意到如下几点： binarySearch 方法内部调用了元素的 compareTo 方法进行比较； indexOf 的结果没问题，列表中搜索不到 id 为 2、name 是 li 的学生； binarySearch 返回了索引 1，代表搜索到的结果是 id 为 2，name 是 wang 的学生。 修复方式很简单，确保 compareTo 的比较逻辑和 equals 的实现一致即可。重新实现一下 Student 类，通过 Comparator.comparing 这个便捷的方法来实现两个字段的比较： @Data @AllArgsConstructor class StudentRight implements Comparable&lt;StudentRight&gt;{ private int id; private String name; @Override public int compareTo(StudentRight other) { return Comparator.comparing(StudentRight::getName) .thenComparingInt(StudentRight::getId) .compare(this, other); } } 其实，这个问题容易被忽略的原因在于两方面： 一是，我们使用了 Lombok 的 @Data 标记了 Student，@Data 注解（详见这里）其实包含了 @EqualsAndHashCode 注解的作用，也就是默认情况下使用类型所有的字段（不包括 static 和 transient 字段）参与到 equals 和 hashCode 方法的实现中。因为这两个方法的实现不是我们自己实现的，所以容易忽略其逻辑。 二是，compareTo 方法需要返回数值，作为排序的依据，容易让人使用数值类型的字段随意实现。 我再强调下，对于自定义的类型，如果要实现 Comparable，请记得 equals、hashCode、compareTo 三者逻辑一致。 4. 小心 Lombok 生成代码的“坑”Lombok 的 @Data 注解会帮我们实现 equals 和 hashcode 方法，但是有继承关系时，Lombok 自动生成的方法可能就不是我们期望的了。 我们先来研究一下其实现：定义一个 Person 类型，包含姓名和身份证两个字段： @Data class Person { private String name; private String identity; public Person(String name, String identity) { this.name = name; this.identity = identity; } } 对于身份证相同、姓名不同的两个 Person 对象： Person person1 = new Person(\"zhuye\",\"001\"); Person person2 = new Person(\"Joseph\",\"001\"); log.info(\"person1.equals(person2) ? {}\", person1.equals(person2)); 使用 equals 判等会得到 false。如果你希望只要身份证一致就认为是同一个人的话，可以使用 @EqualsAndHashCode.Exclude 注解来修饰 name 字段，从 equals 和 hashCode 的实现中排除 name 字段： @EqualsAndHashCode.Exclude private String name; 修改后得到 true。打开编译后的代码可以看到，Lombok 为 Person 生成的 equals 方法的实现，确实只包含了 identity 属性： public boolean equals(final Object o) { if (o == this) { return true; } else if (!(o instanceof LombokEquealsController.Person)) { return false; } else { LombokEquealsController.Person other = (LombokEquealsController.Person)o; if (!other.canEqual(this)) { return false; } else { Object this$identity = this.getIdentity(); Object other$identity = other.getIdentity(); if (this$identity == null) { if (other$identity != null) { return false; } } else if (!this$identity.equals(other$identity)) { return false; } return true; } } } 但到这里还没完，如果类型之间有继承，Lombok 会怎么处理子类的 equals 和 hashCode 呢？我们来测试一下，写一个 Employee 类继承 Person，并新定义一个公司属性： @Data class Employee extends Person { private String company; public Employee(String name, String identity, String company) { super(name, identity); this.company = company; } } 在如下的测试代码中，声明两个 Employee 实例，它们具有相同的公司名称，但姓名和身份证均不同： Employee employee1 = new Employee(\"zhuye\",\"001\", \"bkjk.com\"); Employee employee2 = new Employee(\"Joseph\",\"002\", \"bkjk.com\"); log.info(\"employee1.equals(employee2) ? {}\", employee1.equals(employee2)); 很遗憾，结果是 true，显然是没有考虑父类的属性，而认为这两个员工是同一人，说明 @EqualsAndHashCode 默认实现没有使用父类属性。 为解决这个问题，我们可以手动设置 callSuper 开关为 true，来覆盖这种默认行为： @Data @EqualsAndHashCode(callSuper = true) class Employee extends Person { 修改后的代码，实现了同时以子类的属性 company 加上父类中的属性 identity，作为 equals 和 hashCode 方法的实现条件（实现上其实是调用了父类的 equals 和 hashCode）。 5. 重点回顾 首先，我们要注意 equals 和 == 的区别。业务代码中进行内容的比较，针对基本类型只能使用 ==，针对 Integer、String 在内的引用类型，需要使用 equals。Integer 和 String 的坑在于，使用 == 判等有时也能获得正确结果。 其次，对于自定义类型，如果类型需要参与判等，那么务必同时实现 equals 和 hashCode 方法，并确保逻辑一致。如果希望快速实现 equals、hashCode 方法，我们可以借助 IDE 的代码生成功能，或使用 Lombok 来生成。如果类型也要参与比较，那么 compareTo 方法的逻辑同样需要和 equals、hashCode 方法一致。 最后，Lombok 的 @EqualsAndHashCode 注解实现 equals 和 hashCode 的时候，默认使用类型所有非 static、非 transient 的字段，且不考虑父类。如果希望改变这种默认行为，可以使用 @EqualsAndHashCode.Exclude 排除一些字段，并设置 callSuper = true 来让子类的 equals 和 hashCode 调用父类的相应方法。 6. 思考 在实现 equals 时，我是先通过 getClass 方法判断两个对象的类型，你可能会想到还可以使用 instanceof 来判断。你能说说这两种实现方式的区别吗？ 同样是 Set 的 TreeSet 其 contains 方法和 HashSet 有什么区别吗？","categories":[{"name":"java业务","slug":"java业务","permalink":"https://bowonqin.github.io/categories/java%E4%B8%9A%E5%8A%A1/"}],"tags":[{"name":"java基础","slug":"java基础","permalink":"https://bowonqin.github.io/tags/java%E5%9F%BA%E7%A1%80/"},{"name":"java业务","slug":"java业务","permalink":"https://bowonqin.github.io/tags/java%E4%B8%9A%E5%8A%A1/"}],"author":"qxd"},{"title":"SpringCloud-服务注册与发现","slug":"微服务/SpringCloud-服务注册与发现","date":"2022-03-16T12:38:15.000Z","updated":"2022-03-16T12:32:54.237Z","comments":true,"path":"posts/springcloud-fu-wu-zhu-ce-yu-fa-xian.html","link":"","permalink":"https://bowonqin.github.io/posts/springcloud-fu-wu-zhu-ce-yu-fa-xian.html","excerpt":"","text":"SpringCloud-服务注册与发现本文为b站黑马程序员SpringCloud的学习笔记，网址为:SpringCloud 1.认识微服务随着互联网行业的发展，对服务的要求也越来越高，服务架构也从单体架构逐渐演变为现在流行的微服务架构。这些架构之间有怎样的差别呢？ 1.0.学习目标了解微服务架构的优缺点 1.1.单体架构单体架构：将业务的所有功能集中在一个项目中开发，打成一个包部署。 单体架构的优缺点如下： 优点： 架构简单 部署成本低 缺点： 耦合度高（维护困难、升级困难） 1.2.分布式架构分布式架构：根据业务功能对系统做拆分，每个业务功能模块作为独立项目开发，称为一个服务。 分布式架构的优缺点： 优点： 降低服务耦合 有利于服务升级和拓展 缺点： 服务调用关系错综复杂 分布式架构虽然降低了服务耦合，但是服务拆分时也有很多问题需要思考： 服务拆分的粒度如何界定？ 服务之间如何调用？ 服务的调用关系如何管理？ 人们需要制定一套行之有效的标准来约束分布式架构。 1.3.微服务微服务的架构特征： 单一职责：微服务拆分粒度更小，每一个服务都对应唯一的业务能力，做到单一职责 自治：团队独立、技术独立、数据独立，独立部署和交付 面向服务：服务提供统一标准的接口，与语言和技术无关 隔离性强：服务调用做好隔离、容错、降级，避免出现级联问题 微服务的上述特性其实是在给分布式架构制定一个标准，进一步降低服务之间的耦合度，提供服务的独立性和灵活性。做到高内聚，低耦合。 因此，可以认为微服务是一种经过良好架构设计的分布式架构方案 。 但方案该怎么落地？选用什么样的技术栈？全球的互联网公司都在积极尝试自己的微服务落地方案。 其中在Java领域最引人注目的就是SpringCloud提供的方案了。 1.4.SpringCloudSpringCloud是目前国内使用最广泛的微服务框架。官网地址：https://spring.io/projects/spring-cloud。 SpringCloud集成了各种微服务功能组件，并基于SpringBoot实现了这些组件的自动装配，从而提供了良好的开箱即用体验。 其中常见的组件包括： 另外，SpringCloud底层是依赖于SpringBoot的，并且有版本的兼容关系，如下： 我们课堂学习的版本是 Hoxton.SR10，因此对应的SpringBoot版本是2.3.x版本。 1.5.总结 单体架构：简单方便，高度耦合，扩展性差，适合小型项目。例如：学生管理系统 分布式架构：松耦合，扩展性好，但架构复杂，难度大。适合大型互联网项目，例如：京东、淘宝 微服务：一种良好的分布式架构方案 ①优点：拆分粒度更小、服务更独立、耦合度更低 ②缺点：架构非常复杂，运维、监控、部署难度提高 SpringCloud是微服务架构的一站式解决方案，集成了各种优秀微服务功能组件 2.服务拆分和远程调用任何分布式架构都离不开服务的拆分，微服务也是一样。 2.1.服务拆分原则这里我总结了微服务拆分时的几个原则： 不同微服务，不要重复开发相同业务 微服务数据独立，不要访问其它微服务的数据库 微服务可以将自己的业务暴露为接口，供其它微服务调用 2.2.服务拆分示例以课前资料中的微服务cloud-demo为例，其结构如下： cloud-demo：父工程，管理依赖 order-service：订单微服务，负责订单相关业务 user-service：用户微服务，负责用户相关业务 要求： 订单微服务和用户微服务都必须有各自的数据库，相互独立 订单服务和用户服务都对外暴露Restful的接口 订单服务如果需要查询用户信息，只能调用用户服务的Restful接口，不能查询用户数据库 2.2.1.导入Sql语句首先，将课前资料提供的cloud-order.sql和cloud-user.sql导入到mysql中： cloud-user表中初始数据如下： cloud-order表中初始数据如下： cloud-order表中持有cloud-user表中的id字段。 2.2.2.导入demo工程用IDEA导入课前资料提供的Demo： 项目结构如下： 导入后，会在IDEA右下角出现弹窗： 点击弹窗，然后按下图选择： 会出现这样的菜单： 配置下项目使用的JDK： 2.3.实现远程调用案例在order-service服务中，有一个根据id查询订单的接口： 根据id查询订单，返回值是Order对象，如图： 其中的user为null 在user-service中有一个根据id查询用户的接口： 查询的结果如图： 2.3.1.案例需求：修改order-service中的根据id查询订单业务，要求在查询订单的同时，根据订单中包含的userId查询出用户信息，一起返回。 因此，我们需要在order-service中 向user-service发起一个http的请求，调用http://localhost:8081/user/{userId}这个接口。 大概的步骤是这样的： 注册一个RestTemplate的实例到Spring容器 修改order-service服务中的OrderService类中的queryOrderById方法，根据Order对象中的userId查询User 将查询的User填充到Order对象，一起返回 2.3.2.注册RestTemplate首先，我们在order-service服务中的OrderApplication启动类中，注册RestTemplate实例： package cn.itcast.order; import org.mybatis.spring.annotation.MapperScan; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.context.annotation.Bean; import org.springframework.web.client.RestTemplate; @MapperScan(\"cn.itcast.order.mapper\") @SpringBootApplication public class OrderApplication { public static void main(String[] args) { SpringApplication.run(OrderApplication.class, args); } @Bean public RestTemplate restTemplate() { return new RestTemplate(); } } 2.3.3.实现远程调用修改order-service服务中的cn.itcast.order.service包下的OrderService类中的queryOrderById方法： 2.4.提供者与消费者在服务调用关系中，会有两个不同的角色： 服务提供者：一次业务中，被其它微服务调用的服务。（提供接口给其它微服务） 服务消费者：一次业务中，调用其它微服务的服务。（调用其它微服务提供的接口） 但是，服务提供者与服务消费者的角色并不是绝对的，而是相对于业务而言。 如果服务A调用了服务B，而服务B又调用了服务C，服务B的角色是什么？ 对于A调用B的业务而言：A是服务消费者，B是服务提供者 对于B调用C的业务而言：B是服务消费者，C是服务提供者 因此，服务B既可以是服务提供者，也可以是服务消费者。 3.Eureka注册中心假如我们的服务提供者user-service部署了多个实例，如图： 大家思考几个问题： order-service在发起远程调用的时候，该如何得知user-service实例的ip地址和端口？ 有多个user-service实例地址，order-service调用时该如何选择？ order-service如何得知某个user-service实例是否依然健康，是不是已经宕机？ 3.1.Eureka的结构和作用这些问题都需要利用SpringCloud中的注册中心来解决，其中最广为人知的注册中心就是Eureka，其结构如下： 回答之前的各个问题。 问题1：order-service如何得知user-service实例地址？ 获取地址信息的流程如下： user-service服务实例启动后，将自己的信息注册到eureka-server（Eureka服务端）。这个叫服务注册 eureka-server保存服务名称到服务实例地址列表的映射关系 order-service根据服务名称，拉取实例地址列表。这个叫服务发现或服务拉取 问题2：order-service如何从多个user-service实例中选择具体的实例？ order-service从实例列表中利用负载均衡算法选中一个实例地址 向该实例地址发起远程调用 问题3：order-service如何得知某个user-service实例是否依然健康，是不是已经宕机？ user-service会每隔一段时间（默认30秒）向eureka-server发起请求，报告自己状态，称为心跳 当超过一定时间没有发送心跳时，eureka-server会认为微服务实例故障，将该实例从服务列表中剔除 order-service拉取服务时，就能将故障实例排除了 注意：一个微服务，既可以是服务提供者，又可以是服务消费者，因此eureka将服务注册、服务发现等功能统一封装到了eureka-client端 因此，接下来我们动手实践的步骤包括： 3.2.搭建eureka-server首先大家注册中心服务端：eureka-server，这必须是一个独立的微服务 3.2.1.创建eureka-server服务在cloud-demo父工程下，创建一个子模块： 填写模块信息： 然后填写服务信息： 3.2.2.引入eureka依赖引入SpringCloud为eureka提供的starter依赖： &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt; &lt;/dependency&gt; 3.2.3.编写启动类给eureka-server服务编写一个启动类，一定要添加一个@EnableEurekaServer注解，开启eureka的注册中心功能： package cn.itcast.eureka; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.cloud.netflix.eureka.server.EnableEurekaServer; @SpringBootApplication @EnableEurekaServer public class EurekaApplication { public static void main(String[] args) { SpringApplication.run(EurekaApplication.class, args); } } 3.2.4.编写配置文件编写一个application.yml文件，内容如下： server: port: 10086 spring: application: name: eureka-server eureka: client: service-url: defaultZone: http://127.0.0.1:10086/eureka 3.2.5.启动服务启动微服务，然后在浏览器访问：http://127.0.0.1:10086 看到下面结果应该是成功了： 3.3.服务注册下面，我们将user-service注册到eureka-server中去。 1）引入依赖在user-service的pom文件中，引入下面的eureka-client依赖： &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; 2）配置文件在user-service中，修改application.yml文件，添加服务名称、eureka地址： spring: application: name: userservice eureka: client: service-url: defaultZone: http://127.0.0.1:10086/eureka 3）启动多个user-service实例为了演示一个服务有多个实例的场景，我们添加一个SpringBoot的启动配置，再启动一个user-service。 首先，复制原来的user-service启动配置： 然后，在弹出的窗口中，填写信息： 现在，SpringBoot窗口会出现两个user-service启动配置： 不过，第一个是8081端口，第二个是8082端口。 启动两个user-service实例： 查看eureka-server管理页面： 3.4.服务发现下面，我们将order-service的逻辑修改：向eureka-server拉取user-service的信息，实现服务发现。 1）引入依赖之前说过，服务发现、服务注册统一都封装在eureka-client依赖，因此这一步与服务注册时一致。 在order-service的pom文件中，引入下面的eureka-client依赖： &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; 2）配置文件服务发现也需要知道eureka地址，因此第二步与服务注册一致，都是配置eureka信息： 在order-service中，修改application.yml文件，添加服务名称、eureka地址： spring: application: name: orderservice eureka: client: service-url: defaultZone: http://127.0.0.1:10086/eureka 3）服务拉取和负载均衡最后，我们要去eureka-server中拉取user-service服务的实例列表，并且实现负载均衡。 不过这些动作不用我们去做，只需要添加一些注解即可。 在order-service的OrderApplication中，给RestTemplate这个Bean添加一个@LoadBalanced注解： 修改order-service服务中的cn.itcast.order.service包下的OrderService类中的queryOrderById方法。修改访问的url路径，用服务名代替ip、端口： spring会自动帮助我们从eureka-server端，根据userservice这个服务名称，获取实例列表，而后完成负载均衡。 4.Ribbon负载均衡上一节中，我们添加了@LoadBalanced注解，即可实现负载均衡功能，这是什么原理呢？ 4.1.负载均衡原理SpringCloud底层其实是利用了一个名为Ribbon的组件，来实现负载均衡功能的。 那么我们发出的请求明明是http://userservice/user/1，怎么变成了http://localhost:8081的呢？ 4.2.源码跟踪为什么我们只输入了service名称就可以访问了呢？之前还要获取ip和端口。 显然有人帮我们根据service名称，获取到了服务实例的ip和端口。它就是LoadBalancerInterceptor，这个类会在对RestTemplate的请求进行拦截，然后从Eureka根据服务id获取服务列表，随后利用负载均衡算法得到真实的服务地址信息，替换服务id。 我们进行源码跟踪： 1）LoadBalancerIntercepor 可以看到这里的intercept方法，拦截了用户的HttpRequest请求，然后做了几件事： request.getURI()：获取请求uri，本例中就是 http://user-service/user/8 originalUri.getHost()：获取uri路径的主机名，其实就是服务id，user-service this.loadBalancer.execute()：处理服务id，和用户请求。 这里的this.loadBalancer是LoadBalancerClient类型，我们继续跟入。 2）LoadBalancerClient继续跟入execute方法： 代码是这样的： getLoadBalancer(serviceId)：根据服务id获取ILoadBalancer，而ILoadBalancer会拿着服务id去eureka中获取服务列表并保存起来。 getServer(loadBalancer)：利用内置的负载均衡算法，从服务列表中选择一个。本例中，可以看到获取了8082端口的服务 放行后，再次访问并跟踪，发现获取的是8081： 果然实现了负载均衡。 3）负载均衡策略IRule在刚才的代码中，可以看到获取服务使通过一个getServer方法来做负载均衡: 我们继续跟入： 继续跟踪源码chooseServer方法，发现这么一段代码： 我们看看这个rule是谁： 这里的rule默认值是一个RoundRobinRule，看类的介绍： 这不就是轮询的意思嘛。 到这里，整个负载均衡的流程我们就清楚了。 4）总结SpringCloudRibbon的底层采用了一个拦截器，拦截了RestTemplate发出的请求，对地址做了修改。用一幅图来总结一下： 基本流程如下： 拦截我们的RestTemplate请求http://userservice/user/1 RibbonLoadBalancerClient会从请求url中获取服务名称，也就是user-service DynamicServerListLoadBalancer根据user-service到eureka拉取服务列表 eureka返回列表，localhost:8081、localhost:8082 IRule利用内置负载均衡规则，从列表中选择一个，例如localhost:8081 RibbonLoadBalancerClient修改请求地址，用localhost:8081替代userservice，得到http://localhost:8081/user/1，发起真实请求 4.3.负载均衡策略4.3.1.负载均衡策略负载均衡的规则都定义在IRule接口中，而IRule有很多不同的实现类： 不同规则的含义如下： 内置负载均衡规则类 规则描述 RoundRobinRule 简单轮询服务列表来选择服务器。它是Ribbon默认的负载均衡规则。 AvailabilityFilteringRule 对以下两种服务器进行忽略： （1）在默认情况下，这台服务器如果3次连接失败，这台服务器就会被设置为“短路”状态。短路状态将持续30秒，如果再次连接失败，短路的持续时间就会几何级地增加。 （2）并发数过高的服务器。如果一个服务器的并发连接数过高，配置了AvailabilityFilteringRule规则的客户端也会将其忽略。并发连接数的上限，可以由客户端的..ActiveConnectionsLimit属性进行配置。 WeightedResponseTimeRule 为每一个服务器赋予一个权重值。服务器响应时间越长，这个服务器的权重就越小。这个规则会随机选择服务器，这个权重值会影响服务器的选择。 ZoneAvoidanceRule 以区域可用的服务器为基础进行服务器的选择。使用Zone对服务器进行分类，这个Zone可以理解为一个机房、一个机架等。而后再对Zone内的多个服务做轮询。 BestAvailableRule 忽略那些短路的服务器，并选择并发数较低的服务器。 RandomRule 随机选择一个可用的服务器。 RetryRule 重试机制的选择逻辑 默认的实现就是ZoneAvoidanceRule，是一种轮询方案 4.3.2.自定义负载均衡策略通过定义IRule实现可以修改负载均衡规则，有两种方式： 代码方式：在order-service中的OrderApplication类中，定义一个新的IRule： @Bean public IRule randomRule(){ return new RandomRule(); } 配置文件方式：在order-service的application.yml文件中，添加新的配置也可以修改规则： userservice: # 给某个微服务配置负载均衡规则，这里是userservice服务 ribbon: NFLoadBalancerRuleClassName: com.netflix.loadbalancer.RandomRule # 负载均衡规则 注意，一般用默认的负载均衡规则，不做修改。 4.4.饥饿加载Ribbon默认是采用懒加载，即第一次访问时才会去创建LoadBalanceClient，请求时间会很长。 而饥饿加载则会在项目启动时创建，降低第一次访问的耗时，通过下面配置开启饥饿加载： ribbon: eager-load: enabled: true clients: userservice 5.Nacos注册中心国内公司一般都推崇阿里巴巴的技术，比如注册中心，SpringCloudAlibaba也推出了一个名为Nacos的注册中心。 5.1.认识和安装NacosNacos是阿里巴巴的产品，现在是SpringCloud中的一个组件。相比Eureka功能更加丰富，在国内受欢迎程度较高。 5.2.服务注册到nacosNacos是SpringCloudAlibaba的组件，而SpringCloudAlibaba也遵循SpringCloud中定义的服务注册、服务发现规范。因此使用Nacos和使用Eureka对于微服务来说，并没有太大区别。 主要差异在于： 依赖不同 服务地址不同 1）引入依赖在cloud-demo父工程的pom文件中的&lt;dependencyManagement&gt;中引入SpringCloudAlibaba的依赖： &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-alibaba-dependencies&lt;/artifactId&gt; &lt;version&gt;2.2.6.RELEASE&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; 然后在user-service和order-service中的pom文件中引入nacos-discovery依赖： &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;/dependency&gt; 注意：不要忘了注释掉eureka的依赖。 2）配置nacos地址在user-service和order-service的application.yml中添加nacos地址： spring: cloud: nacos: server-addr: localhost:8848 注意：不要忘了注释掉eureka的地址 3）重启重启微服务后，登录nacos管理页面，可以看到微服务信息： 5.3.服务分级存储模型一个服务可以有多个实例，例如我们的user-service，可以有: 127.0.0.1:8081 127.0.0.1:8082 127.0.0.1:8083 假如这些实例分布于全国各地的不同机房，例如： 127.0.0.1:8081，在上海机房 127.0.0.1:8082，在上海机房 127.0.0.1:8083，在杭州机房 Nacos就将同一机房内的实例 划分为一个集群。 也就是说，user-service是服务，一个服务可以包含多个集群，如杭州、上海，每个集群下可以有多个实例，形成分级模型，如图： 微服务互相访问时，应该尽可能访问同集群实例，因为本地访问速度更快。当本集群内不可用时，才访问其它集群。例如： 杭州机房内的order-service应该优先访问同机房的user-service。 5.3.1.给user-service配置集群修改user-service的application.yml文件，添加集群配置： spring: cloud: nacos: server-addr: localhost:8848 discovery: cluster-name: HZ # 集群名称 重启两个user-service实例后，我们可以在nacos控制台看到下面结果： 我们再次复制一个user-service启动配置，添加属性： -Dserver.port=8083 -Dspring.cloud.nacos.discovery.cluster-name=SH 配置如图所示： 启动UserApplication3后再次查看nacos控制台： 5.3.2.同集群优先的负载均衡默认的ZoneAvoidanceRule并不能实现根据同集群优先来实现负载均衡。 因此Nacos中提供了一个NacosRule的实现，可以优先从同集群中挑选实例。 1）给order-service配置集群信息 修改order-service的application.yml文件，添加集群配置： spring: cloud: nacos: server-addr: localhost:8848 discovery: cluster-name: HZ # 集群名称 2）修改负载均衡规则 修改order-service的application.yml文件，修改负载均衡规则： userservice: ribbon: NFLoadBalancerRuleClassName: com.alibaba.cloud.nacos.ribbon.NacosRule # 负载均衡规则 5.4.权重配置实际部署中会出现这样的场景： 服务器设备性能有差异，部分实例所在机器性能较好，另一些较差，我们希望性能好的机器承担更多的用户请求。 但默认情况下NacosRule是同集群内随机挑选，不会考虑机器的性能问题。 因此，Nacos提供了权重配置来控制访问频率，权重越大则访问频率越高。 在nacos控制台，找到user-service的实例列表，点击编辑，即可修改权重： 在弹出的编辑窗口，修改权重： 注意：如果权重修改为0，则该实例永远不会被访问 5.5.环境隔离Nacos提供了namespace来实现环境隔离功能。 nacos中可以有多个namespace namespace下可以有group、service等 不同namespace之间相互隔离，例如不同namespace的服务互相不可见 5.5.1.创建namespace默认情况下，所有service、data、group都在同一个namespace，名为public： 我们可以点击页面新增按钮，添加一个namespace： 然后，填写表单： 就能在页面看到一个新的namespace： 5.5.2.给微服务配置namespace给微服务配置namespace只能通过修改配置来实现。 例如，修改order-service的application.yml文件： spring: cloud: nacos: server-addr: localhost:8848 discovery: cluster-name: HZ namespace: 492a7d5d-237b-46a1-a99a-fa8e98e4b0f9 # 命名空间，填ID 重启order-service后，访问控制台，可以看到下面的结果： 此时访问order-service，因为namespace不同，会导致找不到userservice，控制台会报错： 5.6.Nacos与Eureka的区别Nacos的服务实例分为两种l类型： 临时实例：如果实例宕机超过一定时间，会从服务列表剔除，默认的类型。 非临时实例：如果实例宕机，不会从服务列表剔除，也可以叫永久实例。 配置一个服务实例为永久实例： spring: cloud: nacos: discovery: ephemeral: false # 设置为非临时实例 Nacos和Eureka整体结构类似，服务注册、服务拉取、心跳等待，但是也存在一些差异： Nacos与eureka的共同点 都支持服务注册和服务拉取 都支持服务提供者心跳方式做健康检测 Nacos与Eureka的区别 Nacos支持服务端主动检测提供者状态：临时实例采用心跳模式，非临时实例采用主动检测模式 临时实例心跳不正常会被剔除，非临时实例则不会被剔除 Nacos支持服务列表变更的消息推送模式，服务列表更新更及时 Nacos集群默认采用AP方式，当集群中存在非临时实例时，采用CP模式；Eureka采用AP方式 6.Nacos配置管理Nacos除了可以做注册中心，同样可以做配置管理来使用。 6.1.统一配置管理当微服务部署的实例越来越多，达到数十、数百时，逐个修改微服务配置就会让人抓狂，而且很容易出错。我们需要一种统一配置管理方案，可以集中管理所有实例的配置。 Nacos一方面可以将配置集中管理，另一方可以在配置变更时，及时通知微服务，实现配置的热更新。 6.1.1.在nacos中添加配置文件如何在nacos中管理配置呢？ 然后在弹出的表单中，填写配置信息： 注意：项目的核心配置，需要热更新的配置才有放到nacos管理的必要。基本不会变更的一些配置还是保存在微服务本地比较好。 6.1.2.从微服务拉取配置微服务要拉取nacos中管理的配置，并且与本地的application.yml配置合并，才能完成项目启动。 但如果尚未读取application.yml，又如何得知nacos地址呢？ 因此spring引入了一种新的配置文件：bootstrap.yaml文件，会在application.yml之前被读取，流程如下： 1）引入nacos-config依赖 首先，在user-service服务中，引入nacos-config的客户端依赖： &lt;!--nacos配置管理依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-config&lt;/artifactId&gt; &lt;/dependency&gt; 2）添加bootstrap.yaml 然后，在user-service中添加一个bootstrap.yaml文件，内容如下： spring: application: name: userservice # 服务名称 profiles: active: dev #开发环境，这里是dev cloud: nacos: server-addr: localhost:8848 # Nacos地址 config: file-extension: yaml # 文件后缀名 这里会根据spring.cloud.nacos.server-addr获取nacos地址，再根据 ${spring.application.name}-${spring.profiles.active}.${spring.cloud.nacos.config.file-extension}作为文件id，来读取配置。 本例中，就是去读取userservice-dev.yaml： 3）读取nacos配置 在user-service中的UserController中添加业务逻辑，读取pattern.dateformat配置： 完整代码： package cn.itcast.user.web; import cn.itcast.user.pojo.User; import cn.itcast.user.service.UserService; import lombok.extern.slf4j.Slf4j; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.beans.factory.annotation.Value; import org.springframework.web.bind.annotation.*; import java.time.LocalDateTime; import java.time.format.DateTimeFormatter; @Slf4j @RestController @RequestMapping(\"/user\") public class UserController { @Autowired private UserService userService; @Value(\"${pattern.dateformat}\") private String dateformat; @GetMapping(\"now\") public String now(){ return LocalDateTime.now().format(DateTimeFormatter.ofPattern(dateformat)); } // ...略 } 在页面访问，可以看到效果： 6.2.配置热更新我们最终的目的，是修改nacos中的配置后，微服务中无需重启即可让配置生效，也就是配置热更新。 要实现配置热更新，可以使用两种方式： 6.2.1.方式一在@Value注入的变量所在类上添加注解@RefreshScope： 6.2.2.方式二使用@ConfigurationProperties注解代替@Value注解。 在user-service服务中，添加一个类，读取patterrn.dateformat属性： package cn.itcast.user.config; import lombok.Data; import org.springframework.boot.context.properties.ConfigurationProperties; import org.springframework.stereotype.Component; @Component @Data @ConfigurationProperties(prefix = \"pattern\") public class PatternProperties { private String dateformat; } 在UserController中使用这个类代替@Value： 完整代码： package cn.itcast.user.web; import cn.itcast.user.config.PatternProperties; import cn.itcast.user.pojo.User; import cn.itcast.user.service.UserService; import lombok.extern.slf4j.Slf4j; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.PathVariable; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.RestController; import java.time.LocalDateTime; import java.time.format.DateTimeFormatter; @Slf4j @RestController @RequestMapping(\"/user\") public class UserController { @Autowired private UserService userService; @Autowired private PatternProperties patternProperties; @GetMapping(\"now\") public String now(){ return LocalDateTime.now().format(DateTimeFormatter.ofPattern(patternProperties.getDateformat())); } // 略 } 6.3.配置共享其实微服务启动时，会去nacos读取多个配置文件，例如： [spring.application.name]-[spring.profiles.active].yaml，例如：userservice-dev.yaml [spring.application.name].yaml，例如：userservice.yaml 而[spring.application.name].yaml不包含环境，因此可以被多个环境共享。 下面我们通过案例来测试配置共享 1）添加一个环境共享配置我们在nacos中添加一个userservice.yaml文件： 2）在user-service中读取共享配置在user-service服务中，修改PatternProperties类，读取新添加的属性： 在user-service服务中，修改UserController，添加一个方法： 3）运行两个UserApplication，使用不同的profile修改UserApplication2这个启动项，改变其profile值： 这样，UserApplication(8081)使用的profile是dev，UserApplication2(8082)使用的profile是test。 启动UserApplication和UserApplication2 访问http://localhost:8081/user/prop，结果： 访问http://localhost:8082/user/prop，结果： 可以看出来，不管是dev，还是test环境，都读取到了envSharedValue这个属性的值。 4）配置共享的优先级当nacos、服务本地同时出现相同属性时，优先级有高低之分：","categories":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://bowonqin.github.io/categories/SpringCloud/"}],"tags":[{"name":"服务消息治理","slug":"服务消息治理","permalink":"https://bowonqin.github.io/tags/%E6%9C%8D%E5%8A%A1%E6%B6%88%E6%81%AF%E6%B2%BB%E7%90%86/"}],"author":"qxd"},{"title":"mongoDB快速入门","slug":"mongoDB/mongodb快速入门","date":"2022-03-14T12:01:33.000Z","updated":"2022-03-14T12:17:37.481Z","comments":true,"path":"posts/mongodb-kuai-su-ru-men.html","link":"","permalink":"https://bowonqin.github.io/posts/mongodb-kuai-su-ru-men.html","excerpt":"","text":"MongoDB快速上手本文为黑马程序员MongoDB学习笔记，相关视频为黑马MongoDB 1. MongoDB相关概念1.1 业务场景传统的关系型数据库（如MySQL），在数据操作的“三高”需求以及应对Web2.0的网站需求面前，显得力不从心。 解释： “三高”需求： • High performance - 对数据库高并发读写的需求。 • Huge Storage - 对海量数据的高效率存储和访问的需求。 • High Scalability &amp;&amp; High Availability- 对数据库的高可扩展性和高可用性的需求。 而MongoDB可应对三高需求。 具体的应用场景如： 1）社交场景，使用 MongoDB 存储存储用户信息，以及用户发表的朋友圈信息，通过地理位置索引实现附近的人、地点等功能。 2）游戏场景，使用 MongoDB 存储游戏用户信息，用户的装备、积分等直接以内嵌文档的形式存储，方便查询、高效率存储和访问。 3）物流场景，使用 MongoDB 存储订单信息，订单状态在运送过程中会不断更新，以 MongoDB 内嵌数组的形式来存储，一次查询就能将 订单所有的变更读取出来。 4）物联网场景，使用 MongoDB 存储所有接入的智能设备信息，以及设备汇报的日志信息，并对这些信息进行多维度的分析。 5）视频直播，使用 MongoDB 存储用户信息、点赞互动信息等。 这些应用场景中，数据操作方面的共同特点是： （1）数据量大 （2）写入操作频繁（读写都很频繁） （3）价值较低的数据，对事务性要求不高 对于这样的数据，我们更适合使用MongoDB来实现数据的存储 什么时候选择MongoDB? 在架构选型上，除了上述的三个特点外，如果你还犹豫是否要选择它？可以考虑以下的一些问题： 应用不需要事务及复杂 join 支持 新应用，需求会变，数据模型无法确定，想快速迭代开发 应用需要2000-3000以上的读写QPS（更高也可以） 应用需要TB甚至 PB 级别数据存储 应用发展迅速，需要能快速水平扩展 应用要求存储的数据不丢失 应用需要99.999%高可用 应用需要大量的地理位置查询、文本查询 如果上述有1个符合，可以考虑 MongoDB，2个及以上的符合，选择 MongoDB 绝不会后悔。 思考：如果用MySQL呢？ 答：相对MySQL，可以以更低的成本解决问题（包括学习、开发、运维等成本） 1.2 MongoDB简介MongoDB是一个开源、高性能、无模式的文档型数据库，当初的设计就是用于简化开发和方便扩展，是NoSQL数据库产品中的一种。是最 像关系型数据库（MySQL）的非关系型数据库。 它支持的数据结构非常松散，是一种类似于 JSON 的 格式叫BSON，所以它既可以存储比较复杂的数据类型，又相当的灵活。 MongoDB中的记录是一个文档，它是一个由字段和值对（fifield:value）组成的数据结构。MongoDB文档类似于JSON对象，即一个文档认 为就是一个对象。字段的数据类型是字符型，它的值除了使用基本的一些类型外，还可以包括其他文档、普通数组和文档数组。 1.3 体系结构MySQL和MongoDB对比 1.4 数据模型MongoDB的最小存储单位就是文档(document)对象。文档(document)对象对应于关系型数据库的行。数据在MongoDB中以 BSON（Binary-JSON）文档的格式存储在磁盘上。 BSON（Binary Serialized Document Format）是一种类json的一种二进制形式的存储格式，简称Binary JSON。BSON和JSON一样，支持内嵌的文档对象和数组对象，但是BSON有JSON没有的一些数据类型，如Date和BinData类型。 BSON采用了类似于 C 语言结构体的名称、对表示方法，支持内嵌的文档对象和数组对象，具有轻量性、可遍历性、高效性的三个特点，可以有效描述非结构化数据和结构化数据。这种格式的优点是灵活性高，但它的缺点是空间利用率不是很理想。 Bson中，除了基本的JSON类型：string,integer,boolean,double,null,array和object，mongo还使用了特殊的数据类型。这些类型包括date,object id,binary data,regular expression 和code。每一个驱动都以特定语言的方式实现了这些类型，查看你的驱动的文档来获取详细信息。 BSON数据类型参考列表： 提示： shell默认使用64位浮点型数值。{“x”：3.14}或{“x”：3}。对于整型值，可以使用NumberInt（4字节符号整数）或NumberLong（8字节符号整数），{“x”:NumberInt(“3”)}{“x”:NumberLong(“3”)} 1.5 MongoDB的特点MongoDB主要有如下特点： （1）高性能： MongoDB提供高性能的数据持久性。特别是,对嵌入式数据模型的支持减少了数据库系统上的I/O活动。 索引支持更快的查询，并且可以包含来自嵌入式文档和数组的键。（文本索引解决搜索的需求、TTL索引解决历史数据自动过期的需求、地理位置索引可用于构建各种 O2O 应用） mmapv1、wiredtiger、mongorocks（rocksdb）、in-memory 等多引擎支持满足各种场景需求。 Gridfs解决文件存储的需求。 （2）高可用性： MongoDB的复制工具称为副本集（replica set），它可提供自动故障转移和数据冗余。 （3）高扩展性： MongoDB提供了水平可扩展性作为其核心功能的一部分。分片将数据分布在一组集群的机器上。（海量数据存储，服务能力水平扩展）从3.4开始，MongoDB支持基于片键创建数据区域。在一个平衡的集群中，MongoDB将一个区域所覆盖的读写只定向到该区域内的那些片。 （4）丰富的查询支持： MongoDB支持丰富的查询语言，支持读和写操作(CRUD)，比如数据聚合、文本搜索和地理空间查询等。 （5）其他特点：如无模式（动态模式）、灵活的文档模型 2. 单机部署2.1 Linux系统安装和连接步骤如下： （1）先到官网下载压缩包 mongod-linux-x86_64-4.0.10.tgz 。 （2）上传压缩包到Linux中，解压到当前目录： tar -xvf mongodb-linux-x86_64-4.0.10.tgz （3）移动解压后的文件夹到指定的目录中： mv mongodb-linux-x86_64-4.0.10 /usr/local/mongodb （4）新建几个目录，分别用来存储数据和日志： #数据存储目录 mkdir -p /mongodb/single/data/db #日志存储目录 mkdir -p /mongodb/single/log （5）新建并修改配置文件 vi /mongodb/single/mongod.conf 配置文件的内容如下： systemLog: #MongoDB发送所有日志输出的目标指定为文件 # #The path of the log file to which mongod or mongos should send all diagnostic logging information destination: file #mongod或mongos应向其发送所有诊断日志记录信息的日志文件的路径 path: \"/mongodb/single/log/mongod.log\" #当mongos或mongod实例重新启动时，mongos或mongod会将新条目附加到现有日志文件的末尾。 logAppend: true storage: #mongod实例存储其数据的目录。storage.dbPath设置仅适用于mongod。 ##The directory where the mongod instance stores its data.Default Value is \"/data/db\". dbPath: \"/mongodb/single/data/db\" journal: #启用或禁用持久性日志以确保数据文件保持有效和可恢复。 enabled: true processManagement: #启用在后台运行mongos或mongod进程的守护进程模式。 fork: true net: #服务实例绑定的IP，默认是localhost bindIp: localhost,192.168.0.2 #bindIp #绑定的端口，默认是27017 port: 27017 （6）启动MongoDB服务 [root@bobohost single]# /usr/local/mongodb/bin/mongod -f /mongodb/single/mongod.conf about to fork child process, waiting until server is ready for connections. forked process: 90384 child process started successfully, parent exiting 注意： 如果启动后不是 successfully ，则是启动失败了。原因基本上就是配置文件有问题。 通过进程来查看服务是否启动了： [root@bobohost single]# ps -ef |grep mongod root 90384 1 0 8月26 ? 00:02:13 /usr/local/mongdb/bin/mongod -f /mongodb/single/mongod.conf （7）分别使用mongo命令和compass工具来连接测试。 #查看防火墙状态 systemctl status firewalld #临时关闭防火墙 systemctl stop firewalld #开机禁止启动防火墙 systemctl disable firewalld （8）停止关闭服务 停止服务的方式有两种：快速关闭和标准关闭，下面依次说明： （一）快速关闭方法（快速，简单，数据可能会出错） 目标：通过系统的kill命令直接杀死进程： 杀完要检查一下，避免有的没有杀掉。 #通过进程编号关闭节点 kill -2 54410 【补充】 如果一旦是因为数据损坏，则需要进行如下操作（了解）： 1）删除lock文件： rm -f /mongodb/single/data/db/*.lock 2）修复数据： /usr/local/mongdb/bin/mongod --repair --dbpath=/mongodb/single/data/db （二）标准的关闭方法（数据不容易出错，但麻烦）： 目标：通过mongo客户端中的shutdownServer命令来关闭服务 主要的操作步骤参考如下: # 客户端登录服务，注意，这里通过localhost登录，如果需要远程登录，必须先登录认证才行。 mongo --port 27017 # 切换到admin库 use admin # 关闭服务 db.shutdownServer() 3. 基本常用命令3.1 案例需求存放文章评论的数据存放到MongoDB中，数据结构参考如下： 数据库：articledb 3.2 数据库操作3.2.1 选择和创建数据库选择和创建数据库的语法格式： use 数据库名称 如果数据库不存在则自动创建，例如，以下语句创建 spitdb 数据库 use articledb 查看有权限查看的所有的数据库命令 show dbs 或 show databases 注意:在 MongoDB 中，集合只有在内容插入后才会创建! 就是说，创建集合(数据表)后要再插入一个文档(记录)，集合才会真正创建。 查看当前正在使用的数据库命令 db MongoDB 中默认的数据库为 test，如果你没有选择数据库，集合将存放在 test 数据库中。 另外： 数据库名可以是满足以下条件的任意UTF-8字符串。 不能是空字符串（””)。 不得含有’ ‘（空格)、.、$、/、\\和\\0 (空字符)。 应全部小写。 最多64字节。 有一些数据库名是保留的，可以直接访问这些有特殊作用的数据库。 admin： 从权限的角度来看，这是”root”数据库。要是将一个用户添加到这个数据库，这个用户自动继承所有数据库的权限。一些特定的服务器端命令也只能从这个数据库运行，比如列出所有的数据库或者关闭服务器。 local: 这个数据永远不会被复制，可以用来存储限于本地单台服务器的任意集合 confifig: 当Mongo用于分片设置时，confifig数据库在内部使用，用于保存分片的相关信息。 3.2.2 数据库的删除MongoDB 删除数据库的语法格式如下： db.dropDatabase() 提示：主要用来删除已经持久化的数据库 3.3 集合操作集合，类似关系型数据库中的表。 可以显示的创建，也可以隐式的创建。 3.3.1 集合的显式创建（了解）基本语法格式： db.createCollection(name) 参数说明： name: 要创建的集合名称 例如：创建一个名为 mycollection 的普通集合。 db.createCollection(\"mycollection\") 查看当前库中的表：show tables命令 show collections 或 show tables 集合的命名规范： 集合名不能是空字符串””。 集合名不能含有\\0字符（空字符)，这个字符表示集合名的结尾。 集合名不能以”system.”开头，这是为系统集合保留的前缀。 用户创建的集合名字不能含有保留字符。有些驱动程序的确支持在集合名里面包含，这是因为某些系统生成的集合中包含该字符。除非你要访问这种系统创建的集合，否则千万不要在名字里出现$。 3.3.2 集合的隐式创建当向一个集合中插入一个文档的时候，如果集合不存在，则会自动创建集合。 详见 文档的插入 章节。 提示：通常我们使用隐式创建文档即可。 3.3.3 集合的删除集合删除语法格式如下： db.collection.drop() 或 db.集合.drop() 返回值 如果成功删除选定集合，则 drop() 方法返回 true，否则返回 false。 例如：要删除mycollection集合 db.mycollection.drop() 3.4 文档基本CRUD文档（document）的数据结构和 JSON 基本一样。 所有存储在集合中的数据都是 BSON 格式 3.4.1 文档的插入（1）单个文档插入 使用insert() 或 save() 方法向集合中插入文档，语法如下： db.collection.insert( &lt;document or array of documents&gt;, { writeConcern: &lt;document&gt;, ordered: &lt;boolean&gt; } ) 参数： 【示例】 要向comment的集合(表)中插入一条测试数据： db.comment.insert({ \"articleid\": \"100000\", \"content\": \"今天天气真好，阳光明 媚\", \"userid\": \"1001\", \"nickname\": \"Rose\", \"createdatetime\": new Date(), \"likenum\": NumberInt(10), \"state\": null }) 提示： 1）comment集合如果不存在，则会隐式创建 2）mongo中的数字，默认情况下是double类型，如果要存整型，必须使用函数NumberInt(整型数字)，否则取出来就有问题了。 3）插入当前日期使用 new Date() 4）插入的数据没有指定 _id ，会自动生成主键值 5）如果某字段没值，可以赋值为null，或不写该字段。 执行后，如下，说明插入一个数据成功了。 WriteResult({ \"nInserted\" : 1 }) 注意： 文档中的键/值对是有序的。 文档中的值不仅可以是在双引号里面的字符串，还可以是其他几种数据类型（甚至可以是整个嵌入的文档)。 MongoDB区分类型和大小写。 MongoDB的文档不能有重复的键。 文档的键是字符串。除了少数例外情况，键可以使用任意UTF-8字符。 文档键命名规范： 键不能含有\\0 (空字符)。这个字符用来表示键的结尾。 .和$有特别的意义，只有在特定环境下才能使用。 以下划线”_”开头的键是保留的(不是严格要求的)。 （2）批量插入 语法： db.collection.insertMany([&lt; document 1 &gt; , &lt; document 2 &gt; , ...], { writeConcern: &lt; document &gt; , ordered: &lt; boolean &gt; }) 参数： 【示例】 批量插入多条文章评论： db.comment.insertMany([{ \"_id\": \"1\", \"articleid\": \"100001\", \"content\": \"我们不应该把清晨浪费在手机上，健康很重要，一杯温水幸福你我 他。\", \"userid\": \"1002\", \"nickname\": \"相忘于江湖\", \"createdatetime\": new Date(\"2019-08- 05T22:08:15.522Z\"), \"likenum\": NumberInt(1000), \"state\": \"1\" }, { \"_id\": \"2\", \"articleid\": \"100001\", \"content\": \"我夏天空腹喝凉开水，冬天喝温开水\", \"userid\": \"1005\", \"nickname\": \"伊人憔 悴\", \"createdatetime\": new Date(\"2019-08-05T23:58:51.485Z\"), \"likenum\": NumberInt(888), \"state\": \"1\" }, { \"_id\": \"3\", \"articleid\": \"100001\", \"content\": \"我一直喝凉开水，冬天夏天都喝。\", \"userid\": \"1004\", \"nickname\": \"杰克船 长\", \"createdatetime\": new Date(\"2019-08-06T01:05:06.321Z\"), \"likenum\": NumberInt(666), \"state\": \"1\" }, { \"_id\": \"4\", \"articleid\": \"100001\", \"content\": \"专家说不能空腹吃饭，影响健康。\", \"userid\": \"1003\", \"nickname\": \"凯 撒\", \"createdatetime\": new Date(\"2019-08-06T08:18:35.288Z\"), \"likenum\": NumberInt(2000), \"state\": \"1\" }, { \"_id\": \"5\", \"articleid\": \"100001\", \"content\": \"研究表明，刚烧开的水千万不能喝，因为烫 嘴。\", \"userid\": \"1003\", \"nickname\": \"凯撒\", \"createdatetime\": new Date(\"2019-08- 06T11:01:02.521Z\"), \"likenum\": NumberInt(3000), \"state\": \"1\" }]); 提示： 插入时指定了 _id ，则主键就是该值。 如果某条数据插入失败，将会终止插入，但已经插入成功的数据不会回滚掉。 因为批量插入由于数据较多容易出现失败，因此，可以使用try catch进行异常捕捉处理，测试的时候可以不处理。如（了解）： try{ db.comment.insertMany([{ \"_id\": \"11\", \"articleid\": \"100001\", \"content\": \"我们不应该把清晨浪费在手机上，健康很重要，一杯温水幸福你我 他。\", \"userid\": \"1002\", \"nickname\": \"相忘于江湖\", \"createdatetime\": new Date(\"2019-08- 05T22:08:15.522Z\"), \"likenum\": NumberInt(1000), \"state\": \"1\" }, { \"_id\": \"2\", \"articleid\": \"100001\", \"content\": \"我夏天空腹喝凉开水，冬天喝温开水\", \"userid\": \"1005\", \"nickname\": \"伊人憔 悴\", \"createdatetime\": new Date(\"2019-08-05T23:58:51.485Z\"), \"likenum\": NumberInt(888), \"state\": \"1\" }, { \"_id\": \"3\", \"articleid\": \"100001\", \"content\": \"我一直喝凉开水，冬天夏天都喝。\", \"userid\": \"1004\", \"nickname\": \"杰克船 长\", \"createdatetime\": new Date(\"2019-08-06T01:05:06.321Z\"), \"likenum\": NumberInt(666), \"state\": \"1\" }, { \"_id\": \"4\", \"articleid\": \"100001\", \"content\": \"专家说不能空腹吃饭，影响健康。\", \"userid\": \"1003\", \"nickname\": \"凯 撒\", \"createdatetime\": new Date(\"2019-08-06T08:18:35.288Z\"), \"likenum\": NumberInt(2000), \"state\": \"1\" }, { \"_id\": \"5\", \"articleid\": \"100001\", \"content\": \"研究表明，刚烧开的水千万不能喝，因为烫 嘴。\", \"userid\": \"1003\", \"nickname\": \"凯撒\", \"createdatetime\": new Date(\"2019-08- 06T11:01:02.521Z\"), \"likenum\": NumberInt(3000), \"state\": \"1\" }]); } catch(e) { print(e); } 3.4.2 文档的基本查询查询数据的语法格式如下 db.collection.find(&lt;query&gt;, [projection]) 参数： 【示例】 （1）查询所有 如果我们要查询spit集合的所有文档，我们输入以下命令 db.comment.find() 或 db.comment.find({}) 这里你会发现每条文档会有一个叫_id的字段，这个相当于我们原来关系数据库中表的主键，当你在插入文档记录时没有指定该字段，MongoDB会自动创建，其类型是ObjectID类型。 如果我们在插入文档记录时指定该字段也可以，其类型可以是ObjectID类型，也可以是MongoDB支持的任意类型。 如果我想按一定条件来查询，比如我想查询userid为1003的记录，怎么办？很简单！只 要在fifind()中添加参数即可，参数也是json格式，如下： db.comment.find({userid:'1003'}) 如果你只需要返回符合条件的第一条数据，我们可以使用fifindOne命令来实现，语法和fifind一样。 如：查询用户编号是1003的记录，但只最多返回符合条件的第一条记录： db.comment.findOne({userid:'1003'}) （2）投影查询（Projection Query）： 如果要查询结果返回部分字段，则需要使用投影查询（不显示所有字段，只显示指定的字段）。 如：查询结果只显示 _id、userid、nickname : db.comment.find({userid:\"1003\"},{userid:1,nickname:1}) 默认 _id 会显示。 如：查询结果只显示 、userid、nickname ，不显示 _id ： db.comment.find({userid:\"1003\"},{userid:1,nickname:1,_id:0}) 再例如：查询所有数据，但只显示 _id、userid、nickname db.comment.find({},{userid:1,nickname:1}) 3.4.3 文档的更新更新文档的语法： db.collection.update(query, update, options) // 或 db.collection.update(&lt; query &gt; , &lt; update &gt; , { upsert: &lt; boolean &gt; , multi: &lt; boolean &gt; , writeConcern: &lt; document &gt; , collation: &lt; document &gt; , arrayFilters: [&lt; filterdocument1 &gt; , ...], hint: &lt; document | string &gt; // Available starting in MongoDB 4.2 } ) 参数： 提示： 主要关注前四个参数即可。 【示例】 （1）覆盖的修改 如果我们想修改_id为1的记录，点赞量为1001，输入以下语句： db.comment.update({_id:\"1\"},{likenum:NumberInt(1001)}) 执行后，我们会发现，这条文档除了likenum字段其它字段都不见了， （2）局部修改 为了解决这个问题，我们需要使用修改器$set来实现，命令如下： 我们想修改_id为2的记录，浏览量为889，输入以下语句： db.comment.update({_id:\"2\"},{$set:{likenum:NumberInt(889)}}) 这样就OK啦。 （3）批量的修改 更新所有用户为 1003 的用户的昵称为 凯撒大帝 。 //默认只修改第一条数据 db.comment.update({userid:\"1003\"},{$set:{nickname:\"凯撒2\"}}) //修改所有符合条件的数据 db.comment.update({userid:\"1003\"},{$set:{nickname:\"凯撒大帝\"}},{multi:true}) 提示：如果不加后面的参数，则只更新符合条件的第一条记录 （4）列值增长的修改 如果我们想实现对某列值在原有值的基础上进行增加或减少，可以使用 $inc 运算符来实现。 需求：对3号数据的点赞数，每次递增1 db.comment.update({_id:\"3\"},{$inc:{likenum:NumberInt(1)}}) 3.4.4 删除文档删除文档的语法结构： db.集合名称.remove(条件) 以下语句可以将数据全部删除，请慎用 db.comment.remove({}) 如果删除_id=1的记录，输入以下语句 db.comment.remove({_id:\"1\"}) 3.5 文档的分页查询3.5.1 统计查询统计查询使用count()方法，语法如下： db.collection.count(query, options) 参数： 提示： 可选项暂时不使用。 【示例】 （1）统计所有记录数： 统计comment集合的所有的记录数： db.comment.count() （2）按条件统计记录数： 例如：统计userid为1003的记录条数 db.comment.count({userid:\"1003\"}) 提示： 默认情况下 count() 方法返回符合条件的全部记录条数。 3.5.2 分页列表查询可以使用limit()方法来读取指定数量的数据，使用skip()方法来跳过指定数量的数据。 基本语法如下所示： db.COLLECTION_NAME.find().limit(NUMBER).skip(NUMBER) 如果你想返回指定条数的记录，可以在fifind方法后调用limit来返回结果(TopN)，默认值20，例如： db.comment.find().limit(3) skip方法同样接受一个数字参数作为跳过的记录条数。（前N个不要）,默认值是0 db.comment.find().skip(3) 分页查询：需求：每页2个，第二页开始：跳过前两条数据，接着值显示3和4条数据 //第一页 db.comment.find().skip(0).limit(2) //第二页 db.comment.find().skip(2).limit(2) //第三页 db.comment.find().skip(4).limit(2) 3.5.3 排序查询sort() 方法对数据进行排序，sort() 方法可以通过参数指定排序的字段，并使用 1 和 -1 来指定排序的方式，其中 1 为升序排列，而 -1 是用于降序排列。 语法如下所示： db.COLLECTION_NAME.find().sort({KEY:1}) 或 db.集合名称.find().sort(排序方式) 例如： 对userid降序排列，并对访问量进行升序排列 db.comment.find().sort({userid:-1,likenum:1}) 提示： skip(), limilt(), sort()三个放在一起执行的时候，执行的顺序是先 sort(), 然后是 skip()，最后是显示的 limit()，和命令编写顺序无关。 3.6 文档的更多查询3.6.1 正则的复杂条件查询MongoDB的模糊查询是通过正则表达式的方式实现的。格式为： db.collection.find({field:/正则表达式/}) 或 db.集合.find({字段:/正则表达式/}) 提示：正则表达式是js的语法，直接量的写法。 例如，我要查询评论内容包含“开水”的所有文档，代码如下： db.comment.find({content:/开水/}) 如果要查询评论的内容中以“专家”开头的，代码如下 db.comment.find({content:/^专家/}) 3.6.2 比较查询&lt;, &lt;=, &gt;, &gt;= 这个操作符也是很常用的，格式如下: db.集合名称.find({ \"field\" : { $gt: value }}) // 大于: field &gt; value db.集合名称.find({ \"field\" : { $lt: value }}) // 小于: field &lt; value db.集合名称.find({ \"field\" : { $gte: value }}) // 大于等于: field &gt;= value db.集合名称.find({ \"field\" : { $lte: value }}) // 小于等于: field &lt;= value db.集合名称.find({ \"field\" : { $ne: value }}) // 不等于: field != value 示例：查询评论点赞数量大于700的记录 db.comment.find({likenum:{$gt:NumberInt(700)}}) 3.6.3 包含查询包含使用$in操作符。 示例：查询评论的集合中userid字段包含1003或1004的文档 db.comment.find({userid:{$in:[\"1003\",\"1004\"]}}) 不包含使用$nin操作符。 示例：查询评论集合中userid字段不包含1003和1004的文档 db.comment.find({userid:{$nin:[\"1003\",\"1004\"]}}) 3.6.4 条件连接查询我们如果需要查询同时满足两个以上条件，需要使用$and操作符将条件进行关联。（相 当于SQL的and） 格式为： $and:[ { },{ },{ } ] 示例：查询评论集合中likenum大于等于700 并且小于2000的文档： db.comment.find({$and:[{likenum:{$gte:NumberInt(700)}},{likenum:{$lt:NumberInt(2000)}}]}) 如果两个以上条件之间是或者的关系，我们使用 操作符进行关联，与前面 and的使用方式相同 格式为： $or:[ { },{ },{ } ] 示例：查询评论集合中userid为1003，或者点赞数小于1000的文档记录 db.comment.find({$or:[ {userid:\"1003\"} ,{likenum:{$lt:1000} }]}) 3.7 常用命令小结选择切换数据库：use articledb 插入数据：db.comment.insert({bson数据}) 查询所有数据：db.comment.find(); 条件查询数据：db.comment.find({条件}) 查询符合条件的第一条记录：db.comment.findOne({条件}) 查询符合条件的前几条记录：db.comment.find({条件}).limit(条数) 查询符合条件的跳过的记录：db.comment.find({条件}).skip(条数) 修改数据：db.comment.update({条件},{修改后的数据}) 或db.comment.update({条件},{$set:{要修改部分的字段:数据}) 修改数据并自增某字段值：db.comment.update({条件},{$inc:{自增的字段:步进值}}) 删除数据：db.comment.remove({条件}) 统计查询：db.comment.count({条件}) 模糊查询：db.comment.find({字段名:/正则表达式/}) 条件比较运算：db.comment.find({字段名:{$gt:值}}) 包含查询：db.comment.find({字段名:{$in:[值1，值2]}})或db.comment.find({字段名:{$nin:[值1，值2]}}) 条件连接查询：db.comment.find({$and:[{条件1},{条件2}]})或db.comment.find({$or:[{条件1},{条件2}]}) 4. 索引-Index4.1 概述索引支持在MongoDB中高效地执行查询。如果没有索引，MongoDB必须执行全集合扫描，即扫描集合中的每个文档，以选择与查询语句匹配的文档。这种扫描全集合的查询效率是非常低的，特别在处理大量的数据时，查询可以要花费几十秒甚至几分钟，这对网站的性能是非常致命的。 如果查询存在适当的索引，MongoDB可以使用该索引限制必须检查的文档数。 索引是特殊的数据结构，它以易于遍历的形式存储集合数据集的一小部分。索引存储特定字段或一组字段的值，按字段值排序。索引项的排序支持有效的相等匹配和基于范围的查询操作。此外，MongoDB还可以使用索引中的排序返回排序结果。 官网文档：https://docs.mongodb.com/manual/indexes/ 了解： MongoDB索引使用B树数据结构（确切的说是B-Tree，MySQL是B+Tree） 4.2 索引类型4.2.1 单字段索引MongoDB支持在文档的单个字段上创建用户定义的升序/降序索引，称为单字段索引（Single Field Index）。 对于单个字段索引和排序操作，索引键的排序顺序（即升序或降序）并不重要，因为MongoDB可以在任何方向上遍历索引。 4.2.2 复合索引MongoDB还支持多个字段的用户定义索引，即复合索引（Compound Index）。 复合索引中列出的字段顺序具有重要意义。例如，如果复合索引由 { userid: 1, score: -1 } 组成，则索引首先按userid正序排序，然后在每个userid的值内，再在按score倒序排序。 4.2.3 其他索引地理空间索引（Geospatial Index）、文本索引（Text Indexes）、哈希索引（Hashed Indexes）。 地理空间索引（Geospatial Index） 为了支持对地理空间坐标数据的有效查询，MongoDB提供了两种特殊的索引：返回结果时使用平面几何的二维索引和返回结果时使用球面几何的二维球面索引。 文本索引（Text Indexes） MongoDB提供了一种文本索引类型，支持在集合中搜索字符串内容。这些文本索引不存储特定于语言的停止词（例如“the”、“a”、“or”），而将集合中的词作为词干，只存储根词。 哈希索引（Hashed Indexes） 为了支持基于散列的分片，MongoDB提供了散列索引类型，它对字段值的散列进行索引。这些索引在其范围内的值分布更加随机，但只支持相等匹配，不支持基于范围的查询。 4.3 索引的管理操作4.3.1 索引的查看说明： 返回一个集合中的所有索引的数组。 语法： db.collection.getIndexes() 提示：该语法命令运行要求是MongoDB 3.0+ 【示例】 查看comment集合中所有的索引情况 db.comment.getIndexes()[{ \"v\": 2, \"key\": { \"_id\": 1 }, \"name\": \"_id_\", \"ns\": \"articledb.comment\" } 结果中显示的是默认 _id 索引。 默认_id索引： MongoDB在创建集合的过程中，在 _id 字段上创建一个唯一的索引，默认名字为 id ，该索引可防止客户端插入两个具有相同值的文档，您不能在_id字段上删除此索引。 注意：该索引是唯一索引，因此值不能重复，即 _id 值不能重复的。在分片集群中，通常使用 _id 作为片键。 4.3.2 索引的创建说明： 在集合上创建索引。 语法： db.collection.createIndex(keys, options) 参数： options（更多选项）列表： 提示： 注意在 3.0.0 版本前创建索引方法为 db.collection.ensureIndex() ，之后的版本使用了 db.collection.createIndex() 方法，ensureIndex() 还能用，但只是 createIndex() 的别名。 【示例】 （1）单字段索引示例：对 userid 字段建立索引： db.comment.createIndex({userid:1}) 参数1：按升序创建索引 可以查看一下： db.comment.getIndexes() （2）复合索引：对 userid 和 nickname 同时建立复合（Compound）索引： db.comment.createIndex({userid:1,nickname:-1}) 4.3.3 索引的移除说明：可以移除指定的索引，或移除所有索引 一、指定索引的移除 语法: db.collection.dropIndex(index) 参数： 【示例】 删除 comment 集合中 userid 字段上的升序索引： db.comment.dropIndex({userid:1}) 查看已经删除了。 二、所有索引的移除 语法： db.collection.dropIndexes() 【示例】 删除 spit 集合中所有索引。 db.comment.dropIndexes() 提示： _id 的字段的索引是无法删除的，只能删除非 _id 字段的索引。 4.4 索引的使用4.4.1 执行计划分析查询性能（Analyze Query Performance）通常使用执行计划（解释计划、Explain Plan）来查看查询的情况，如查询耗费的时间、是否基于索引查询等。 那么，通常，我们想知道，建立的索引是否有效，效果如何，都需要通过执行计划查看。 语法： db.collection.find(query,options).explain(options) 【示例】 查看根据userid查询数据的情况： db.comment.find({userid:\"1003\"}).explain() 关键点看： “stage” : “COLLSCAN”, 表示全集合扫描 下面对userid建立索引 db.comment.createIndex({userid:1}) 再次查看执行计划： db.comment.find({userid:\"1013\"}).explain() 关键点看： “stage” : “IXSCAN” ,基于索引的扫描 4.4.2 涵盖的查询Covered Queries 当查询条件和查询的投影仅包含索引字段时，MongoDB直接从索引返回结果，而不扫描任何文档或将文档带入内存。 这些覆盖的查询可以非常有效 更多：https://docs.mongodb.com/manual/core/query-optimization/#read-operations-covered-query 【示例】 db.comment.find({userid:\"1003\"},{userid:1,_id:0}) db.comment.find({userid:\"1003\"},{userid:1,_id:0}).explain() 类似MySQL中的覆盖索引 5. 文章评论5.1 需求分析某头条的文章评论业务如下： 文章示例参考：早晨空腹喝水，是对还是错？https://www.toutiao.com/a6721476546088927748/ 需要实现以下功能： 1）基本增删改查API 2）根据文章id查询评论 3）评论点赞 5.2 表结构分析数据库：articledb 5.3 文章微服务模块搭建(1) 搭建项目工程article，pom.xml引入依赖： &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.1.6.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;groupId&gt;cn.itcast&lt;/groupId&gt; &lt;artifactId&gt;article&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-mongodb&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/project&gt; （2）创建application.yml spring: #数据源配置 data: mongodb: # 主机地址 host: 180.76.159.126 # 数据库 database: articledb # 默认端口是27017 port: 27017 #也可以使用uri连接 # uri: mongodb://192.168.40.134:27017/articledb （3）创建启动类 cn.itcast.article.ArticleApplication @SpringBootApplication public class ArticleApplication { public static void main(String[] args) { SpringApplication.run(ArticleApplication.class, args); } } （4）启动项目，看是否能正常启动，控制台没有错误。 5.4 文章评论实体类编写创建实体类 创建包cn.itcast.article，包下建包po用于存放实体类，创建实体类 cn.itcast.article.po.Comment package cn.itcast.article.po; import org.springframework.data.annotation.Id; import org.springframework.data.mongodb.core.index.CompoundIndex; import org.springframework.data.mongodb.core.index.Indexed; import org.springframework.data.mongodb.core.mapping.Document; import org.springframework.data.mongodb.core.mapping.Field; import java.io.Serializable; import java.time.LocalDateTime; import java.util.Date; /** * 文章评论实体类 */ //把一个java类声明为mongodb的文档，可以通过collection参数指定这个类对应的文档。 //@Document(collection=\"mongodb 对应 collection 名\") // 若未加 @Document ，该 bean save 到 mongo 的 comment collection // 若添加 @Document ，则 save 到 comment collection @Document(collection=\"comment\")//可以省略，如果省略，则默认使用类名小写映射集合 //复合索引 @CompoundIndex( def = \"{'userid': 1, 'nickname': -1}\") public class Comment implements Serializable { //主键标识，该属性的值会自动对应mongodb的主键字段\"_id\"，如果该属性名就叫“id”,则该注解可以省略，否则必须写 // @Id private String id;//主键 //该属性对应mongodb的字段的名字，如果一致，则无需该注解 @Field(\"content\") private String content;//吐槽内容 private Date publishtime;//发布日期 //添加了一个单字段的索引 @Indexed private String userid;//发布人ID private String nickname;//昵称 private LocalDateTime createdatetime;//评论的日期时间 private Integer likenum;//点赞数 private Integer replynum;//回复数 private String state;//状态 private String parentid;//上级ID private String articleid; //getter and setter..... public String getId() { return id; } public void setId(String id) { this.id = id; } public String getContent() { return content; } public void setContent(String content) { this.content = content; } public Date getPublishtime() { return publishtime; } public void setPublishtime(Date publishtime) { this.publishtime = publishtime; } public String getUserid() { return userid; } public void setUserid(String userid) { this.userid = userid; } public String getNickname() { return nickname; } public void setNickname(String nickname) { this.nickname = nickname; } public LocalDateTime getCreatedatetime() { return createdatetime; } public void setCreatedatetime(LocalDateTime createdatetime) { this.createdatetime = createdatetime; } public Integer getLikenum() { return likenum; } public void setLikenum(Integer likenum) { this.likenum = likenum; } public Integer getReplynum() { return replynum; } public void setReplynum(Integer replynum) { this.replynum = replynum; } public String getState() { return state; } public void setState(String state) { this.state = state; } public String getParentid() { return parentid; } public void setParentid(String parentid) { this.parentid = parentid; } public String getArticleid() { return articleid; } public void setArticleid(String articleid) { this.articleid = articleid; } @Override public String toString() { return \"Comment{\" + \"id='\" + id + '\\'' + \", content='\" + content + '\\'' + \", publishtime=\" + publishtime + \", userid='\" + userid + '\\'' + \", nickname='\" + nickname + '\\'' + \", createdatetime=\" + createdatetime + \", likenum=\" + likenum + \", replynum=\" + replynum + \", state='\" + state + '\\'' + \", parentid='\" + parentid + '\\'' + \", articleid='\" + articleid + '\\'' + '}'; } } 说明： 索引可以大大提升查询效率，一般在查询字段上添加索引，索引的添加可以通过Mongo的命令来添加，也可以在Java的实体类中通过注解添加。 1）单字段索引注解@Indexed org.springframework.data.mongodb.core.index.Indexed.class 声明该字段需要索引，建索引可以大大的提高查询效率。 Mongo命令参考： db.comment.createIndex({\"userid\":1}) 2）复合索引注解@CompoundIndex org.springframework.data.mongodb.core.index.CompoundIndex.class 复合索引的声明，建复合索引可以有效地提高多字段的查询效率。 Mongo命令参考： db.comment.createIndex({\"userid\":1,\"nickname\":-1}) 5.5 接口逻辑编写（1）创建数据访问接口 cn.itcast.article包下创建dao包，包下创建接口 cn.itcast.article.dao.CommentRepository package cn.itcast.article.dao; import cn.itcast.article.po.Comment; import org.springframework.data.domain.Page; import org.springframework.data.domain.Pageable; import org.springframework.data.mongodb.repository.MongoRepository; public interface CommentRepository extends MongoRepository&lt;Comment, String&gt; { Page&lt;Comment&gt; findByParentid(String parentid, Pageable pageable); } （2）创建业务逻辑类 cn.itcast.article包下创建service包，包下创建类 cn.itcast.article.service.CommentService package cn.itcast.article.service; import cn.itcast.article.dao.CommentRepository; import cn.itcast.article.po.Comment; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.data.domain.Page; import org.springframework.data.domain.PageRequest; import org.springframework.data.domain.Pageable; import org.springframework.data.mongodb.core.MongoTemplate; import org.springframework.data.mongodb.core.query.Criteria; import org.springframework.data.mongodb.core.query.Query; import org.springframework.data.mongodb.core.query.Update; import org.springframework.stereotype.Service; import java.util.List; @Service public class CommentService { @Autowired private CommentRepository commentRepository; @Autowired private MongoTemplate mongoTemplate; /** * 保存一个评论 * @param comment */ public void saveComment(Comment comment){ //如果需要自定义主键，可以在这里指定主键；如果不指定主键，MongoDB会自动生成主键 //设置一些默认初始值。。。 //调用dao commentRepository.save(comment); } /** * 更新评论 * @param comment */ public void updateComment(Comment comment){ //调用dao commentRepository.save(comment); } /** * 根据id删除评论 * @param id */ public void deleteCommentById(String id){ //调用dao commentRepository.deleteById(id); } /** * 查询所有评论 * @return */ public List&lt;Comment&gt; findCommentList(){ //调用dao return commentRepository.findAll(); } /** * 根据id查询评论 * @param id * @return */ public Comment findCommentById(String id){ //调用dao return commentRepository.findById(id).get(); } public Page&lt;Comment&gt; findCommentListByParentid(String parentid,int page,int size) { return commentRepository.findByParentid(parentid,PageRequest.of(page-1,size)); } public void updateCommentLikenum(String id){ // 查询条件 Query query = Query.query(Criteria.where(\"_id\").is(id)); // 更新条件 Update update = new Update(); update.inc(\"likenum\"); mongoTemplate.updateFirst(query,update,Comment.class); } } （3）新建Junit测试类，测试保存和查询所有： cn.itcast.article.service.CommentServiceTest package cn.itcast.article.service; import cn.itcast.article.po.Comment; import org.junit.Test; import org.junit.runner.RunWith; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.boot.test.context.SpringBootTest; import org.springframework.data.domain.Page; import org.springframework.test.context.junit4.SpringRunner; import java.time.LocalDateTime; import java.util.List; @RunWith(SpringRunner.class) @SpringBootTest public class CommentServiceTest { @Autowired private CommentService commentService; @Test public void testFindCommentList() { List&lt;Comment&gt; commentList = commentService.findCommentList(); System.out.println(commentList); } @Test public void testFindCommentById() { Comment commentById = commentService.findCommentById(\"1\"); System.out.println(commentById); } @Test public void testSaveComment(){ Comment comment=new Comment(); comment.setArticleid(\"100000\"); comment.setContent(\"测试添加的数据\"); comment.setCreatedatetime(LocalDateTime.now()); comment.setUserid(\"1003\"); comment.setNickname(\"凯撒大帝\"); comment.setState(\"1\"); comment.setLikenum(0); comment.setReplynum(0); commentService.saveComment(comment); } @Test public void testFindCommentListByParentid() { Page&lt;Comment&gt; page = commentService.findCommentListByParentid(\"3\", 1, 2); System.out.println(page.getTotalElements()); System.out.println(page.getContent()); } @Test public void testUpdateCommentLikenum() { commentService.updateCommentLikenum(\"1\"); } }","categories":[{"name":"mongoDB","slug":"mongoDB","permalink":"https://bowonqin.github.io/categories/mongoDB/"}],"tags":[{"name":"数据库","slug":"数据库","permalink":"https://bowonqin.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"NoSql","slug":"NoSql","permalink":"https://bowonqin.github.io/tags/NoSql/"},{"name":"mongoDB","slug":"mongoDB","permalink":"https://bowonqin.github.io/tags/mongoDB/"}],"author":"qxd"},{"title":"Redis实践篇","slug":"redis/redis实践","date":"2022-03-13T10:01:33.000Z","updated":"2022-03-13T05:29:37.814Z","comments":true,"path":"posts/redis-shi-jian-pian.html","link":"","permalink":"https://bowonqin.github.io/posts/redis-shi-jian-pian.html","excerpt":"","text":"","categories":[{"name":"Redis","slug":"Redis","permalink":"https://bowonqin.github.io/categories/Redis/"}],"tags":[{"name":"数据库","slug":"数据库","permalink":"https://bowonqin.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"Redis","slug":"Redis","permalink":"https://bowonqin.github.io/tags/Redis/"},{"name":"NoSql","slug":"NoSql","permalink":"https://bowonqin.github.io/tags/NoSql/"}],"author":"qxd"},{"title":"Redis基础篇","slug":"redis/redis基础","date":"2022-03-13T02:01:33.000Z","updated":"2022-03-13T06:05:12.463Z","comments":true,"path":"posts/redis-ji-chu-pian.html","link":"","permalink":"https://bowonqin.github.io/posts/redis-ji-chu-pian.html","excerpt":"","text":"Redis基础本文笔记为黑马程序员听课笔记，b站网址为: 黑马程序员-redis 1. Redis快速入门1.1 初识Redis1.2 认识NoSQL SQL NoSQL 数据结构 结构化（Structured） 非结构化 数据关联 关联的（Relational） 无关联的 查询方式 SQL查询 非SQL 事务特性 ACID BASE 1.3 认识RedisRedis诞生于2009年全称是Remote Dictionary Server，远程词典服务器，是一个基于内存的键值型NoSQL数据库。 特征： 键值（key-value）型，value支持多种不同数据结构，功能丰富 单线程，每个命令具备原子性 低延迟，速度快（基于内存、IO多路复用、良好的编码）。 支持数据持久化 支持主从集群、分片集群 支持多语言客户端 2. Redis常见命令2.1 Redis数据结构介绍Redis是一个key-value的数据库，key一般是String类型，不过value的类型多种多样： ​ Redis为了方便我们学习，将操作不同数据类型的命令也做了分组，在官网（ https://redis.io/commands ）可以查看到不同的命令 ​ 2.2 Redis通用命令通用指令是部分数据类型的，都可以使用的指令，常见的有： KEYS：查看符合模板的所有key DEL：删除一个指定的key EXISTS：判断key是否存在 EXPIRE：给一个key设置有效期，有效期到期时该key会被自动删除 TTL：查看一个KEY的剩余有效期 通过help [command] 可以查看一个命令的具体用法，例如： 2.3 String类型String类型，也就是字符串类型，是Redis中最简单的存储类型。 其value是字符串，不过根据字符串的格式不同，又可以分为3类： string：普通字符串 int：整数类型，可以做自增、自减操作 float：浮点类型，可以做自增、自减操作 不管是哪种格式，底层都是字节数组形式存储，只不过是编码方式不同。字符串类型的最大空间不能超过512m. KEY VALUE msg hello world num 10 score 92.5 String的常见命令有： SET：添加或者修改已经存在的一个String类型的键值对 GET：根据key获取String类型的value MSET：批量添加多个String类型的键值对 MGET：根据多个key获取多个String类型的value INCR：让一个整型的key自增1 INCRBY:让一个整型的key自增并指定步长，例如：incrby num 2 让num值自增2 INCRBYFLOAT：让一个浮点类型的数字自增并指定步长 SETNX：添加一个String类型的键值对，前提是这个key不存在，否则不执行 SETEX：添加一个String类型的键值对，并且指定有效期 思考： Redis没有类似MySQL中的Table的概念，我们该如何区分不同类型的key呢？ 例如，需要存储用户、商品信息到redis，有一个用户id是1，有一个商品id恰好也是1 Redis的key允许有多个单词形成层级结构，多个单词之间用’:’隔开，格式如下： 这个格式并非固定，也可以根据自己的需求来删除或添加词条。例如我们的项目名称叫 heima，有user和product两种不同类型的数据，我们可以这样定义key： user相关的key：heima:user:1 product相关的key：heima:product:1 如果Value是一个Java对象，例如一个User对象，则可以将对象序列化为JSON字符串后存储： KEY VALUE heima:user:1 {“id”:1, “name”: “Jack”, “age”: 21} heima:product:1 {“id”:1, “name”: “小米11”, “price”: 4999} 2.4 Hash类型Hash类型，也叫散列，其value是一个无序字典，类似于Java中的HashMap结构。 String结构是将对象序列化为JSON字符串后存储，当需要修改对象某个字段时很不方便： KEY VALUE heima:user:1 {name:”Jack”, age:21} heima:user:2 {name:”Rose”, age:18} Hash结构可以将对象中的每个字段独立存储，可以针对单个字段做CRUD： KEY VALUE VALUE field value heima:user:1 name Jack heima:user:1 age 21 heima:user:2 name Rose heima:user:2 age 18 Hash的常见命令有： HSET key field value：添加或者修改hash类型key的field的值 HGET key field：获取一个hash类型key的field的值 HMSET：批量添加多个hash类型key的field的值 HMGET：批量获取多个hash类型key的field的值 HGETALL：获取一个hash类型的key中的所有的field和value HKEYS：获取一个hash类型的key中的所有的field HVALS：获取一个hash类型的key中的所有的value HINCRBY:让一个hash类型key的字段值自增并指定步长 HSETNX：添加一个hash类型的key的field值，前提是这个field不存在，否则不执行 2.5 List类型Redis中的List类型与Java中的LinkedList类似，可以看做是一个双向链表结构。既可以支持正向检索和也可以支持反向检索。特征也与LinkedList类似： 有序 元素可以重复 插入和删除快 查询速度一般 常用来存储一个有序数据，例如：朋友圈点赞列表，评论列表等。 List的常见命令有： LPUSH key element … ：向列表左侧插入一个或多个元素 LPOP key：移除并返回列表左侧的第一个元素，没有则返回nil RPUSH key element … ：向列表右侧插入一个或多个元素 RPOP key：移除并返回列表右侧的第一个元素 LRANGE key star end：返回一段角标范围内的所有元素 BLPOP和BRPOP：与LPOP和RPOP类似，只不过在没有元素时等待指定时间，而不是直接返回nil 思考： 如何利用List结构模拟一个栈?入口和出口在同一边 如何利用List结构模拟一个队列?入口和出口在不同边 如何利用List结构模拟一个阻塞队列?入口和出口在不同边出队时采用BLPOP或BRPOP 2.6 Set类型Redis的Set结构与Java中的HashSet类似，可以看做是一个value为null的HashMap。因为也是一个hash表，因此具备与HashSet类似的特征： 无序 元素不可重复 查找快 支持交集、并集、差集等功能 Set的常见命令有： SADD key member … ：向set中添加一个或多个元素 SREM key member … : 移除set中的指定元素 SCARD key： 返回set中元素的个数 SISMEMBER key member：判断一个元素是否存在于set中 SMEMBERS：获取set中的所有元素 SINTER key1 key2 … ：求key1与key2的交集 案例：Set命令的练习 将下列数据用Redis的Set集合来存储： 张三的好友有：李四、王五、赵六 127.0.0.1:6379&gt; sadd zhangsan lisi wangwu zhaoliu 李四的好友有：王五、麻子、二狗 127.0.0.1:6379&gt; sadd lisi wangwu mazi ergou 利用Set的命令实现下列功能： 计算张三的好友有几人 127.0.0.1:6379&gt; SCARD zhangsan 计算张三和李四有哪些共同好友 127.0.0.1:6379&gt; SINTER zhangsan lisi --- 1) \"wangwu\" 查询哪些人是张三的好友却不是李四的好友 127.0.0.1:6379&gt; SDIFF zhangsan lisi --- 1) \"zhaoliu\" 2) \"lisi\" 查询张三和李四的好友总共有哪些人 127.0.0.1:6379&gt; sunion zhangsan lisi --- 1) \"wangwu\" 2) \"zhaoliu\" 3) \"mazi\" 4) \"lisi\" 5) \"ergou\" 判断李四是否是张三的好友 127.0.0.1:6379&gt; SISMEMBER zhangsan lisi --- (integer) 1 判断张三是否是李四的好友 127.0.0.1:6379&gt; SISMEMBER lisi zhangsan --- (integer) 0 将李四从张三的好友列表中移除 127.0.0.1:6379&gt; SREM zhangsan lisi1 (integer) 0 127.0.0.1:6379&gt; SMEMBERS zhangsan 1) \"wangwu\" 2) \"zhaoliu\" 2.7 SortedSet类型Redis的SortedSet是一个可排序的set集合，与Java中的TreeSet有些类似，但底层数据结构却差别很大。SortedSet中的每一个元素都带有一个score属性，可以基于score属性对元素排序，底层的实现是一个跳表（SkipList）加 hash表。 SortedSet具备下列特性： 可排序 元素不重复 查询速度快 因为SortedSet的可排序特性，经常被用来实现排行榜这样的功能。 SortedSet的常见命令有： ZADD key score member：添加一个或多个元素到sorted set ，如果已经存在则更新其score值 ZREM key member：删除sorted set中的一个指定元素 ZSCORE key member : 获取sorted set中的指定元素的score值 ZREVRANK key member: 获取sorted set 中的指定元素的降序排名 ZRANK key member：获取sorted set 中的指定元素的排名 ZCARD key：获取sorted set中的元素个数 ZCOUNT key min max：统计score值在给定范围内的所有元素的个数 ZINCRBY key increment member：让sorted set中的指定元素自增，步长为指定的increment值 ZRANGE key min max：按照score排序后，获取指定排名范围内的元素 ZREVRANGE key min max：按照score倒序排序后，获取指定排名范围内的元素 ZRANGEBYSCORE key min max：按照score排序后，获取指定score范围内的元素 ZDIFF、ZINTER、ZUNION：求差集、交集、并集 注意：所有的排名默认都是升序，如果要降序则在命令的Z后面添加REV即可 案例： 将班级的下列学生得分存入Redis的SortedSet中： Jack 85, Lucy 89, Rose 82, Tom 95, Jerry 78, Amy 92, Miles 76 127.0.0.1:6379&gt; ZADD stus 85 Jack 89 Lucy 82 Rose 95 Tom 78 Jerry 92 Amy 76 Miles (integer) 7 并实现下列功能： 删除Tom同学 127.0.0.1:6379&gt; ZREM stus Tom (integer) 1 获取Amy同学的分数 127.0.0.1:6379&gt; ZSCORE stus Amy \"92\" 获取Rose同学的排名 127.0.0.1:6379&gt; ZRANK stus Rose (integer) 2 127.0.0.1:6379&gt; ZREVRANK stus Rose (integer) 3 查询80分以下有几个学生 127.0.0.1:6379&gt; ZCOUNT stus 0 80 (integer) 2 给Amy同学加2分 127.0.0.1:6379&gt; ZINCRBY stus 2 Amy \"94\" 查出成绩前3名的同学 127.0.0.1:6379&gt; ZREVRANGE stus 0 2 1) \"Amy\" 2) \"Lucy\" 3) \"Jack\" 查出成绩80分以下的所有同学 127.0.0.1:6379&gt; ZRANGEBYSCORE stus 0 80 1) \"Miles\" 2) \"Jerry\" 3. Redis的Java客户端在Redis官网中提供了各种语言的客户端，地址：https://redis.io/clients 3.1 Jedis客户端Jedis的官网地址： https://github.com/redis/jedis，我们先来个快速入门： 引入依赖： 建立连接 private Jedis jedis; @BeforeEach void setUp() { // 建立连接 jedis = new Jedis(\"192.168.150.101\", 6379); // 设置密码 jedis.auth(\"123321\"); // 选择库 jedis.select(0); } 测试string @Test void testString() { // 插入数据，方法名称就是redis命令名称，非常简单 String result = jedis.set(\"name\", \"张三\"); System.out.println(\"result = \" + result); // 获取数据 String name = jedis.get(\"name\"); System.out.println(\"name = \" + name); } 释放资源 @AfterEach void tearDown() { // 释放资源 if (jedis != null) { jedis.close(); } } Jedis本身是线程不安全的，并且频繁的创建和销毁连接会有性能损耗，因此我们推荐大家使用Jedis连接池代替Jedis的直连方式。 public class JedisConnectionFactory { private static final JedisPool jedisPool; static { JedisPoolConfig jedisPoolConfig = new JedisPoolConfig(); // 最大连接 jedisPoolConfig.setMaxTotal(8); // 最大空闲连接 jedisPoolConfig.setMaxIdle(8); // 最小空闲连接 jedisPoolConfig.setMinIdle(0); // 设置最长等待时间， ms jedisPoolConfig.setMaxWaitMillis(200); jedisPool = new JedisPool(jedisPoolConfig, \"192.168.150.101\", 6379, 1000, \"123321\"); } // 获取Jedis对象 public static Jedis getJedis(){ return jedisPool.getResource(); } } 3.2 SpringDataRedis客户端SpringData是Spring中数据操作的模块，包含对各种数据库的集成，其中对Redis的集成模块就叫做SpringDataRedis，官网地址：https://spring.io/projects/spring-data-redis 提供了对不同Redis客户端的整合（Lettuce和Jedis） 提供了RedisTemplate统一API来操作Redis 支持Redis的发布订阅模型 支持Redis哨兵和Redis集群 支持基于Lettuce的响应式编程 支持基于JDK、JSON、字符串、Spring对象的数据序列化及反序列化 支持基于Redis的JDKCollection实现 SpringDataRedis中提供了RedisTemplate工具类，其中封装了各种对Redis的操作。并且将不同数据类型的操作API封装到了不同的类型中： API 返回值类型 说明 redisTemplate.opsForValue() ValueOperations 操作String类型数据 redisTemplate.opsForHash() HashOperations 操作Hash类型数据 redisTemplate.opsForList() ListOperations 操作List类型数据 redisTemplate.opsForSet() SetOperations 操作Set类型数据 redisTemplate.opsForZSet() ZSetOperations 操作SortedSet类型数据 redisTemplate 通用的命令 SpringBoot已经提供了对SpringDataRedis的支持，使用非常简单： 引入依赖 &lt;!--Redis依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;] &lt;/dependency&gt; &lt;!--连接池依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.commons&lt;/groupId&gt; &lt;artifactId&gt;commons-pool2&lt;/artifactId&gt; &lt;/dependency&gt; 配置文件 spring: redis: host: 192.168.150.101 port: 6379 password: 123321 lettuce: pool: max-active: 8 # 最大连接 max-idle: 8 # 最大空闲连接 min-idle: 0 # 最小空闲连接 max-wait: 100 # 连接等待时间 注入RedisTemplate @Autowired private RedisTemplate redisTemplate; 编写测试 @SpringBootTest public class RedisTest { @Autowired private RedisTemplate redisTemplate; @Test void testString() { // 插入一条string类型数据 redisTemplate.opsForValue().set(\"name\", \"李四\"); // 读取一条string类型数据 Object name = redisTemplate.opsForValue().get(\"name\"); System.out.println(\"name = \" + name); } } RedisTemplate可以接收任意Object作为值写入Redis，只不过写入前会把Object序列化为字节形式，默认是采用JDK序列化，得到的结果是这样的： 缺点： 可读性差 内存占用较大 可以自定义RedisTemplate的序列化方式，代码如下： @Bean public RedisTemplate&lt;String, Object&gt; redisTemplate(RedisConnectionFactory redisConnectionFactory) throws UnknownHostException { // 创建Template RedisTemplate&lt;String, Object&gt; redisTemplate = new RedisTemplate&lt;&gt;(); // 设置连接工厂 redisTemplate.setConnectionFactory(redisConnectionFactory); // 设置序列化工具 GenericJackson2JsonRedisSerializer jsonRedisSerializer = new GenericJackson2JsonRedisSerializer(); // key和 hashKey采用 string序列化 redisTemplate.setKeySerializer(RedisSerializer.string()); redisTemplate.setHashKeySerializer(RedisSerializer.string()); // value和 hashValue采用 JSON序列化 redisTemplate.setValueSerializer(jsonRedisSerializer); redisTemplate.setHashValueSerializer(jsonRedisSerializer); return redisTemplate; } 尽管JSON的序列化方式可以满足我们的需求，但依然存在一些问题，如图： 为了在反序列化时知道对象的类型，JSON序列化器会将类的class类型写入json结果中，存入Redis，会带来额外的内存开销。 为了节省内存空间，我们并不会使用JSON序列化器来处理value，而是统一使用String序列化器，要求只能存储String类型的key和value。当需要存储Java对象时，手动完成对象的序列化和反序列化。 Spring默认提供了一个StringRedisTemplate类，它的key和value的序列化方式默认就是String方式。省去了我们自定义RedisTemplate的过程 @Autowired private StringRedisTemplate stringRedisTemplate; // JSON工具 private static final ObjectMapper mapper = new ObjectMapper(); @Test void testStringTemplate() throws JsonProcessingException { // 准备对象 User user = new User(\"虎哥\", 18); // 手动序列化 String json = mapper.writeValueAsString(user); // 写入一条数据到redis stringRedisTemplate.opsForValue().set(\"user:200\", json); // 读取数据 String val = stringRedisTemplate.opsForValue().get(\"user:200\"); // 反序列化 User user1 = mapper.readValue(val, User.class); System.out.println(\"user1 = \" + user1); } 总结： RedisTemplate的两种序列化实践方案 方案一： 自定义RedisTemplate 修改RedisTemplate的序列化器为GenericJackson2JsonRedisSerializer 方案二： 使用StringRedisTemplate 写入Redis时，手动把对象序列化为JSON 读取Redis时，手动把读取到的JSON反序列化为对象","categories":[{"name":"Redis","slug":"Redis","permalink":"https://bowonqin.github.io/categories/Redis/"}],"tags":[{"name":"数据库","slug":"数据库","permalink":"https://bowonqin.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"Redis","slug":"Redis","permalink":"https://bowonqin.github.io/tags/Redis/"},{"name":"NoSql","slug":"NoSql","permalink":"https://bowonqin.github.io/tags/NoSql/"}],"author":"qxd"},{"title":"MySQL索引方面的一些思考","slug":"java业务开发遇到的坑/7. 数据库索引：索引不是万能药","date":"2022-03-12T12:01:34.000Z","updated":"2022-03-13T08:09:43.645Z","comments":true,"path":"posts/mysql-suo-yin-fang-mian-de-yi-xie-si-kao.html","link":"","permalink":"https://bowonqin.github.io/posts/mysql-suo-yin-fang-mian-de-yi-xie-si-kao.html","excerpt":"","text":"MySQL索引的一些思考本片的思考既有关自己的相关业务，也从极客时间的相关文章和讨论中获得一些宝贵的见解，特此记录 1. InnoDB 是如何存储数据的？MySQL 把数据存储和查询操作抽象成了存储引擎，不同的存储引擎，对数据的存储和读取方式各不相同。MySQL 支持多种存储引擎，并且可以以表为粒度设置存储引擎。因为支持事务，我们最常使用的是 InnoDB。 虽然数据保存在磁盘中，但其处理是在内存中进行的。为了减少磁盘随机读取次数，InnoDB 采用页而不是行的粒度来保存数据，即数据被分成若干页，以页为单位保存在磁盘中。InnoDB 的页大小，一般是 16KB。 各个数据页组成一个双向链表，每个数据页中的记录按照主键顺序组成单向链表；每一个数据页中有一个页目录，方便按照主键查询记录。数据页的结构如下： 页目录通过槽把记录分成不同的小组，每个小组有若干条记录。如图所示，记录中最前面的小方块中的数字，代表的是当前分组的记录条数，最小和最大的槽指向 2 个特殊的伪记录。有了槽之后，我们按照主键搜索页中记录时，就可以采用二分法快速搜索，无需从最小记录开始遍历整个页中的记录链表。 举一个例子，如果要搜索主键（PK）=15 的记录： 先二分得出槽中间位是 (0+6)/2=3，看到其指向的记录是 12＜15，所以需要从 #3 槽后继续搜索记录 再使用二分搜索出 #3 槽和 #6 槽的中间位是 (3+6)/2=4.5 取整 4，#4 槽对应的记录是 16＞15，所以记录一定在 #4 槽中； 再从 #3 槽指向的 12 号记录开始向下搜索 3 次，定位到 15 号记录。 2. 聚簇索引和二级索引说到索引，页目录就是最简单的索引，是通过对记录进行一级分组来降低搜索的时间复杂度。但，这样能够降低的时间复杂度数量级，非常有限。当有无数个数据页来存储表数据的时候，我们就需要考虑如何建立合适的索引，才能方便定位记录所在的页 为了解决这个问题，InnoDB 引入了 B+ 树。如下图所示，B+ 树是一棵倒过来的树： B+ 树的特点包括： 最底层的节点叫作叶子节点，用来存放数据； 其他上层节点叫作非叶子节点，仅用来存放目录项，作为索引； 非叶子节点分为不同层次，通过分层来降低每一层的搜索量； 所有节点按照索引键大小排序，构成一个双向链表，加速范围查找。 因此，InnoDB 使用 B+ 树，既可以保存实际数据，也可以加速数据搜索，这就是聚簇索引。如果把上图叶子节点下面方块中的省略号看作实际数据的话，那么它就是聚簇索引的示意图。由于数据在物理上只会保存一份，所以包含实际数据的聚簇索引只能有一个。 InnoDB 会自动使用主键（唯一定义一条记录的单个或多个字段）作为聚簇索引的索引键（如果没有主键，就选择第一个不包含 NULL 值的唯一列）。上图方框中的数字代表了索引键的值，对聚簇索引而言一般就是主键。 我们再看看 B+ 树如何实现快速查找主键。比如，我们要搜索 PK=4 的数据，通过根节点中的索引可以知道数据在第一个记录指向的 2 号页中，通过 2 号页的索引又可以知道数据在 5 号页，5 号页就是实际的数据页，然后再通过二分法查找页目录马上可以找到记录的指针。 为了实现非主键字段的快速搜索，就引出了二级索引，也叫作非聚簇索引、辅助索引。二级索引，也是利用的 B+ 树的数据结构，如下图所示： 这次二级索引的叶子节点中保存的不是实际数据，而是主键，获得主键值后去聚簇索引中获得数据行。这个过程就叫作回表。 举个例子，有个索引是针对用户名字段创建的，索引记录上面方块中的字母是用户名，按照顺序形成链表。如果我们要搜索用户名为 b 的数据，经过两次定位可以得出在 #5 数据页中，查出所有的主键为 7 和 6，再拿着这两个主键继续使用聚簇索引进行两次回表得到完整数据。 考虑额外创建二级索引的代价 创建二级索引的代价，主要表现在维护代价、空间代价和回表代价三个方面。接下来，我就与你仔细分析下吧。 首先是维护代价。创建 N 个二级索引，就需要再创建 N 棵 B+ 树，新增数据时不仅要修改聚簇索引，还需要修改这 N 个二级索引。 我们通过实验测试一下创建索引的代价。假设有一个 person 表，有主键 ID，以及 name、score、create_time 三个字段： CREATE TABLE `person` ( `id` bigint(20) NOT NULL AUTO_INCREMENT, `name` varchar(255) NOT NULL, `score` int(11) NOT NULL, `create_time` timestamp NOT NULL, PRIMARY KEY (`id`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4; 通过下面的存储过程循环创建 10 万条测试数据,我的机器的耗时是 140 秒（本文的例子均在 MySQL 5.7.26 中执行）：： CREATE DEFINER=`root`@`%` PROCEDURE `insert_person`() begin declare c_id integer default 1; while c_id&lt;=100000 do insert into person values(c_id, concat('name',c_id), c_id+100, date_sub(NOW(), interval c_id second)); set c_id=c_id+1; end while; end 如果再创建两个索引，一个是 name 和 score 构成的联合索引，另一个是单一列 create_time 的索引，那么创建 10 万条记录的耗时提高到 154 秒： KEY `name_score` (`name`,`score`) USING BTREE, KEY `create_time` (`create_time`) USING BTREE 这里，我再额外提一下，页中的记录都是按照索引值从小到大的顺序存放的，新增记录就需要往页中插入数据，现有的页满了就需要新创建一个页，把现有页的部分数据移过去，这就是页分裂；如果删除了许多数据使得页比较空闲，还需要进行页合并。页分裂和合并，都会有 IO 代价，并且可能在操作过程中产生死锁。 其次是空间代价。虽然二级索引不保存原始数据，但要保存索引列的数据，所以会占用更多的空间。比如，person 表创建了两个索引后，使用下面的 SQL 查看数据和索引占用的磁盘： SELECT DATA_LENGTH, INDEX_LENGTH FROM information_schema.TABLES WHERE TABLE_NAME='person' 结果显示，数据本身只占用了 4.7M，而索引占用了 8.4M。 最后是回表的代价。二级索引不保存原始数据，通过索引找到主键后需要再查询聚簇索引，才能得到我们要的数据。比如，使用 SELECT * 按照 name 字段查询用户，使用 EXPLAIN 查看执行计划： EXPLAIN SELECT * FROM person WHERE NAME='name1' 执行计划如下，可以发现 key 字段代表实际走的是哪个索引，其值是 name_score，说明走的是 name_score 这个索引。 type 字段代表了访问表的方式，其值 ref 说明是二级索引等值匹配，符合我们的查询。 把 SQL 中的 * 修改为 NAME 和 SCORE，也就是 SELECT name_score 联合索引包含的两列： EXPLAIN SELECT NAME,SCORE FROM person WHERE NAME='name1' 可以看到，Extra 列多了一行 Using index 的提示，证明这次查询直接查的是二级索引，免去了回表。 原因很简单，联合索引中其实保存了多个索引列的值，对于页中的记录先按照字段 1 排序，如果相同再按照字段 2 排序，如图所示： 图中，叶子节点每一条记录的第一和第二个方块是索引列的数据，第三个方块是记录的主键。如果我们需要查询的是索引列索引或联合索引能覆盖的数据，那么查询索引本身已经“覆盖”了需要的数据，不再需要回表查询。因此，这种情况也叫作索引覆盖。 最后，总结下关于索引开销的最佳实践吧。 第一，无需一开始就建立索引，可以等到业务场景明确后，或者是数据量超过 1 万、查询变慢后，再针对需要查询、排序或分组的字段创建索引。创建索引后可以使用 EXPLAIN 命令，确认查询是否可以使用索引。 第二，尽量索引轻量级的字段，比如能索引 int 字段就不要索引 varchar 字段。索引字段也可以是部分前缀(在本项目中使用的是mn前缀编号的前缀索引)，在创建的时候指定字段索引长度。针对长文本的搜索，可以考虑使用 Elasticsearch 等专门用于文本搜索的索引数据库。 第三，尽量不要在 SQL 语句中 SELECT *，而是 SELECT 必要的字段，甚至可以考虑使用联合索引来包含我们要搜索的字段，既能实现索引加速，又可以避免回表的开销。 但是，不是所有针对索引列的查询都能用上索引 在上一个案例中，我创建了一个 name+score 的联合索引，仅搜索 name 时就能够用上这个联合索引。这就引出两个问题： 是不是建了索引一定可以用上？ 怎么选择创建联合索引还是多个独立索引？ 需要考虑索引失效的情况，总结一下就是一下以下一句话： 模型数空运最快，上面集中情况会破坏索引树的搜索，具体含义见MySQL运维篇 在 MySQL 5.6 及之后的版本中，我们可以使用 optimizer trace 功能查看优化器生成执行计划的整个过程。有了这个功能，我们不仅可以了解优化器的选择过程，更可以了解每一个执行环节的成本，然后依靠这些信息进一步优化查询 如下代码所示，打开 optimizer_trace 后，再执行 SQL 就可以查询 information_schema.OPTIMIZER_TRACE 表查看执行计划了，最后可以关闭 optimizer_trace 功能： SET optimizer_trace=\"enabled=on\"; SELECT * FROM person WHERE NAME &gt;'name84059' AND create_time&gt;'2020-01-24 05:00:00'; SELECT * FROM information_schema.OPTIMIZER_TRACE; SET optimizer_trace=\"enabled=off\"; 对于按照 create_time&gt;’2020-01-24 05:00:00’条件走全表扫描的 SQL，我从 OPTIMIZER_TRACE 的执行结果中，摘出了几个重要片段来重点分析： 使用 name_score 对 name84059&lt;name 条件进行索引扫描需要扫描 25362 行，成本是 30435，因此最终没有选择这个方案。这里的 30435 是查询二级索引的 IO 成本和 CPU 成本之和，再加上回表查询聚簇索引的 IO 成本和 CPU 成本之和，我就不再具体分析了： { \"index\": \"name_score\", \"ranges\": [ \"name84059 &lt; name\" ], \"rows\": 25362, \"cost\": 30435, \"chosen\": false, \"cause\": \"cost\" }, 使用 create_time 进行索引扫描需要扫描 23758 行，成本是 28511，同样因为成本原因没有选择这个方案： { \"index\": \"create_time\", \"ranges\": [ \"0x5e2a79d0 &lt; create_time\" ], \"rows\": 23758, \"cost\": 28511, \"chosen\": false, \"cause\": \"cost\" } 最终选择了全表扫描方式作为执行计划。可以看到，全表扫描 100086 条记录的成本是 20306，和我们之前计算的一致，显然是小于其他两个方案的 28511 和 30435： { \"considered_execution_plans\": [{ \"table\": \"`person`\", \"best_access_path\": { \"considered_access_paths\": [{ \"rows_to_scan\": 100086, \"access_type\": \"scan\", \"resulting_rows\": 100086, \"cost\": 20306, \"chosen\": true }] }, \"rows_for_plan\": 100086, \"cost_for_plan\": 20306, \"chosen\": true }] }, 把 SQL 中的 create_time 条件从 05:00 改为 06:00，再次分析 OPTIMIZER_TRACE 可以看到，这次执行计划选择的是走 create_time 索引。因为是查询更晚时间的数据，走 create_time 索引需要扫描的行数从 23758 减少到了 16588。这次走这个索引的成本 19907 小于全表扫描的 20306，更小于走 name_score 索引的 30435： { \"index\": \"create_time\", \"ranges\": [ \"0x5e2a87e0 &lt; create_time\" ], \"rows\": 16588, \"cost\": 19907, \"chosen\": true } 3. 总结分析了 MySQL InnoDB 存储引擎页、聚簇索引和二级索引的结构，然后分析了关于索引的两个误区。 第一个误区是，考虑到索引的维护代价、空间占用和查询时回表的代价，不能认为索引越多越好。索引一定是按需创建的，并且要尽可能确保足够轻量。一旦创建了多字段的联合索引，我们要考虑尽可能利用索引本身完成数据查询，减少回表的成本。 第二个误区是，不能认为建了索引就一定有效，对于后缀的匹配查询、查询中不包含联合索引的第一列、查询条件涉及函数计算等情况无法使用索引。此外，即使 SQL 本身符合索引的使用条件，MySQL 也会通过评估各种查询方式的代价，来决定是否走索引，以及走哪个索引。 因此，在尝试通过索引进行 SQL 性能优化的时候，务必通过执行计划或实际的效果来确认索引是否能有效改善性能问题，否则增加了索引不但没解决性能问题，还增加了数据库增删改的负担。如果对 EXPLAIN 给出的执行计划有疑问的话，你还可以利用 optimizer_trace 查看详细的执行计划做进一步分析。 评论区总结： 关于使用optimizer_trace 分析覆盖索引和回表两者对比 覆盖索引： analyzing_range_alternatives\": { \"range_scan_alternatives\": [ { \"index\": \"name_score\", \"ranges\": [ \"name1 &lt;= name &lt;= name1\" ] /* ranges */, \"index_dives_for_eq_ranges\": true, \"rowid_ordered\": false, \"using_mrr\": false, \"index_only\": true, \"rows\": 1, \"cost\": 1.21, \"chosen\": true } ] 回表： \"range_scan_alternatives\": [ { \"index\": \"name_score\", \"ranges\": [ \"name1 &lt;= name &lt;= name1\" ] /* ranges */, \"index_dives_for_eq_ranges\": true, \"rowid_ordered\": false, \"using_mrr\": false, \"index_only\": false, \"rows\": 1, \"cost\": 2.21, \"chosen\": true } ] 明显可以看出覆盖索引的时间成本远小于回表成本","categories":[{"name":"java业务","slug":"java业务","permalink":"https://bowonqin.github.io/categories/java%E4%B8%9A%E5%8A%A1/"},{"name":"MySQL思考篇","slug":"java业务/MySQL思考篇","permalink":"https://bowonqin.github.io/categories/java%E4%B8%9A%E5%8A%A1/MySQL%E6%80%9D%E8%80%83%E7%AF%87/"}],"tags":[{"name":"数据库","slug":"数据库","permalink":"https://bowonqin.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"MySQL","slug":"MySQL","permalink":"https://bowonqin.github.io/tags/MySQL/"},{"name":"java业务","slug":"java业务","permalink":"https://bowonqin.github.io/tags/java%E4%B8%9A%E5%8A%A1/"}],"author":"qxd"},{"title":"Redis安装篇","slug":"redis/redis安装","date":"2022-03-12T11:01:33.000Z","updated":"2022-03-13T05:58:45.520Z","comments":true,"path":"posts/redis-an-zhuang-pian.html","link":"","permalink":"https://bowonqin.github.io/posts/redis-an-zhuang-pian.html","excerpt":"","text":"Redis安装说明大多数企业都是基于Linux服务器来部署项目，而且Redis官方也没有提供Windows版本的安装包。因此课程中我们会基于Linux系统来安装Redis. 此处选择的Linux版本为CentOS 7. Redis的官方网站地址：https://redis.io/ 1.普通单机安装Redis1.1.安装Redis依赖Redis是基于C语言编写的，因此首先需要安装Redis所需要的gcc依赖： yum install -y gcc tcl 1.2.上传安装包并解压然后将课前资料提供的Redis安装包上传到虚拟机的任意目录： 例如，我放到了/usr/local/src 目录： 解压缩： tar -xzf redis-6.2.6.tar.gz 解压后： 进入redis目录： cd redis-6.2.6 运行编译命令： make &amp;&amp; make install 如果没有出错，应该就安装成功了。 默认的安装路径是在 /usr/local/bin目录下： 该目录以及默认配置到环境变量，因此可以在任意目录下运行这些命令。其中： redis-cli：是redis提供的命令行客户端 redis-server：是redis的服务端启动脚本 redis-sentinel：是redis的哨兵启动脚本 1.3.启动redis的启动方式有很多种，例如： 默认启动 指定配置启动 开机自启 1.3.1.默认启动安装完成后，在任意目录输入redis-server命令即可启动Redis： redis-server 如图： 这种启动属于前台启动，会阻塞整个会话窗口，窗口关闭或者按下CTRL + C则Redis停止。不推荐使用。 1.3.2.指定配置启动如果要让Redis以后台方式启动，则必须修改Redis配置文件，就在我们之前解压的redis安装包下（/usr/local/src/redis-6.2.6），名字叫redis.conf： 我们先将这个配置文件备份一份： cp redis.conf redis.conf.bck 然后修改redis.conf文件中的一些配置： # 允许访问的地址，默认是127.0.0.1，会导致只能在本地访问。修改为0.0.0.0则可以在任意IP访问，生产环境不要设置为0.0.0.0 bind 0.0.0.0 # 守护进程，修改为yes后即可后台运行 daemonize yes # 密码，设置后访问Redis必须输入密码 requirepass 123321 Redis的其它常见配置： # 监听的端口 port 6379 # 工作目录，默认是当前目录，也就是运行redis-server时的命令，日志、持久化等文件会保存在这个目录 dir . # 数据库数量，设置为1，代表只使用1个库，默认有16个库，编号0~15 databases 1 # 设置redis能够使用的最大内存 maxmemory 512mb # 日志文件，默认为空，不记录日志，可以指定日志文件名 logfile \"redis.log\" 启动Redis： # 进入redis安装目录 cd /usr/local/src/redis-6.2.6 # 启动 redis-server redis.conf 停止服务： # 利用redis-cli来执行 shutdown 命令，即可停止 Redis 服务， # 因为之前配置了密码，因此需要通过 -u 来指定密码 redis-cli -u 123321 shutdown 1.3.3.开机自启我们也可以通过配置来实现开机自启。 首先，新建一个系统服务文件： vi /etc/systemd/system/redis.service 内容如下： [Unit] Description=redis-server After=network.target [Service] Type=forking ExecStart=/usr/local/bin/redis-server /usr/local/src/redis-6.2.6/redis.conf PrivateTmp=true [Install] WantedBy=multi-user.target 然后重载系统服务： systemctl daemon-reload 现在，我们可以用下面这组命令来操作redis了： # 启动 systemctl start redis # 停止 systemctl stop redis # 重启 systemctl restart redis # 查看状态 systemctl status redis 执行下面的命令，可以让redis开机自启： systemctl enable redis 2. Docker安装Redis首先，我们新建一个文件夹redis，然后在该目录下创建出data文件夹、redis.conf文件和docker-compose.yaml文件 redis.conf文件的内容如下(后面的配置可在这更改，比如requirepass 我指定的密码为123321) protected-mode no port 6379 timeout 0 save 900 1 save 300 10 save 60 10000 rdbcompression yes dbfilename dump.rdb dir /data appendonly yes appendfsync everysec requirepass 123321 docker-compose.yaml的文件内容如下： version: '3' services: redis: image: redis:latest container_name: redis restart: always ports: - 6379:6379 volumes: - ./redis.conf:/usr/local/etc/redis/redis.conf:rw - ./data:/data:rw command: /bin/bash -c \"redis-server /usr/local/etc/redis/redis.conf \" 配置的工作就完了，如果是云服务器，记得开redis端口6379 docker-compose up -d docker ps docker exec -it redis redis-cli 3.Redis客户端安装完成Redis，我们就可以操作Redis，实现数据的CRUD了。这需要用到Redis客户端，包括： 命令行客户端 图形化桌面客户端 编程客户端 3.1.Redis命令行客户端Redis安装完成后就自带了命令行客户端：redis-cli，使用方式如下： redis-cli [options] [commonds] 其中常见的options有： -h 127.0.0.1：指定要连接的redis节点的IP地址，默认是127.0.0.1 -p 6379：指定要连接的redis节点的端口，默认是6379 -a 123321：指定redis的访问密码 其中的commonds就是Redis的操作命令，例如： ping：与redis服务端做心跳测试，服务端正常会返回pong 不指定commond时，会进入redis-cli的交互控制台： 3.2.图形化桌面客户端GitHub上的大神编写了Redis的图形化桌面客户端，地址：https://github.com/uglide/RedisDesktopManager 不过该仓库提供的是RedisDesktopManager的源码，并未提供windows安装包。 在下面这个仓库可以找到安装包：https://github.com/lework/RedisDesktopManager-Windows/releases 3.2.1.安装在课前资料中可以找到Redis的图形化桌面客户端： 解压缩后，运行安装程序即可安装： 此处略。 安装完成后，在安装目录下找到rdm.exe文件： 双击即可运行： 3.2.2.建立连接点击左上角的连接到Redis服务器按钮： 在弹出的窗口中填写Redis服务信息： 点击确定后，在左侧菜单会出现这个链接： 点击即可建立连接了： Redis默认有16个仓库，编号从0至15. 通过配置文件可以设置仓库数量，但是不超过16，并且不能自定义仓库名称。 如果是基于redis-cli连接Redis服务，可以通过select命令来选择数据库： # 选择 0号库 select 0","categories":[{"name":"Redis","slug":"Redis","permalink":"https://bowonqin.github.io/categories/Redis/"}],"tags":[{"name":"数据库","slug":"数据库","permalink":"https://bowonqin.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"Redis","slug":"Redis","permalink":"https://bowonqin.github.io/tags/Redis/"},{"name":"NoSql","slug":"NoSql","permalink":"https://bowonqin.github.io/tags/NoSql/"}],"author":"qxd"},{"title":"JVM","slug":"java基础/JVM","date":"2022-01-18T13:58:34.000Z","updated":"2022-01-18T14:27:42.332Z","comments":true,"path":"posts/jvm.html","link":"","permalink":"https://bowonqin.github.io/posts/jvm.html","excerpt":"","text":"JVM什么是JVM?定义： Java Virtual Machine - java 程序的运行环境（java 二进制字节码的运行环境） 好处： 一次编写，到处运行 自动内存管理，垃圾回收功能 数组下标越界检查 多态 比较： jvm jre jdk 学习路线 内存结构1.程序计数器 1.1 定义Program Counter Register 程序计数器（寄存器） 作用，是记住下一条jvm指令的执行地址 特点 是线程私有的 不会存在内存溢出 1.2 作用0: getstatic #20 // PrintStream out = System.out; 3: astore_1 // -- 4: aload_1 // out.println(1); 5: iconst_1 // -- 6: invokevirtual #26 // -- 9: aload_1 // out.println(2); 10: iconst_2 // -- 11: invokevirtual #26 // -- 14: aload_1 // out.println(3); 15: iconst_3 // -- 16: invokevirtual #26 // -- 19: aload_1 // out.println(4); 20: iconst_4 // -- 21: invokevirtual #26 // -- 24: aload_1 // out.println(5); 25: iconst_5 // -- 26: invokevirtual #26 // -- 29: return 2. 虚拟机栈 2.1 定义Java Virtual Machine Stacks （Java 虚拟机栈） 每个线程运行时所需要的内存，称为虚拟机栈 每个栈由多个栈帧（Frame）组成，对应着每次方法调用时所占用的内存 每个线程只能有一个活动栈帧，对应着当前正在执行的那个方法 /** * 演示栈帧 */ public class Demo1_1 { public static void main(String[] args) throws InterruptedException { method1(); } private static void method1() { method2(1, 2); } private static int method2(int a, int b) { int c = a + b; return c; } } 问题辨析 垃圾回收是否涉及栈内存？ no 栈内存分配越大越好吗？ no 方法内的局部变量是否线程安全？ 如果方法内局部变量没有逃离方法的作用访问，它是线程安全的 如果是局部变量引用了对象，并逃离方法的作用范围，需要考虑线程安全 2.2 栈内存溢出 栈帧过多导致栈内存溢出 public class Demo1_2 { private static int count; public static void main(String[] args) { try { method1(); } catch (Throwable e) { e.printStackTrace(); System.out.println(count); } } private static void method1() { count++; method1(); } } /** * json 数据转换 */ public class Demo1_19 { public static void main(String[] args) throws JsonProcessingException { Dept d = new Dept(); d.setName(\"Market\"); Emp e1 = new Emp(); e1.setName(\"zhang\"); e1.setDept(d); Emp e2 = new Emp(); e2.setName(\"li\"); e2.setDept(d); d.setEmps(Arrays.asList(e1, e2)); // { name: 'Market', emps: [{ name:'zhang', dept:{ name:'', emps: [ {}]} },] } ObjectMapper mapper = new ObjectMapper(); System.out.println(mapper.writeValueAsString(d)); } } class Emp { private String name; @JsonIgnore private Dept dept; public String getName() { return name; } public void setName(String name) { this.name = name; } public Dept getDept() { return dept; } public void setDept(Dept dept) { this.dept = dept; } } class Dept { private String name; private List&lt;Emp&gt; emps; public String getName() { return name; } public void setName(String name) { this.name = name; } public List&lt;Emp&gt; getEmps() { return emps; } public void setEmps(List&lt;Emp&gt; emps) { this.emps = emps; } } 需要 @JsonIgnore 屏蔽字段 栈帧过大导致栈内存溢出 2.3 线程运行诊断案例1： cpu 占用过多 public class Demo1_16 { public static void main(String[] args) { new Thread(null, () -&gt; { System.out.println(\"1...\"); while(true) { } }, \"thread1\").start(); new Thread(null, () -&gt; { System.out.println(\"2...\"); try { Thread.sleep(1000000L); } catch (InterruptedException e) { e.printStackTrace(); } }, \"thread2\").start(); new Thread(null, () -&gt; { System.out.println(\"3...\"); try { Thread.sleep(1000000L); } catch (InterruptedException e) { e.printStackTrace(); } }, \"thread3\").start(); } } 定位： 用top定位哪个进程对cpu的占用过高 ps H -eo pid,tid,%cpu | grep 进程id （用ps命令进一步定位是哪个线程引起的cpu占用过高） jstack 进程id 可以根据线程id 找到有问题的线程，进一步定位到问题代码的源码行号 案例2：程序运行很长时间没有结果 3. 本地方法栈 java程序底层调用c/c++程序编写的代码，用native修饰。 4.堆 4.1 定义Heap 堆 通过 new 关键字，创建对象都会使用堆内存 特点 它是线程共享的，堆中对象都需要考虑线程安全的问题 有垃圾回收机制 4.2 堆内存溢出/** * 演示堆内存溢出 java.lang.OutOfMemoryError: Java heap space * -Xmx8m */ public class Demo1_5 { public static void main(String[] args) { int i = 0; try { List&lt;String&gt; list = new ArrayList&lt;&gt;(); String a = \"hello\"; while (true) { list.add(a); // hello, hellohello, hellohellohellohello ... a = a + a; // hellohellohellohello i++; } } catch (Throwable e) { e.printStackTrace(); System.out.println(i); } } } 4.3 堆内存诊断/** * 演示堆内存 */ public class Demo1_4 { public static void main(String[] args) throws InterruptedException { System.out.println(\"1...\"); Thread.sleep(30000); byte[] array = new byte[1024 * 1024 * 100]; // 10 Mb System.out.println(\"2...\"); Thread.sleep(20000); array = null; System.gc(); System.out.println(\"3...\"); Thread.sleep(1000000L); } } jps工具 查看当前系统中有哪些 java 进程 jmap 工具 查看堆内存占用情况 jmap - heap 进程id jconsole 工具 图形界面的，多功能的监测工具，可以连续监测 jvisualvm工具 案例： 垃圾回收后，内存占用仍然很高 /** * 演示查看对象个数 堆转储 dump */ public class Demo1_13 { public static void main(String[] args) throws InterruptedException { List&lt;Student&gt; students = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; 200; i++) { students.add(new Student()); // Student student = new Student(); } Thread.sleep(1000000000L); } } class Student { private byte[] big = new byte[1024*1024]; //1M } 5. 方法区 5.1 定义5.2 组成 5.3 方法区内存溢出 1.8 以前会导致永久代内存溢出 /** * 演示永久代内存溢出 java.lang.OutOfMemoryError: PermGen space * -XX:MaxPermSize=8m */ public class Demo1_8_6 extends ClassLoader { public static void main(String[] args) { int j = 0; try { Demo1_8_6 test = new Demo1_8_6(); for (int i = 0; i &lt; 20000; i++, j++) { ClassWriter cw = new ClassWriter(0); cw.visit(Opcodes.V1_6, Opcodes.ACC_PUBLIC, \"Class\" + i, null, \"java/lang/Object\", null); byte[] code = cw.toByteArray(); test.defineClass(\"Class\" + i, code, 0, code.length); } } finally { System.out.println(j); } } } 1.8 之后会导致元空间内存溢出 /** * 演示元空间内存溢出 java.lang.OutOfMemoryError: Metaspace * -XX:MaxMetaspaceSize=8m */ public class Demo1_8 extends ClassLoader { // 可以用来加载类的二进制字节码 public static void main(String[] args) { int j = 0; try { Demo1_8 test = new Demo1_8(); for (int i = 0; i &lt; 10000; i++, j++) { // ClassWriter 作用是生成类的二进制字节码 ClassWriter cw = new ClassWriter(0); // 版本号， public， 类名, 包名, 父类， 接口 cw.visit(Opcodes.V1_8, Opcodes.ACC_PUBLIC, \"Class\" + i, null, \"java/lang/Object\", null); // 返回 byte[] byte[] code = cw.toByteArray(); // 执行了类的加载 test.defineClass(\"Class\" + i, code, 0, code.length); // Class 对象 } } finally { System.out.println(j); } } } 场景 spring mybatis cglib底层的动态字节码技术","categories":[{"name":"java基础","slug":"java基础","permalink":"https://bowonqin.github.io/categories/java%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"java基础","slug":"java基础","permalink":"https://bowonqin.github.io/tags/java%E5%9F%BA%E7%A1%80/"},{"name":"jvm","slug":"jvm","permalink":"https://bowonqin.github.io/tags/jvm/"}],"author":"qxd"},{"title":"docker安装镜像和容器","slug":"微服务/docker安装镜像和容器","date":"2022-01-10T12:12:57.000Z","updated":"2022-01-18T14:28:13.159Z","comments":true,"path":"posts/95fa03d.html","link":"","permalink":"https://bowonqin.github.io/posts/95fa03d.html","excerpt":"","text":"","categories":[],"tags":[]},{"title":"Mysql(MySQL运维篇)","slug":"mysql/MySQL-运维篇","date":"2022-01-07T13:15:16.000Z","updated":"2022-02-15T12:10:34.859Z","comments":true,"path":"posts/mysql-yun-wei-pian.html","link":"","permalink":"https://bowonqin.github.io/posts/mysql-yun-wei-pian.html","excerpt":"","text":"MySQL运维篇1. 日志1.1 错误日志错误日志是 MySQL 中最重要的日志之一，它记录了当 mysqld 启动和停止时，以及服务器在运行过程中发生任何严重错误时的相关信息。当数据库出现任何故障导致无法正常使用时，建议首先查看此日志。 该日志是默认开启的，默认存放目录 /var/log/，默认的日志文件名为 mysqld.log 。查看日志位置： show variables like '%log_error%'; 1.2 二进制日志 介绍 二进制日志（BINLOG）记录了所有的 DDL（数据定义语言）语句和 DML（数据操纵语言）语句，但不包括数据查询（SELECT、SHOW）语句。 作用：①. 灾难时的数据恢复；②. MySQL的主从复制。在MySQL8版本中，默认二进制日志是开启着的，涉及到的参数如下： show variables like '%log_bin%'; 日志格式 MySQL服务器中提供了多种格式来记录二进制日志，具体格式及特点如下： show variables like '%binlog_format%'; 日志查看 由于日志是以二进制方式存储的，不能直接读取，需要通过二进制日志查询工具 mysqlbinlog 来查看，具体语法： 日志删除 对于比较繁忙的业务系统，每天生成的binlog数据巨大，如果长时间不清除，将会占用大量磁盘空间。可以通过以下几种方式清理日志： 也可以在mysql的配置文件中配置二进制日志的过期时间，设置了之后，二进制日志过期会自动删除。 show variables like '%binlog_expire_logs_seconds%'; 1.3 查询日志查询日志中记录了客户端的所有操作语句，而二进制日志不包含查询数据的SQL语句。默认情况下， 查询日志是未开启的。如果需要开启查询日志，可以设置以下配置 ： 修改MySQL的配置文件 /etc/my.cnf 文件，添加如下内容： 1.4 慢查询日志慢查询日志记录了所有执行时间超过参数 long_query_time 设置值并且扫描记录数不小于 min_examined_row_limit 的所有的SQL语句的日志，默认未开启。long_query_time 默认为 10 秒，最小为 0， 精度可以到微秒。 # 慢查询日志 slow_query_log = 1 # 执行时间 long_query_time = 2 默认情况下，不会记录管理语句，也不会记录不使用索引进行查找的查询。可以使用log_slow_admin_statements和 更改此行为 log_queries_not_using_indexes，如下所述。 # 记录执行较慢的管理语句 log_slow_admin_statements = 1 # 记录执行较慢的未使用索引的语句 log_queries_not_using_indexes =1 2. 主从复制 概述： 主从复制是指将主数据库的DDL 和 DML 操作通过二进制日志传到从库服务器中，然后在从库上对这些日志重新执行（也叫重做），从而使得从库和主库的数据保持同步。 MySQL支持一台主库同时向多台从库进行复制， 从库同时也可以作为其他从服务器的主库，实现链状复制。 原理： 从上图来看，复制分成三步： 1. Master 主库在事务提交时，会把数据变更记录在二进制日志文件 Binlog 中。 2. 从库读取主库的二进制日志文件 Binlog ，写入到从库的中继日志 Relay Log 。 3. slave重做中继日志中的事件，将改变反映它自己的数据。 搭建 服务器准备 准备好两台服务器之后，在上述的两台服务器中分别安装好MySQL，并完成基础的初始化准备工作。 主库配置 修改配置文件 /etc/my.cnf、 重启MySQL服务器 systemctl restart mysqld; 登录mysql，创建远程连接的账号，并授予主从复制权限 通过指令，查看二进制日志坐标 show master status; 字段含义说明： ​ file : 从哪个日志文件开始推送日志文件 ​ position ： 从哪个位置开始推送日志 ​ binlog_ignore_db : 指定不需要同步的数据库 从库配置 修改配置文件 /etc/my.cnf 重新启动MySQL服务 systemctl restart mysqld; 登录mysql，设置主库配置 CHANGE REPLICATION SOURCE TO SOURCE_HOST='XXX.XXX',SOURCE_USER='XXX',SOURCE_PASSWORD='XXX',SOURCE_LOGFILE='XXX',SOURCE_LOG_POS=XXX; 上述是8.0.23中的语法。如果mysql是 8.0.23 之前的版本，执行如下SQL： CHANGE MASTER TO MASTER_HOST='XXX.XXX',MASTER_USER='XXX',MASTER_PASSWORD='XXX',MASTER_LOG_FILE='XXX',MASTER_LOG_POS=XXX; 开启同步操作 start replica; # 8.0.22之后 start salve; # 8.0.22之前 查看主从同步状态 show replica status; # 8.0.22之后 show slave status; # 8.0.22之前 测试 在主库上创建数据库、表，并插入数据 在从库中查询数据，验证主从是否同步 3. 分库分表3.1 介绍 概述： Mycat是开源的、活跃的、基于Java语言编写的MySQL数据库中间件。可以像使用mysql一样来使用mycat，对于开发人员来说根本感觉不到mycat的存在。 优势: 性能可靠稳定 强大的技术团队 体系完善 社区活跃 安装 Mycat是采用java语言开发的开源的数据库中间件，支持Windows和Linux运行环境，下面介绍MyCat的Linux中的环境搭建。我们需要在准备好的服务器中安装如下软件。 MySQL JDK MyCat 目录结构 bin : 存放可执行文件，用于启动停止mycat conf：存放mycat的配置文件 lib：存放mycat的项目依赖包（jar） logs：存放mycat的日志文件 概念介绍 3.2 MyCat入门 需求 由于 tb_order 表中数据量很大，磁盘IO及容量都到达了瓶颈，现在需要对 tb_order表进行数据分片，分为三个数据节点，每一个节点主机位于不同的服务器上, 具体的结构，参考下图： 环境准备 分片规则 分片配置 配置mycat的用户及用户的权限信息: 启动服务 切换到Mycat的安装目录，执行如下指令，启动Mycat： # 启动 bin/mycat start # 停止 bin/mycat stop Mycat启动之后，占用端口号 8066。 启动完毕之后，可以查看logs目录下的启动日志，查看Mycat是否启动完成。 分片测试 通过如下指令，就可以连接并登陆MyCat。 mysql -uroot -h192.168.59.132 -P 8066 -p123456 --default-auth=mysql_native_password 然后就可以在MyCat中来创建表，并往表结构中插入数据，查看数据在MySQL中的分布情况。 create table TB_ORDER( id bigint(20) not null, title varchar(20) not null, primary key(id) )engine=innodb default charset=utf8; insert into TB_ORDER(id,title) VALUES(1,'goods1'); insert into TB_ORDER(id,title) VALUES(2,'goods2'); insert into TB_ORDER(id,title) VALUES(3,'goods3'); insert into TB_ORDER(id,title) VALUES(1000000,'goods1000000'); insert into TB_ORDER(id,title) VALUES(10000000,'goods10000000'); 3.3 Mycat配置 schema.xml schema.xml 作为MyCat中最重要的配置文件之一 , 涵盖了MyCat的逻辑库 、 逻辑表 、 分片规则、分片节点及数据源的配置。 主要包含以下三组标签： schema标签 schema 标签用于定义 MyCat实例中的逻辑库 , 一个MyCat实例中, 可以有多个逻辑库 , 可以通过 schema 标签来划分不同的逻辑库。 MyCat中的逻辑库的概念 ， 等同于MySQL中的database概念 , 需要操作某个逻辑库下的表时, 也需要切换逻辑库(use xxx)。 核心属性： name：指定自定义的逻辑库库名 checkSQLschema：在SQL语句操作时指定了数据库名称，执行时是否自动去除；true：自动去除，false：不自动去除 sqlMaxLimit：如果未指定limit进行查询，列表查询模式查询多少条记录 datanode标签 dataNode标签中定义了MyCat中的数据节点, 也就是我们通常说的数据分片。一个dataNode标签就是一个独立的数据分片。 核心属性： name：定义数据节点名称 dataHost：数据库实例主机名称，引用自 dataHost 标签中name属性 database：定义分片所属数据库 datahost标签 该标签在MyCat逻辑库中作为底层标签存在, 直接定义了具体的数据库实例、读写分离、心跳语句。 核心属性： name：唯一标识，供上层标签使用 maxCon/minCon：最大连接数/最小连接数 balance：负载均衡策略，取值 0,1,2,3 writeType：写操作分发方式（0：写操作转发到第一个writeHost，第一个挂了，切换到第二个；1：写操作随机分发到配置的writeHost） dbDriver：数据库驱动，支持 native、jdbc rule.xml rule.xml中定义所有拆分表的规则, 在使用过程中可以灵活的使用分片算法, 或者对同一个分片算法使用不同的参数,它让分片过程可配置化。主要包含两类标签：tableRule、Function。 server.xml server.xml配置文件包含了MyCat的系统配置信息，主要有两个重要的标签：system、user。 system标签 对应的系统配置项及其含义，参考资料 user标签 3.4 Mycat分片 垂直拆分 场景 在业务系统中, 涉及以下表结构 ,但是由于用户与订单每天都会产生大量的数据, 单台服务器的数据存储及处理能力是有限的, 可以对数据库表进行拆分, 原有的数据库表如下 准备 配置 测试 在mycat的命令行中，通过source指令导入表结构，以及对应的数据，查看数据分布情况。 source /root/shopping-table.sql source /root/shopping-insert.sql 查询用户的收件人及收件人地址信息(包含省、市、区)。 SELECT ua.user_id, ua.contact, p.province, c.city, r.area, ua.address FROM tb_user_address ua, tb_areas_city c, tb_areas_provinces p, tb_areas_region r WHERE ua.province_id = p.provinceid AND ua.city_id = c.cityid AND ua.town_id = r.areaid; 查询每一笔订单及订单的收件地址信息(包含省、市、区)。 SELECT order_id, payment, receiver, province, city, area FROM tb_order_master o, tb_areas_provinces p, tb_areas_city c, tb_areas_region r WHERE o.receiver_province = p.provinceid AND o.receiver_city = c.cityid AND o.receiver_region = r.areaid; 全局配置 对于省、市、区/县表tb_areas_provinces , tb_areas_city , tb_areas_region，是属于数据字典表，在多个业务模块中都可能会遇到，可以将其设置为全局表，利于业务操作。 水平拆分 场景 在业务系统中, 有一张表(日志表), 业务系统每天都会产生大量的日志数据 , 单台服务器的数据存储及处理能力是有限的, 可以对数据库表进行拆分。 准备 配置 测试 在mycat的命令行中，执行如下SQL创建表、并插入数据，查看数据分布情况 分片规则-范围 分片规则-取模 根据指定的字段值与节点数量进行求模运算，根据运算结果， 来决定该数据属于哪一个分片。 分片规则-一致性hash 所谓一致性哈希， 相同的哈希因子计算值总是被划分到相同的分区表中，不会因为分区节点的增加而改变原来数据的分区位置。 分片规则-枚举 通过在配置文件中配置可能的枚举值, 指定数据分布到不同数据节点上, 本规则适用于按照省份、性别、状态拆分数据等业务 。 分片规则-应用指定 运行阶段由应用自主决定路由到那个分片 , 直接根据字符子串（必须是数字）计算分片号。 分片规则-固定分片hash算法 该算法类似于十进制的求模运算，但是为二进制的操作，例如，取 id 的二进制低 10 位 与 1111111111 进行位 &amp; 运算 分片规则-字符串hash解析 截取字符串中的指定位置的子字符串, 进行hash算法， 算出分片。 分片规则-按（天）日期分片 分片规则-自然月 使用场景为按照月份来分片, 每个自然月为一个分片。","categories":[{"name":"Mysql运维篇","slug":"Mysql运维篇","permalink":"https://bowonqin.github.io/categories/Mysql%E8%BF%90%E7%BB%B4%E7%AF%87/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"https://bowonqin.github.io/tags/Mysql/"},{"name":"数据库","slug":"数据库","permalink":"https://bowonqin.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"MyCat","slug":"MyCat","permalink":"https://bowonqin.github.io/tags/MyCat/"}],"author":"qxd"},{"title":"git","slug":"git教学/git","date":"2022-01-04T11:31:05.000Z","updated":"2022-01-04T11:36:20.487Z","comments":true,"path":"posts/518e617c.html","link":"","permalink":"https://bowonqin.github.io/posts/518e617c.html","excerpt":"","text":"Git参考黑马程序员Git教程 Idea中使用Git在Idea中配置Git安装好IntelliJ IDEA后，如果Git安装在默认路径下，那么idea会自动找到git的位置，如果更改了Git的安装位置则需要手动配置下Git的路径。选择File→Settings打开设置窗口，找到Version Control下的git选项： 在Idea中操作Git场景：本地已经有一个项目，但是并不是git项目，我们需要将这个放到码云的仓库里，和其他开发人员继续一起协作开发 创建远程仓库 上图中＋号创建分支，按相应步骤即可。 初始化本地仓库 设置远程仓库 提交到本地仓库 推送到本地仓库 克隆远程仓库到本地 创建分支 常规方式 强大方式 切换分支 解决冲突（重点）如果员工甲和员工乙同时修改了同一份文件并commit和push，此时会发生冲突。 任何情况下都应该先将别人写的代码pull到本地，分析他人的提交日志，将别人写的代码添加到自己的文件中，然后在commit and push.","categories":[],"tags":[{"name":"git","slug":"git","permalink":"https://bowonqin.github.io/tags/git/"}]},{"title":"Mysql(MySQL进阶篇)","slug":"mysql/MySQL-进阶篇","date":"2022-01-03T12:35:11.000Z","updated":"2022-02-15T11:32:05.516Z","comments":true,"path":"posts/mysql-jin-jie-pian.html","link":"","permalink":"https://bowonqin.github.io/posts/mysql-jin-jie-pian.html","excerpt":"","text":"MySQL进阶篇1. 存储引擎1.1 MySQL体系结构 连接层 最上层是一些客户端和链接服务，主要完成一些类似于连接处理、授权认证、及相关的安全方案。服务器也会为安全接入的每个客户端验证它所具有的操作权限。 服务层 第二层架构主要完成大多数的核心服务功能，如SQL接口，并完成缓存的查询，SQL的分析和优化，部分内置函数的执行。所有跨存储引擎的功能也在这一层实现，如 过程、函数等。 引擎层 存储引擎真正的负责了MySQL中数据的存储和提取，服务器通过API和存储引擎进行通信。不同的存储引擎具有不同的功能，这样我们可以根据自己的需要，来选取合适的存储引擎。 存储层 主要是将数据存储在文件系统之上，并完成与存储引擎的交互。 1.2 存储引擎简介存储引擎就是存储数据、建立索引、更新/查询数据等技术的实现方式 。存储引擎是基于表的，而不是基于库的，所以存储引擎也可被称为表类型。 在创建表时，指定存储引擎 CREATE TABLE 表名（）ENGINE=INNODB [COMMENT 表注释] 查看当前数据库支持的存储引擎 SHOW ENGINES; 1.3 存储引擎特点 InnoDB 介绍： InnoDB是一种兼顾高可靠性和高性能的通用存储引擎，在 MySQL 5.5 之后，InnoDB是默认的 MySQL 存储引擎。 特点： DML操作遵循ACID模型，支持事务 ； 行级锁 ，提高并发访问性能； 支持外键 FOREIGN KEY约束，保证数据的完整性和正确性； 文件： xxx.ibd：xxx代表的是表名，innoDB引擎的每张表都会对应这样一个表空间文件，存储该表的表结构（frm、sdi）、数据和索引。 参数：innodb_file_per_table MyISAM 介绍： MyISAM是MySQL早期的默认存储引擎。 特点： 不支持事务，不支持外键 支持表锁，不支持行锁 访问速度快 文件： xxx.sdi：存储表结构信息 xxx.MYD: 存储数据 xxx.MYI: 存储索引 Memory 介绍： Memory引擎的表数据时存储在内存中的，由于受到硬件问题、或断电问题的影响，只能将这些表作为临时表或缓存使用。 特点： 内存存放 hash索引（默认） 文件： xxx.sdi：存储表结构信息 1.4 存储引擎选择在选择存储引擎时，应该根据应用系统的特点选择合适的存储引擎。对于复杂的应用系统，还可以根据实际情况选择多种存储引擎进行组合。 InnoDB : 是Mysql的默认存储引擎，支持事务、外键。如果应用对事务的完整性有比较高的要求，在并发条件下要求数据的一致性，数据操作除了插入和查询之外，还包含很多的更新、删除操作，那么InnoDB存储引擎是比较合适的选择。 MyISAM ： 如果应用是以读操作和插入操作为主，只有很少的更新和删除操作，并且对事务的完整性、并发性要求不是很高，那么选择这个存储引擎是非常合适的。 MEMORY：将所有数据保存在内存中，访问速度快，通常用于临时表及缓存。MEMORY的缺陷就是对表的大小有限制，太大的表无法缓存在内存中，而且无法保障数据的安全性。 2. 索引2.1 索引概述 介绍 索引（index）是帮助MySQL高效获取数据的数据结构（有序）。在数据之外，数据库系统还维护着满足特定查找算法的数据结构，这些数据结构以某种方式引用（指向）数据， 这样就可以在这些数据结构上实现高级查找算法，这种数据结构就是索引。 演示 备注：上述的二叉树结构只是示意图，并非真正的索引结构 优缺点 2.2 索引结构MySQL的索引是在存储引擎层实现的，不同的存储引擎有不同的结构，主要包含以下几种： 我们平常所说的索引，如果没有特别指明，都是指B+树结构组织的索引。 二叉树 二叉树缺点：顺序插入时，会形成一个链表，查询性能大大降低。 大数据量情况下，层级较深，检索速度慢。 红黑树：大数据量情况下，层级较深，检索速度慢。 B-Tree（多路平衡查找树） 以一颗最大度数（max-degree）为5(5阶)的b-tree为例(每个节点最多存储4个key，5个指针，指针=key+1)： 树的度数指的是一个节点的子节点个数。 插入 100 65 169 368 900 556 780 35 215 1200 234 888 158 90 1000 88 120 268 250 数据为例。 具体动态变化的过程可以参考网站: https://www.cs.usfca.edu/~galles/visualization/BTree.html B+Tree 以一颗最大度数（max-degree）为4（4阶）的b+tree为例： 插入 100 65 169 368 900 556 780 35 215 1200 234 888 158 90 1000 88 120 268 250 数据为例。 相对于B-Tree区别: ①. 所有的数据都会出现在叶子节点 ②. 叶子节点形成一个单向链表 MySQL索引数据结构对经典的B+Tree进行了优化。在原B+Tree的基础上，增加一个指向相邻叶子节点的链表指针，就形成了带有顺序指针的B+Tree，提高区间访问的性能。 Hash 哈希索引就是采用一定的hash算法，将键值换算成新的hash值，映射到对应的槽位上，然后存储在hash表中。 如果两个(或多个)键值，映射到一个相同的槽位上，他们就产生了hash冲突（也称为hash碰撞），可以通过链表来解决。 Hash索引特点 Hash索引只能用于对等比较(=，in)，不支持范围查询（between，&gt;，&lt; ，…） 无法利用索引完成排序操作 查询效率高，通常只需要一次检索就可以了，效率通常要高于B+tree索引 存储引擎支持 在MySQL中，支持hash索引的是Memory引擎，而InnoDB中具有自适应hash功能，hash索引是存储引擎根据B+Tree索引在指定条件下自动构建的。 2.3 索引分类 在InnoDB存储引擎中，根据索引的存储形式，又可以分为以下两种 聚集索引选取规则: 如果存在主键，主键索引就是聚集索引。 如果不存在主键，将使用第一个唯一（UNIQUE）索引作为聚集索引。 如果表没有主键，或没有合适的唯一索引，则InnoDB会自动生成一个rowid作为隐藏的聚集索引。 2.4 索引语法 创建索引 CREATE [UNIQUE|FULLTEXT] INDEX index_name ON table_name(index_col_name,...); 查看索引 SHOW INDEX FROM table_name; 删除索引 DROP INDEX index_name ON table_name; 按照下列的需求，完成索引的创建 name字段为姓名字段，该字段的值可能会重复，为该字段创建索引。 phone手机号字段的值，是非空，且唯一的，为该字段创建唯一索引。 为profession、age、status创建联合索引。 为email建立合适的索引来提升查询效率。 CREATE INDEX idx_user_name on tb_user(name); CREATE UNIQUE INDEX idx_user_phone on tb_user(phone); CREATE INDEX idx_user_pro_age_sta ON tb_user(profession,age,status); CREATE INDEX idx_email on tb_user(email); 2.5 SQL性能分析 SQL执行频率 MySQL 客户端连接成功后，通过 show [session|global] status 命令可以提供服务器状态信息。通过如下指令，可以查看当前数据库的INSERT、UPDATE、DELETE、SELECT的访问频次： SHOW GLOBAL STATUS LIKE 'Com_______'; 慢查询日志 慢查询日志记录了所有执行时间超过指定参数（long_query_time，单位：秒，默认10秒）的所有SQL语句的日志。MySQL的慢查询日志默认没有开启，需要在MySQL的配置文件（/etc/my.cnf）中配置如下信息： # 开启MySQL慢日志查询开关 slow_query_log=1 # 设置慢日志时间为2秒，SQL语句的执行时间超过2s，就会被视为慢查询，记录慢查询日志 long_query_time=2 配置完毕之后，通过以下指令重新启动MySQL服务器进行测试，查看慢日志文件中记录的信息 /var/lib/mysql/localhost-slow.log。 profile详情 show profiles 能够在做SQL优化时帮助我们了解时间都耗费到哪里去了。通过have_profiling参数，能够看到当前MySQL是否支持 profile操作： SELECT @@have_profiling; 默认profiling是关闭的，可以通过set语句在session/global级别开启profiling： SET profiling=1; 执行一系列的业务SQL的操作，然后通过如下指令查看指令的执行耗时: # 查看每一条SQL的耗时基本情况 show profiles; # 查看指定query_id的SQL语句各个阶段的耗时情况 show profile for query query_id; # 查看指定query_id的SQL语句CPU的使用情况 show profile cpu for query query_id; explain执行计划 EXPLAIN 或者 DESC命令获取 MySQL 如何执行 SELECT 语句的信息，包括在 SELECT 语句执行过程中表如何连接和连接的顺序。 语法： EXPLAIN SELECT 字段列表 FROM 表名 WHERE 条件; EXPLAIN 执行计划各字段含义： Id select查询的序列号，表示查询中执行select子句或者是操作表的顺序(id相同，执行顺序从上到下；id不同，值越大，越先执行)。 select_type 表示 SELECT 的类型，常见的取值有 SIMPLE（简单表，即不使用表连接或者子查询）、PRIMARY（主查询，即外层的查询）、UNION（UNION 中的第二个或者后面的查询语句）、SUBQUERY（SELECT/WHERE之后包含了子查询）等。 type 表示连接类型，性能由好到差的连接类型为NULL、system、const、eq_ref、ref、range、 index、all 。 possible_key 显示可能应用在这张表上的索引，一个或多个。 Key 实际使用的索引，如果为NULL，则没有使用索引。 Key_len 表示索引中使用的字节数， 该值为索引字段最大可能长度，并非实际使用长度，在不损失精确性的前提下， 长度越短越好 。 rows MySQL认为必须要执行查询的行数，在innodb引擎的表中，是一个估计值，可能并不总是准确的。 filtered 表示返回结果的行数占需读取行数的百分比， filtered 的值越大越好。 2.6 索引使用 验证索引效率 在未建立索引之前，执行如下SQL语句，查看SQL的耗时 SELECT * FROM tb_sku WHERE sn='10000003145001'; 针对字段创建索引 create index idx_std_sn on tb_sku(sn); 然后再次执行相同的SQL语句，再次查看SQL的耗时。 SELECT * FROM tb_sku WHERE sn='10000003145001'; 最左前缀法则 如果索引了多列（联合索引），要遵守最左前缀法则。最左前缀法则指的是查询从索引的最左列开始，并且不跳过索引中的列。如果跳跃某一列，索引将部分失效(后面的字段索引失效) explain select * from tb_user where profession='软件工程' and age=31 and status='0'; explain select * from tb_user where profession='软件工程' and age=31; explain select * from tb_user where profession='软件工程'; explain select * from tb_user where age=31 and status='0'; explain select * from tb_user where status='0'; 范围查询 联合索引中，出现范围查询(&gt;,&lt;)，范围查询右侧的列索引失效 explain select * from tb_user where profession='软件工程' and age&gt;31 and status='0'; explain select * from tb_user where profession='软件工程' and age&gt;=31 and status='0'; 索引列运算 不要在索引列上进行运算操作， 索引将失效。 explain select * from tb_user where substring(phone,10,2)='15'; 字符串不加引号 字符串类型字段使用时，不加引号， 索引将失效。 explain select * from tb_user where profession='软件工程' and age=31 and status=0; explain select * from tb_user where phone = 17799999019; 模糊查询如果仅仅是尾部模糊匹配，索引不会失效。如果是头部模糊匹配，索引失效。 explain select * from tb_user where profession like '软件%'； explain select * from tb_user where profession like '%软件%'； explain select * from tb_user where profession like '%软件'； or连接的条件 用or分割开的条件， 如果or前的条件中的列有索引，而后面的列中没有索引，那么涉及的索引都不会被用到。 explain select * from tb_user where id = 10 or age = 23; explain select * from tb_user where phone ='17777703456' or age = 24; 由于age没有索引，所以即使id、phone有索引，索引也会失效。所以需要针对于age也要建立索引。 数据分布影响 如果MySQL评估使用索引比全表更慢，则不使用索引。 explain select * from tb_user where phone &gt;='17777703456'; explain select * from tb_user where phone &gt;='17777703453'; SQL提示 SQL提示，是优化数据库的一个重要手段，简单来说，就是在SQL语句中加入一些人为的提示来达到优化操作的目的。 use index explain select * from tb_user use index(idx_user_pro) where profession='软件工程'; ignore index explain select * from tb_user ignore index(idx_user_pro) where profession='软件工程'; force index explain select * from tb_user force index(idx_user_pro) where profession='软件工程'; 覆盖索引 尽量使用覆盖索引（查询使用了索引，并且需要返回的列，在该索引中已经全部能够找到），减少select *; explain select id,profession from tb_user where profession='软件工程' and age=31 and status='0'; explain select id,profession,age,status from tb_user where profession='软件工程' and age=31 and status='0'; explain select id,profession,age,status,name from tb_user where profession='软件工程' and age=31 and status='0'; explain select * from tb_user where profession='软件工程' and age=31 and status='0'; using index condition ：查找使用了索引，但是需要回表查询数据 using where; using index ：查找使用了索引，但是需要的数据都在索引列中能找到，所以不需要回表查询数据 前缀索引 当字段类型为字符串（varchar，text等）时，有时候需要索引很长的字符串，这会让索引变得很大，查询时，浪费大量的磁盘IO， 影响查询效率。此时可以只将字符串的一部分前缀，建立索引，这样可以大大节约索引空间，从而提高索引效率。 语法 create index idx_xxxx on table_name(column(n)); 前缀长度 可以根据索引的选择性来决定，而选择性是指不重复的索引值（基数）和数据表的记录总数的比值，索引选择性越高则查询效率越高， 唯一索引的选择性是1，这是最好的索引选择性，性能也是最好的。 select count(distinct email)/ count(*) from tb_user; select count(distinct substring(email,1,5))/count(*) from tb_user; 前缀索引查询流程 单列索引与联合索引 单列索引：即一个索引只包含单个列。 联合索引：即一个索引包含了多个列。 在业务场景中，如果存在多个查询条件，考虑针对于查询字段建立索引时，建议建立联合索引，而非单列索引。 单列索引情况： explain select id ,phone, name from tb_user where phone='11234565642' and name = '韩信'; 多条件联合查询时， MySQL优化器会评估哪个字段的索引效率更高，会选择该索引完成本次查询。 联合索引情况：创建联合索引时，需要考虑顺序。 2.7 索引设计原则 表 针对于数据量较大，且查询比较频繁的表建立索引。（至少超过100w）。 字段 针对于常作为查询条件（where）、排序（order by）、分组（group by）操作的字段建立索引 尽量选择区分度高的列作为索引，尽量建立唯一索引，区分度越高，使用索引的效率越高。 如果是字符串类型的字段，字段的长度较长，可以针对于字段的特点，建立前缀索引。（数采仪的mn号，可以将mn号反转再建立前缀索引）。 索引 尽量使用联合索引，减少单列索引，查询时，联合索引很多时候可以覆盖索引，节省存储空间，避免回表，提高查询效率。 要控制索引的数量，索引并不是多多益善，索引越多，维护索引结构的代价也就越大，会影响增删改的效率。 如果索引列不能存储NULL值，请在创建表时使用NOT NULL约束它。当优化器知道每列是否包含NULL值时，它可以更好地确定哪个索引最有效地用于查询。 3. SQL优化3.1 插入数据 insert优化 批量插入 手动提交事务 start transaction; insert into tb_test values(1,'Tom'),(2,'Cat'),(3,'Jerry'); insert into tb_test values(4,'Tom'),(5,'Cat'),(6,'Jerry'); insert into tb_test values(7,'Tom'),(8,'Cat'),(9,'Jerry'); commit; 主键顺序插入 主键乱序插入 : 8 1 9 21 88 2 4 15 89 5 7 3 主键顺序插入 : 1 2 3 4 5 7 8 9 15 21 88 89 大批量插入数据 # 客户端连接服务端时，加上参数 --local-infile mysql --local-infile -u root -p # 设置全局参数local_infile为1 ，开启从本地加载文件导入数据的开关 set global local_infile=1; # 执行load指令将准备好的数据，加载到表结构中 load data local infile '/root/sql1.log' into table `tb_user` fields terminated by ',' lines terminated by '\\n'; 3.2 主键优化 数据组织方式 在InnoDB存储引擎中，表数据都是根据主键顺序组织存放的，这种存储方式的表称为索引组织表(index organized table IOT)。 页分裂 页可以为空，也可以填充一半，也可以填充100%。每个页包含了2-N行数据(如果一行数据多大，会行溢出)，根据主键排列。 页合并 当删除一行记录时，实际上记录并没有被物理删除，只是记录被标记（flaged）为删除并且它的空间变得允许被其他记录声明使用。 当页中删除的记录达到 MERGE_THRESHOLD（默认为页的50%），InnoDB会开始寻找最靠近的页（前或后）看看是否可以将两个页合并以优化空间使用。 主键设计原则 满足业务需求的情况下，尽量降低主键的长度。 插入数据时，尽量选择顺序插入，选择使用AUTO_INCREMENT自增主键。 尽量不要使用UUID做主键或者是其他自然主键，如身份证号。 业务操作时，避免对主键的修改。 3.3 order by优化 Using filesort ：通过表的索引或全表扫描，读取满足条件的数据行，然后在排序缓冲区 sort buffer中完成排序操作，所有不是通过索引直接返回排序结果的排序都叫FileSort排序。 Using index:通过有序索引顺序扫描直接返回有序数据，这种情况即为 using index，不需要额外排序，操作效率高。 # 没有创建索引时，根据age,phone进行排序 explain select id ,age,phone from tb_user order by age,phone; # 创建索引 create index idx_user_age_phone_aa on tb_user(age,phone); # 创建索引后，根据age,phone进行升序排序 explain select id ,age,phone from tb_user order by age,phone; # 创建索引后，根据age,phone进行降序排序 explain select id ,age,phone from tb_user order by age desc,phone desc; # 根据age,phone进行降序一个升序，一个降序 explain select id ,age,phone from tb_user order by age asc,phone desc; # 创建索引 create index idx_user_age_phone_ad on tb_user(age asc,phone desc); # 根据age,phone进行降序一个升序，一个降序 explain select id ,age,phone from tb_user order by age asc,phone desc; 根据排序字段建立合适的索引，多字段排序时，也遵循最左前缀法则。 尽量使用覆盖索引。 多字段排序 一个升序一个降序，此时需要注意联合索引在创建时的规则（ ASC/DESC）。 如果不可避免的出现 filesort，大数据量排序时，可以适当增大排序缓冲区大小 sort_buffer_size默认 (256k)。 3.4 group by优化# 删除掉目前的联合索引 idx_user_pro_age_sta drop index idx_user_pro_age_sta on tb_user; # 执行分组操作，根据profession字段分组 explain select profession, count(*) from tb_user group by profession; # 创建索引 create index idx_user_pro_age_sta on tb_user(profession,age,status); # 执行分组操作，根据profession字段分组 explain select profession, count(*) from tb_user group by profession; # 执行分组操作，根据profession字段分组 explain select profession, count(*) from tb_user group by profession,age; 在分组操作时，可以通过索引来提高效率。 分组操作时，索引的使用也是满足最左前缀法则的。 3.5 limit优化一个常见又非常头疼的问题就是 limit 2000000,10 ，此时需要MySQL排序前2000010 记录，仅仅返回2000000 - 2000010 的记录，其他记录丢弃，查询排序的代价非常大 。 优化思路: 一般分页查询时，通过创建 覆盖索引 能够比较好地提高性能，可以通过覆盖索引加子查询形式进行优化。 explain select t.* from tb_sku t, (select id from tb_sku order by id limit 2000000 ,10) a where t.id = a.id; 3.6 count优化explain select count(*) from tb_user; MyISAM 引擎把一个表的总行数存在了磁盘上，因此执行 count(*) 的时候会直接返回这个数，效率很高； InnoDB 引擎就麻烦了，它执行 count(*) 的时候，需要把数据一行一行地从引擎里面读出来，然后累积计数。 优化思路：mysql另外创建一张表维护或者redis维护。 count的几种用法 count() 是一个聚合函数，对于返回的结果集，一行行地判断，如果 count 函数的参数不是 NULL，累计值就加 1，否则不加，最后返回累计值。 用法：count（*）、count（主键）、count（字段）、count（1）。 count（主键） InnoDB 引擎会遍历整张表，把每一行的 主键id 值都取出来，返回给服务层。服务层拿到主键后，直接按行进行累加(主键不可能为null) count（主键） 没有not null 约束 : InnoDB 引擎会遍历整张表把每一行的字段值都取出来，返回给服务层，服务层判断是否为null，不为null，计数累加。 有not null 约束：InnoDB 引擎会遍历整张表把每一行的字段值都取出来，返回给服务层，直接按行进行累加。 count（常数） InnoDB 引擎遍历整张表，但不取值。服务层对于返回的每一行，放一个数字“1”进去，直接按行进行累加。 count(*) InnoDB引擎并不会把全部字段取出来，而是专门做了优化，不取值，服务层直接按行进行累加。 按照效率排序的话，count(字段) &lt; count(主键 id) &lt; count(1) ≈ count()，所以尽量使用 count()。 3.7 update优化update student set no='2222201010' where id =1 ; update student set no='2222201010' where name ='liutao' ; InnoDB的行锁是针对索引加的锁，不是针对记录加的锁 ,并且该索引不能失效，否则会从行锁升级为表锁 。 4. 锁在数据库中，除传统的计算资源（如CPU、RAM、I/O等）的争用以外，数据也是一种供许多用户共享的 资源。为保证数据的一致性，需要对 并发操作进行控制 ，因此产生了 锁 。同时 锁机制 也为实现MySQL 的各个隔离级别提供了保证。 锁冲突 也是影响数据库 并发访问性能 的一个重要因素。所以锁对数据库而 言显得尤其重要，也更加复杂 4.1 MySQL并发事务访问相同记录 读-读 读-读 情况，即并发事务相继 读取相同的记录 。读取操作本身不会对记录有任何影响，并不会引起什么 问题，所以允许这种情况的发生。 写写 写-写 情况，即并发事务相继对相同的记录做出改动 在这种情况下会发生 脏写 的问题，任何一种隔离级别都不允许这种问题的发生。所以在多个未提交事务 相继对一条记录做改动时，需要让它们 排队执行 ，这个排队的过程其实是通过 锁 来实现的。这个所谓 的锁其实是一个 内存中的结构 ，在事务执行前本来是没有锁的，也就是说一开始是没有 锁结构 和记录进 行关联的，如图所示： 当一个事务想对这条记录做改动时，首先会看看内存中有没有与这条记录关联的 锁结构 ，当没有的时候 就会在内存中生成一个 锁结构 与之关联。比如，事务 T1 要对这条记录做改动，就需要生成一个 锁结构 与之关联： 小结几种说法： 不加锁 意思就是不需要在内存中生成对应的 锁结构 ，可以直接执行操作。 获取锁成功，或者加锁成功 意思就是在内存中生成了对应的 锁结构 ，而且锁结构的 is_waiting 属性为 false ，也就是事务 可以继续执行操作。 获取锁失败，或者加锁失败，或者没有获取到锁 意思就是在内存中生成了对应的 锁结构 ，不过锁结构的 is_waiting 属性为 true ，也就是事务 需要等待，不可以继续执行操作。 读-写/写-读 读-写 或 写-读 ，即一个事务进行读取操作，另一个进行改动操作。这种情况下可能发生 脏读 、 不可重 复读 、 幻读 的问题。 方案1：读操作利用多版本并发控制（ MVCC），写操作进行 加锁 。 方案2：读、写操作都采用 加锁 的方式。 小结对比发现： 采用 MVCC 方式的话， 读-写 操作彼此并不冲突， 性能更高 。 采用 加锁 方式的话， 读-写 操作彼此需要 排队执行 ，影响性能。 一般情况下我们当然愿意采用 MVCC 来解决 读-写 操作并发执行的问题，但是业务在某些特殊情况 下，要求必须采用 加锁 的方式执行。 4.2 锁在不同角度的分类 4.2.1 从数据操作的类型划分：读锁、写锁读锁 ：也称为 共享锁 、英文用 S 表示。针对同一份数据，多个事务的读操作可以同时进行而不会互相影响，相互不阻塞的。也可以加排它锁。 写锁： 也称为 排他锁 、英文用 X 表示。当前写操作没有完成前，它会阻断其他写锁和读锁。这样就能确保在给定的时间里，只有一个事务能执行写入，并防止其他用户读取正在写入的同一资源。 需要注意的是对于 InnoDB 引擎来说，读锁和写锁可以加在表上，也可以加在行上。 4.2.2 从数据操作的粒度划分：表级锁、页级锁、行锁4.2.2.1 表锁（Table Lock）：可以避免死锁① 表级别的S锁、X锁 在对某个表执行SELECT、INSERT、DELETE、UPDATE语句时，InnoDB存储引擎是不会为这个表添加表级 别的 S锁 或者 X锁 的。在对某个表执行一些诸如 ALTER TABLE 、 DROP TABLE 这类的 DDL 语句时，其 他事务对这个表并发执行诸如SELECT、INSERT、DELETE、UPDATE的语句会发生阻塞。同理，某个事务 中对某个表执行SELECT、INSERT、DELETE、UPDATE语句时，在其他会话中对这个表执行 DDL 语句也会 发生阻塞。这个过程其实是通过在 server层 使用一种称之为 元数据锁 （英文名： Metadata Locks ，简称 MDL ）结构来实现的。 一般情况下，不会使用InnoDB存储引擎提供的表级别的 S锁 和 X锁 。只会在一些特殊情况下，比方说崩溃恢复 过程中用到。比如，在系统变量 autocommit=0，innodb_table_locks = 1 时， 手动 获取InnoDB存储引擎提供的表t 的 S锁 或者 X锁 可以这么写： LOCK TABLES t READ ：InnoDB存储引擎会对表 t 加表级别的 S锁 。 LOCK TABLES t WRITE ：InnoDB存储引擎会对表 t 加表级别的 X锁 。 不过尽量避免在使用InnoDB存储引擎的表上使用 LOCK TABLES 这样的手动锁表语句，它们并不会提供什么额外的保护，只是会降低并发能力而已。InnoDB的厉害之处还是实现了更细粒度的 行锁 ，关于InnoDB表级别的 S锁 和 X锁 大家了解一下就可以了。 MySQL的表级锁有两种模式：（以MyISAM表进行操作的演示，Innodb一般使用行锁，表锁的粒度太粗了，影响并发性能） 表共享读锁（Table Read Lock） 表独占写锁（Table Write Lock） ② 意向锁 （intention lock） 为了避免DML在执行时，加的行锁与表锁的冲突，在InnoDB中引入了意向锁，使得表锁不用检查每行数据是否加锁，使用意向锁来减少表锁的检查。 InnoDB 支持 多粒度锁（multiple granularity locking），它允许 行级锁 与 表级锁共存，而意向锁就是其中的一种表锁。 意向锁分为两种： 意向共享锁（intention shared lock, IS）：事务有意向对表中的某些行加共享锁（S锁） -- 事务要获取某些行的 S 锁，必须先获得表的 IS 锁。 SELECT column FROM table ... LOCK IN SHARE MODE; 意向排他锁（intention exclusive lock, IX）：事务有意向对表中的某些行加排他锁（X锁） -- 事务要获取某些行的 X 锁，必须先获得表的 IX 锁。 SELECT column FROM table ... FOR UPDATE; 即：意向锁是由存储引擎 自己维护的 ，用户无法手动操作意向锁，在为数据行加共享 / 排他锁之前，InooDB 会先获取该数据行 所在数据表的对应意向锁 。 意向锁的并发性 意向锁不会与行级的共享 / 排他锁互斥！正因为如此，意向锁并不会影响到多个事务对不同数据行加排他锁时的并发性。（不然我们直接用普通的表锁就行了） 即为IX与IS之间不会互斥。 总结： InnoDB 支持 多粒度锁 ，特定场景下，行级锁可以与表级锁共存。 意向锁之间互不排斥，但除了 IS 与 S 兼容外， 意向锁会与 共享锁 / 排他锁 互斥 。 IX，IS是表级锁，不会和行级的X，S锁发生冲突。只会和表级的X，S发生冲突。 即： IS-S(兼容) IS-X(不兼容) IX-S(不兼容) IX-X(不兼容) ​ IS-IS,IS-IX,IX-IS,IX-IX之间都是兼容的 意向锁在保证并发性的前提下，实现了 行锁和表锁共存 且 满足事务隔离性 的要求 ③元数据锁（MDL锁） MySQL5.5引入了meta data lock，简称MDL锁，属于表锁范畴。MDL 的作用是，保证读写的正确性。比如，如果一个查询正在遍历一个表中的数据，而执行期间另一个线程对这个 表结构做变更 ，增加了一列，那么查询线程拿到的结果跟表结构对不上，肯定是不行的。 因此，当对一个表做增删改查操作的时候，加MDL读锁（共享）；当要对表做结构变更操作的时候，加MDL写锁（排他）。 4.2.2.2 InnoDB中的行锁（Row Lock）：可能造成死锁① 记录锁（Record Locks） 记录锁也就是仅仅把一条记录锁上，官方的类型名称为： LOCK_REC_NOT_GAP 。比如我们把id值为8的那条记录加一个记录锁的示意图如图所示。仅仅是锁住了id值为8的记录，对周围的数据没有影响。 举例如下： 记录锁是有S锁和X锁之分的，称之为 S型记录锁 和 X型记录锁 。 当一个事务获取了一条记录的S型记录锁后，其他事务也可以继续获取该记录的S型记录锁，但不可以继续获取X型记录锁； 当一个事务获取了一条记录的X型记录锁后，其他事务既不可以继续获取该记录的S型记录锁，也不可以继续获取X型记录锁。 ② 间隙锁（Gap Locks） MySQL 在 REPEATABLE READ 隔离级别下是可以解决幻读问题的，解决方案有两种，可以使用 MVCC 方案解决，也可以采用 加锁 方案解决。但是在使用加锁方案解决时有个大问题，就是事务在第一次执行读取操作时，那些幻影记录尚不存在，我们无法给这些 幻影记录 加上 记录锁 。InnoDB提出了一种称之为Gap Locks 的锁，官方的类型名称为： LOCK_GAP ，我们可以简称为 gap锁 。比如，把id值为8的那条记录加一个gap锁的示意图如下。 图中id值为8的记录加了gap锁，意味着 不允许别的事务在id值为8的记录前边的间隙插入新记录 ，其实就是id列的值(3, 8)这个区间的新记录是不允许立即插入的。比如，有另外一个事务再想插入一条id值为4的新记录，它定位到该条新记录的下一条记录的id值为8，而这条记录上又有一个gap锁，所以就会阻塞插入操作，直到拥有这个gap锁的事务提交了之后，id列的值在区间(3, 8)中的新记录才可以被插入。 gap锁的提出仅仅是为了防止插入幻影记录而提出的。 结论：MySQL的锁机制 - 记录锁、间隙锁、临键锁 主键索引的间隙锁： 对于指定查询某一条记录的加锁语句，如果该记录不存在，会产生记录锁和间隙锁，如果记录存在，则只会产生记录锁，如：WHERE id= 5 FOR UPDATE; 对于查找某一范围内的查询语句，会产生间隙锁，如：WHERE id BETWEEN 5 AND 7 FOR UPDATE; 普通索引的间隙锁 在普通索引列上，不管是何种查询，只要加锁，都会产生间隙锁，这跟唯一索引不一样； 在普通索引跟唯一索引中，数据间隙的分析，数据行是优先根据普通索引排序，再根据唯一索引排序。 ③ 临键锁（Next-Key Locks） 有时候我们既想 锁住某条记录 ，又想 阻止 其他事务在该记录前边的 间隙插入新记录 ，所以InnoDB就提出了一种称之为 Next-Key Locks 的锁，官方的类型名称为： LOCK_ORDINARY ，我们也可以简称为next-key锁 。Next-Key Locks是在存储引擎 innodb 、事务级别在 可重复读 的情况下使用的数据库锁，innodb默认的锁就是Next-Key locks。 begin; select * from student where id &lt;=8 and id &gt; 3 for update; ④ 插入意向锁（Insert Intention Locks） 我们说一个事务在 插入 一条记录时需要判断一下插入位置是不是被别的事务加了 gap锁 （ next-key锁也包含 gap锁 ），如果有的话，插入操作需要等待，直到拥有 gap锁 的那个事务提交。但是InnoDB规定事务在等待的时候也需要在内存中生成一个锁结构，表明有事务想在某个 间隙 中 插入 新记录，但是现在在等待。InnoDB就把这种类型的锁命名为 Insert Intention Locks ，官方的类型名称为：LOCK_INSERT_INTENTION ，我们称为 插入意向锁 。插入意向锁是一种 Gap锁 ，不是意向锁，在insert操作时产生。 插入意向锁是在插入一条记录行前，由 INSERT 操作产生的一种间隙锁 。 事实上插入意向锁并不会阻止别的事务继续获取该记录上任何类型的锁。 4.2.3 悲观锁和乐观锁从对待锁的态度来看锁的话，可以将锁分成乐观锁和悲观锁，从名字中也可以看出这两种锁是两种看待数据并发的思维方式 。需要注意的是，乐观锁和悲观锁并不是锁，而是锁的设计思想 。 4.2.3.1 悲观锁悲观锁是一种思想，顾名思义，就是很悲观，对数据被其他事务的修改持保守态度，会通过数据库自身的锁机制来实现，从而保证数据操作的排它性。 悲观锁总是假设最坏的情况，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会 阻塞 直到它拿到锁（共享资源每次只给一个线程使用，其它线程阻塞，用完后再把资源转让给其它线程）。比如行锁，表锁等，读锁，写锁等，都是在做操作之前先上锁，当其他线程想要访问数据时，都需要阻塞挂起。Java中 synchronized 和 ReentrantLock 等独占锁就是悲观锁思想的实现。 4.2.3.2 乐观锁乐观锁认为对同一数据的并发操作不会总发生，属于小概率事件，不用每次都对数据上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，也就是不采用数据库自身的锁机制，而是通过程序来实现。在程序上，我们可以采用 版本号机制 或者 CAS机制 实现。乐观锁适用于多读的应用类型，这样可以提高吞吐量。在Java中 java.util.concurrent.atomic 包下的原子变量类就是使用了乐观锁begin; select * from student where id &lt;=8 and id &gt; 3 for update;的一种实现方式：CAS实现的。 乐观锁的版本号机制 在表中设计一个 版本字段 version ，第一次读的时候，会获取 version 字段的取值。然后对数据进行更新或删除操作时，会执行 UPDATE … SET version=version+1 WHERE version=version 。此时如果已经有事务对这条数据进行了更改，修改就不会成功。 乐观锁的时间戳机制 时间戳和版本号机制一样，也是在更新提交的时候，将当前数据的时间戳和更新之前取得的时间戳进行比较，如果两者一致则更新成功，否则就是版本冲突。你能看到乐观锁就是程序员自己控制数据并发操作的权限，基本是通过给数据行增加一个戳（版本号或者时间戳），从而证明当前拿到的数据是否最新。 从这两种锁的设计思想中，我们总结一下乐观锁和悲观锁的适用场景： 乐观锁 适合 读操作多 的场景，相对来说写的操作比较少。它的优点在于 程序实现 ， 不存在死锁问题，不过适用场景也会相对乐观，因为它阻止不了除了程序以外的数据库操作。 悲观锁 适合 写操作多 的场景，因为写的操作具有 排它性 。采用悲观锁的方式，可以在数据库层面阻止其他事务对该数据的操作权限，防止 读 - 写 和 写 - 写 的冲突。 5. InnoDB引擎5.1 逻辑结构 5.2 架构MySQL5.5 版本开始，默认使用InnoDB存储引擎，它擅长事务处理，具有崩溃恢复特性，在日常开发中使用非常广泛。下面是InnoDB架构图，左侧为内存结构，右侧为磁盘结构。 Buffer Pool：缓冲池是主内存中的一个区域，里面可以缓存磁盘上经常操作的真实数据，在执行增删改查操作时，先操作缓冲池中的数据（若缓冲池没有数据，则从磁盘加载并缓存），然后再以一定频率刷新到磁盘，从而减少磁盘IO，加快处理速度。 缓冲池以Page页为单位，底层采用链表数据结构管理Page。根据状态，将Page分为三种类型： free page：空闲page，未被使用。 clean page：被使用page，数据没有被修改过。 dirty page：脏页，被使用page，数据被修改过，也中数据与磁盘的数据产生了不一致。 Change Buffer：更改缓冲区（针对于非唯一二级索引页），在执行DML语句时，如果这些数据Page没有在Buffer Pool中，不会直接操作磁盘，而会将数据变更存在更改缓冲区 Change Buffer 中，在未来数据被读取时，再将数据合并恢复到Buffer Pool中，再将合并后的数据刷新到磁盘中。 Change Buffer的意义是什么? 与聚集索引不同，二级索引通常是非唯一的，并且以相对随机的顺序插入二级索引。同样，删除和更新可能会影响索引树中不相邻的二级索引页，如果每一次都操作磁盘，会造成大量的磁盘IO。有了ChangeBuffer之后，我们可以在缓冲池中进行合并处理，减少磁盘IO。 Adaptive Hash Index：自适应hash索引，用于优化对Buffer Pool数据的查询。InnoDB存储引擎会监控对表上各索引页的查询，如果观察到hash索引可以提升速度，则建立hash索引，称之为自适应hash索引。 自适应哈希索引，无需人工干预，是系统根据情况自动完成。 参数： adaptive_hash_index Log Buffer：日志缓冲区，用来保存要写入到磁盘中的log日志数据（redo log 、undo log），默认大小为 16MB，日志缓冲区的日志会定期刷新到磁盘中。如果需要更新、插入或删除许多行的事务，增加日志缓冲区的大小可以节省磁盘 I/O。 参数: innodb_log_buffer_size：缓冲区大小 innodb_flush_log_at_trx_commit：日志刷新到磁盘时机: 1: 日志在每次事务提交时写入并刷新到磁盘 0:每秒将日志写入并刷新到磁盘一次。 2:日志在每次事务提交后写入，并每秒刷新到磁盘 一次 System Tablespace：系统表空间是更改缓冲区的存储区域。如果表是在系统表空间而不是每个表文件或通用表空间中创建的，它也可能包含表和索引数据。(在MySQL5.x版本中还包含InnoDB数据字典、undolog等) 参数：innodb_data_file_path File-Per-Table Tablespaces：每个表的文件表空间包含单个InnoDB表的数据和索引 ，并存储在文件系统上的单个数据文件中。 参数：innodb_file_per_table General Tablespaces：通用表空间，需要通过 CREATE TABLESPACE 语法创建通用表空间，在创建表时，可以指定该表空间。 CREATE TABLESPACExx ADD DATAFILE 'file name' ENGINE=engine_name; CREATE TABLE xxx… TABLESPACE ts name; Undo Tablespaces：撤销表空间，MySQL实例在初始化时会自动创建两个默认的undo表空间（初始大小16M），用于存储undo log日志。 Temporary Tablespaces：InnoDB 使用会话临时表空间和全局临时表空间。存储用户创建的临时表等数据。 1. Master Thread 核心后台线程，负责调度其他线程，还负责将缓冲池中的数据异步刷新到磁盘中, 保持数据的一致性，还包括脏页的刷新、合并插入缓存、undo页的回收 。 2. IO Thread 在InnoDB存储引擎中大量使用了AIO来处理IO请求, 这样可以极大地提高数据库的性能，而IO Thread主要负责这些IO请求的回调。 3. Purge Thread 主要用于回收事务已经提交了的undo log，在事务提交之后，undo log可能不用了，就用它来回收。 4. Page Cleaner Thread 协助 Master Thread 刷新脏页到磁盘的线程，它可以减轻 Master Thread 的工作压力，减少阻塞。 5.3 事务 事务 事务 是一组操作的集合，它是一个不可分割的工作单位，事务会把所有的操作作为一个整体一起向系统提交或撤销操作请求，即这些操作要么同时成功，要么同时失败 特性： 原子性（Atomicity）：事务是不可分割的最小操作单元，要么全部成功，要么全部失败。 一致性（Consistency）：事务完成时，必须使所有的数据都保持一致状态 隔离性（Isolation）：数据库系统提供的隔离机制，保证事务在不受外部并发操作影响的独立环境下运行。 持久性（Durability）：事务一旦提交或回滚，它对数据库中的数据的改变就是永久的。 redo log(持久性) 重做日志，记录的是事务提交时数据页的物理修改，是用来实现事务的持久性。 该日志文件由两部分组成：重做日志缓冲（redo log buffer）以及重做日志文件（redo log file）,前者是在内存中，后者在磁盘中。当事务提交之后会把所有修改信息都存到该日志文件中, 用于在刷新脏页到磁盘,发生错误时, 进行数据恢复使用。 undo log(原子性) 回滚日志，用于记录数据被修改前的信息 , 作用包含两个 : 提供回滚 和 MVCC(多版本并发控制) 。 undo log和redo log记录物理日志不一样，它是逻辑日志。可以认为当delete一条记录时，undo log中会记录一条对应的insert记录，反之亦然，当update一条记录时，它记录一条对应相反的update记录。当执行rollback时，就可以从undo log中的逻辑记录读取到相应的内容并进行回滚。 Undo log销毁：undo log在事务执行时产生，事务提交时，并不会立即删除undo log，因为这些日志可能还用于MVCC。 Undo log存储：undo log采用段的方式进行管理和记录，存放在前面介绍的 rollback segment 回滚段中，内部包含1024个undo log segment。 5.4 MVCC5.4.1 基本概念 当前读 读取的是记录的最新版本，读取时还要保证其他并发事务不能修改当前记录，会对读取的记录进行加锁。对于我们日常的操作，如：select … lock in share mode(共享锁)，select … for update、update、insert、delete(排他锁)都是一种当前读。 快照读 简单的select（不加锁）就是快照读，快照读，读取的是记录数据的可见版本，有可能是历史数据，不加锁，是非阻塞读。 Read Committed：每次select，都生成一个快照读。 Repeatable Read：开启事务后第一个select语句才是快照读的地方。 Serializable：快照读会退化为当前读。 MVCC 全称 Multi-Version Concurrency Control，多版本并发控制。指维护一个数据的多个版本，使得读写操作没有冲突，快照读为MySQL实现MVCC提供了一个非阻塞读功能。MVCC的具体实现，还需要依赖于数据库记录中的三个隐式字段、undo log日志、readView。 5.4.2 MVCC-实现原理 记录隐藏字段 undo log 回滚日志，在insert、update、delete的时候产生的便于数据回滚的日志。 当insert的时候，产生的undo log日志只在回滚时需要，在事务提交后，可被立即删除。 而update、delete的时候，产生的undo log日志不仅在回滚时需要，在快照读时也需要，不会立即被删除。 undo log 版本链 不同事务或相同事务对同一条记录进行修改，会导致该记录的undolog生成一条记录版本链表，链表的头部是最新的旧记录，链表尾部是最早的旧记录。 readview ReadView（读视图）是 快照读 SQL执行时MVCC提取数据的依据，记录并维护系统当前活跃的事务（未提交的）id。 ReadView中包含了四个核心字段： 不同的隔离级别，生成ReadView的时机不同： READ COMMITTED ：在事务中每一次执行快照读时生成ReadView。 RC隔离级别下，在事务中每一次执行快照读时生成ReadView。 REPEATABLE READ：仅在事务中第一次执行快照读时生成ReadView，后续复用该ReadView。 5.4.3 RR隔离级别下的幻写问题https://blog.csdn.net/weixin_36380516/article/details/115291399 https://zhuanlan.zhihu.com/p/103580034 6 MySQL管理6.1 系统数据库Mysql数据库安装完成后，自带了一下四个数据库，具体作用如下： mysql: 存储MySQL服务器正常运行所需要的各种信息（时区、主从、用户、权限等） information_schema: 提供了访问数据库元数据的各种表和视图，包含数据库、表、字段类型及访问权限等 performance_schema: 为MySQL服务器运行时状态提供了一个底层监控功能，主要用于收集数据库服务器性能参数 sys: 包含了一系列方便DBA 和开发人员利用performance_schema性能数据库进行性能调优和诊断的视图 6.2 常用工具 mysql 该mysql不是指mysql服务，而是指mysql的客户端工具 -e选项可以在Mysql客户端执行SQL语句，而不用连接到MySQL数据库再执行，对于一些批处理脚本，这种方式尤其方便。 mysql -uroot -p1234 db01 -e \"select * from stu\"; mysqladmin mysqladmin 是一个执行管理操作的客户端程序。可以用它来检查服务器的配置和当前状态、创建并删除数据库等。 mysqlbinlog 由于服务器生成的二进制日志文件以二进制格式保存，所以如果想要检查这些文本的文本格式，就会使用到mysqlbinlog 日志管理工具。 mysqlshow mysqlshow 客户端对象查找工具，用来很快地查找存在哪些数据库、数据库中的表、表中的列或者索引。 mysqldump mysqldump 客户端工具用来备份数据库或在不同数据库之间进行数据迁移。备份内容包含创建表，及插入表的SQL语句。 mysqlimport/source mysqlimport 是客户端数据导入工具，用来导入mysqldump 加 -T 参数后导出的文本文件。 如果需要导入sql文件,可以使用mysql中的source 指令 :","categories":[{"name":"Mysql进阶篇","slug":"Mysql进阶篇","permalink":"https://bowonqin.github.io/categories/Mysql%E8%BF%9B%E9%98%B6%E7%AF%87/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"https://bowonqin.github.io/tags/Mysql/"},{"name":"数据库","slug":"数据库","permalink":"https://bowonqin.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"author":"qxd"},{"title":"","slug":"常见问题/微服务启动超时","date":"2022-01-02T08:16:08.000Z","updated":"2022-01-02T08:20:45.927Z","comments":true,"path":"posts/asdas.html","link":"","permalink":"https://bowonqin.github.io/posts/asdas.html","excerpt":"","text":"微服务docker启动超时问题使用docker运行一个中型的项目，包含40多个微服务及相关数据库的docker。由于docker-compose up 同时启动的服务过多，超过了请求HTTP限制的60s时间仍未全部成功启动起来，所以出现了超时错误： ERROR: An HTTP request took too long to complete. Retry with --verbose to obtain debug information. If you encounter this issue regularly because of slow network conditions, consider setting COMPOSE_HTTP_TIMEOUT to a higher value (current value: 60). 其中60s是默认的时间。 解决思路 把 COMPOSE_HTTP_TIMEOUT 的值调大，并转为环境变量即可。 解决步骤 先进入/etc/profile配置文件，执行命令： vi /etc/profile 然后在尾部添加上下面代码： export COMPOSE_HTTP_TIMEOUT=500 export DOCKER_CLIENT_TIMEOUT=500 接着使/etc/profile配置文件生效，执行命令： source /etc/profile 最后重新执行命令 docker-compose up 即可。","categories":[{"name":"常见问题","slug":"常见问题","permalink":"https://bowonqin.github.io/categories/%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/"}],"tags":[{"name":"常见问题","slug":"常见问题","permalink":"https://bowonqin.github.io/tags/%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/"},{"name":"docker","slug":"docker","permalink":"https://bowonqin.github.io/tags/docker/"}],"author":"qxd"},{"title":"SpringCloud Gateway 自定义全局过滤器不生效","slug":"常见问题/spring-cloud-gateway-自定义全局过滤器不生效","date":"2022-01-01T12:38:15.000Z","updated":"2022-04-15T13:18:09.790Z","comments":true,"path":"posts/springcloud-gateway-zi-ding-yi-quan-ju-guo-lu-qi-bu-sheng-xiao-wen-ti.html","link":"","permalink":"https://bowonqin.github.io/posts/springcloud-gateway-zi-ding-yi-quan-ju-guo-lu-qi-bu-sheng-xiao-wen-ti.html","excerpt":"","text":"spring cloud gateway 自定义全局过滤器不生效springboot的启动类不在包的最外层，导致过滤器的@Component注解不生效，也就是bean没有在spring中实例化。","categories":[{"name":"常见问题","slug":"常见问题","permalink":"https://bowonqin.github.io/categories/%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/"}],"tags":[{"name":"常见问题","slug":"常见问题","permalink":"https://bowonqin.github.io/tags/%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/"}],"author":"qxd"},{"title":"idea在debug模式下查看集合内部结构","slug":"常见问题/idea在debug模式下查看集合内部结构","date":"2021-12-31T04:05:49.000Z","updated":"2021-12-31T04:12:57.555Z","comments":true,"path":"posts/asdas.html","link":"","permalink":"https://bowonqin.github.io/posts/asdas.html","excerpt":"","text":"idea在debug模式下查看集合内部结构idea对集合类调试的时候自己做了视图 忽略掉了集合的内部结构，在下面的位置关闭就可以看到原有的集合视图 以调试ArrayList为例对比 未关闭Enable alternative view for Collection classes选项时： 关闭Enable alternative view for Collection classes选项时：","categories":[{"name":"常见问题","slug":"常见问题","permalink":"https://bowonqin.github.io/categories/%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/"}],"tags":[{"name":"常见问题","slug":"常见问题","permalink":"https://bowonqin.github.io/tags/%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/"},{"name":"idea","slug":"idea","permalink":"https://bowonqin.github.io/tags/idea/"}],"author":"qxd"},{"title":"java集合专题(Set)","slug":"java基础/java集合专题-Set","date":"2021-12-30T11:10:10.000Z","updated":"2021-12-31T13:51:41.182Z","comments":true,"path":"posts/b2440e5a.html","link":"","permalink":"https://bowonqin.github.io/posts/b2440e5a.html","excerpt":"","text":"SetSet接口的常用方法和List接口一样，Set接口也是Collection接口的子接口，因此，常用方法和Collection接口一样 Set的遍历方式同Collection接口的遍历方式一样，因为Set接口是Collection接口的子接口 迭代器遍历 增强for 不能使用按索引的方式来获取 @Test public void test1() { // 1. Set接口的实现类HashSet讲解Set接口的使用方法 // 2. set接口的实现类的对象（Set接口对象），不能存放重复的数据，可以添加一个null // 3. set接口对象存放数据是无序的（即添加的顺序和取出的顺序不一致） // 4. 注意： 取出的顺序虽然不是添加的顺序，但是它固定 Set&lt;String&gt; set = new HashSet&lt;&gt;(); set.add(\"john1\"); set.add(\"john2\"); set.add(\"john2\"); // 重复数据 set.add(\"john4\"); set.add(null); set.add(null); for (int i = 0; i &lt; 10; i++) { System.out.println(set); } // 遍历 // 方式1： 使用迭代器 System.out.println(\"=========使用迭代器=======\"); Iterator&lt;String&gt; iterator = set.iterator(); while (iterator.hasNext()) { String next = iterator.next(); System.out.println(next); } // 方式2： 增强for System.out.println(\"=========增强for=======\"); for (String s : set) { System.out.println(s); } set.remove(null); System.out.println(set); } HashSet HashSet的全面说明 HashSet实现了Set接口 HashSet实际上是HashMap，构造函数源码: public HashSet() { map = new HashMap&lt;&gt;(); } 可以存放null，但是只能存放一个null HashSet不能保证元素是有序的，取决于hash后再确定索引结果（即无法保证存放元素和取出元素的顺序一致） 不能有重复的对象/元素 HashSet的底层机制说明 分析HashSet的底层是HashMap,HashMap的底层是（数组+链表+红黑树） HashSet底层机制说明 分析hashSet添加元素底层是如何实现的（hash() +equals()） Debug+源码解析 @Test public void test7() { HashSet&lt;String&gt; set = new HashSet&lt;&gt;(); set.add(\"java\"); // 到此位置，第1次add分析完毕 set.add(\"php\");// 到此位置，第2次add分析完毕 set.add(\"java\"); System.out.println(set); } /////////////////////////////////////// [java, php] 源码：断点打在第一个java处 执行构造器 public HashSet() { map = new HashMap&lt;&gt;(); } 执行add() public boolean add(E e) { // e = ”java\" // private static final Object PRESENT = new Object(); return map.put(e, PRESENT)==null; } 执行put,该方法会执行hash(key)得到key对应的hash值算法h = key.hashCode()^ (h &gt;&gt;&gt; 16) static final int hash(Object key) { int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16); } 执行putVal()方法 final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) { Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; // table就是Hashmap的一个数组，类型是[] // if语句表示如果当前table为null,或者大小为0 // 就是第一次扩容到16空间（resize()为扩容方法） if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; // (1)根据key的得到hash去计算该key应该存放到table表的哪个索引位置, 并且把这个位置的对象赋给p // (2) 判断p是否为null // (2.1) 如果p为null,表示还没有存放元素，就创建一个Node(key=\"java\" value=PRESENT) // (2.2) 就放在该位置 tab[i] = newNode(hash, key, value, null); // 第一次用到了hash值，这里的hash是确定Node插入在Node[]的哪个位置 if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null); else { // 一个开发技巧提示：在需要局部变量时再创建 Node&lt;K,V&gt; e; K k; // 当前索引位置对应链表的第一个元素和准备添加的key的hash值一样并且满足下面两个条件之一 // (1) 准备加入的key和p指向的Node节点的key是同一个对象 // (2) p指向的Node节点的key的eqauls()和准备加入的key比较后相同 // 满足上述两个条件就不能加入，说明元素重复了 // 这里的hash配合equals()使用 if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; // 再判断p是不是一颗红黑树 // 如果是一颗红黑树，就调用putTreeVal,来进行添加 else if (p instanceof TreeNode) e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); // hash值相同，equals不能的情况，通过在Node挂载在链表后面方式实现 else { // 如果table对应索引位置，已经是一个链表，就使用for循环 for (int binCount = 0; ; ++binCount) { // （1） 依次和该链表的每一个元素比较后，都不相同，就添加到该链表的最后 if ((e = p.next) == null) { p.next = newNode(hash, key, value, null); // 注意在把元素添加到链表后，立即判断该链表是否已经达到8个结点 if (binCount &gt;= TREEIFY_THRESHOLD - 1) // TREEIFY_THRESHOLD = 8 // 就调用treeifyBin()对当前这个链表进行树化（转成红黑树） // 注意，在转成红黑树时，要进行判断，如果该table数组的大小&lt;64 resize() // 先扩容，再转红黑树 treeifyBin(tab, hash); /** final void treeifyBin(Node&lt;K,V&gt;[] tab, int hash) { int n, index; Node&lt;K,V&gt; e; if (tab == null || (n = tab.length) &lt; MIN_TREEIFY_CAPACITY) // 64 resize(); }else ....... } **/ break; } // （2） 依次和该链表的每一个元素比较过程中，如果有相同的情况，就直接break if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; } } if (e != null) { // existing mapping for key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; } } ++modCount; // 就是我们每加入一个节点Node(k,v,h,next),size就会++ if (++size &gt; threshold) resize(); afterNodeInsertion(evict); return null; } 总结： HashSet底层是HashMap 添加一个元素时，先得到hash值, 转化为索引 找到存储数据表table，看这个索引位置是否已经存放有元素 如果没有，就直接加入 如果有，调用equals比较，如果相同就放弃添加，如果不相同，就添加到最后 在JDK8中，如果一条链表的元素个数TREEIFY_THRESHOLD（默认 = 8），并且table大小&gt;=MIN_TREEIFY_CAPACITY（默认=64），就会进行树化（红黑树） 注意： ​ 当我们向hashset增加一个元素时，-&gt;Node-&gt;加入table,就算是增加了一个元素。 ​ 即无论是加在Node[]的Node第一个节点上还是挂载在Node后面指向的节点上都算size++ @Test public void test9(){ // 当我们向hashset增加一个元素时，-&gt;Node-&gt;加入table,就算是增加了一个 // 即无论是加在Node[]的Node第一个节点上还是挂载在Node后面指向的节点上都算size++ HashSet&lt;Object&gt; objects = new HashSet&lt;&gt;(); for (int i = 0; i &lt; 7; i++) { // 在table的某条链表上增加7个A对象 objects.add(new A(i)); } for (int i = 0; i &lt; 7; i++) { // 在table的某条链表上增加7个B对象 objects.add(new B(i)); } System.out.println(objects); } 此时table扩容到32 HashSet底层机制说明 HashSet底层为HashMap,第一次添加时，table数组扩容到16，临界值（threshold）是16*（loadFactor ）是0.75 = 12 如果table数组使用到了临界值12，就会扩容到16*2 = 32，新的临界值就是32乘以0.75 = 24 在JDK8中，如果一条链表的元素个数TREEIFY_THRESHOLD（默认 = 8），并且table大小&gt;=MIN_TREEIFY_CAPACITY（默认=64），就会进行树化（红黑树） LinkedHashSet LinkedHashSet全面说明 LinkedHashSet是HashSet的子类 LinkedHashSet底层是一个LinkedHashMap,底层维护了一个数组+双向链表，每个结点有pre和next属性，这样可以形成双向链表 在添加一个元素时，先求hash值再求索引，确定该元素在hashtable的位置，然后将添加的元素加入到双向链表（如果已经存在，不添加【原则和HashSet一样】） LinkedHashSet根据元素的hashCode值确定元素的存储位置，同时使用链表维护元素的次数，这使得元素看起来是以插入顺序保存的。 LinkedHashSet不允许重复添加元素 @Test public void test1(){ Set set = new LinkedHashSet(); set.add(new String(\"AA\")); set.add(456); set.add(456); set.add(new Customer(\"刘\",1001)); set.add(456) // 1.LinkedHashSet 加入顺序和取出元素/数据的顺序一致 // 2.LinkedHashSet 底层维护的是LinkedHashMap(是HashMap的子类) // 3. LinkedHashSet底层结构（数组+双向链表） // 4.添加第一次时，直接将 数组table扩容到16，存放的结点类型是LinkedHashMap$Entry // 5. 数组是HashMap$Node[] 存放的数据是LinkedHashMap$Entry类型 // 继承关系是内部类完成的 // static class Entry&lt;K,V&gt; extends HashMap.Node&lt;K,V&gt; { // LinkedHashMap.Entry&lt;K,V&gt; before, after; // Entry(int hash, K key, V value, HashMap.Node&lt;K,V&gt; next) { // super(hash, key, value, next); // } // } System.out.println(set); }","categories":[{"name":"java基础","slug":"java基础","permalink":"https://bowonqin.github.io/categories/java%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"java基础","slug":"java基础","permalink":"https://bowonqin.github.io/tags/java%E5%9F%BA%E7%A1%80/"},{"name":"java集合","slug":"java集合","permalink":"https://bowonqin.github.io/tags/java%E9%9B%86%E5%90%88/"}],"author":"qxd"},{"title":"java集合专题(ArrayList)","slug":"java基础/java集合框架","date":"2021-12-27T11:56:57.000Z","updated":"2021-12-31T13:40:39.099Z","comments":true,"path":"posts/java-ji-he-arraylist.html","link":"","permalink":"https://bowonqin.github.io/posts/java-ji-he-arraylist.html","excerpt":"","text":"java集合专题(ArrayList)集合的理解和好处数组的不足之处 长度开始时必须指定，一旦指定，无法更改 保存的必须为同一类型的元素 数组增加/删除元素比较麻烦 // 数组扩容 @Test public void test1(){ Person[] people = new Person[1]; people[0] = new Person(); // 增加新的Person对象 Person[] people1 = new Person[people.length + 1]; for (int i = 0; i &lt; people.length; i++) { people1[i] = people[i]; } people1[people1.length - 1] = new Person(); // 添加新的对象 } 集合的好处 动态保存任意多个对象，使用比较方便 提供了一系列方便操作对象的方法：add、remove、set、get等 使用集合添加删除元素比较简单明了 集合框架体系（重要，需要背下来）主要分为两大类 Collection接口 单列集合 Map接口 双列集合 键值对的形式存在 Collection接口和常用方法 Collection接口的遍历元素的方式1-使用Iterator(迭代器) Iterator对象成为迭代器，主要用于遍历Collection集合中的元素 所有实现了Collection接口的集合类都有一个iterator()方法，用以返回一个实现了Iterator接口的对象，即返回一个迭代器 Iterator仅仅用于遍历集合，Iterato本身并不存在对象 迭代器执行原理： ​ Iterator接口的方法： hasNext(): 判断有没有下一个元素 next()：返回下一个元素的值 remove() 注意：在调用iterator.next()方法之前必须调用iterator.hasNext()进行检测。若不调用，下一条记录无效时会抛出NoSuchElementException异常。 public class CollectionIterator { public static void main(String[] args) { Collection&lt;Book&gt; books = new ArrayList&lt;&gt;(); books.add(new Book(\"三国演义\",\"罗贯中\",10.1)); books.add(new Book(\"红楼梦\",\"曹雪芹\",10.2)); books.add(new Book(\"西游记\",\"吴承恩\",11.1)); // 1.先得到books对应的迭代器 Iterator&lt;Book&gt; iterator = books.iterator(); // 2. while 判断是否还有数据 while (iterator.hasNext()){ Book book = iterator.next(); System.out.println(\"book = \" + book); } // 快捷键 快速生成while=&gt;itit // ctrl+j 显示所有快捷键的快捷键 // 3.当退出while循环后，这是iterator迭代器指向最后的元素 // iterator.next(); // 抛异常 java.util.NoSuchElementException // 4.如果希望再次遍历，需要重置迭代器 iterator = books.iterator(); } } class Book{ private String name; private String author; private double price; public Book(String name, String author, double price) { this.name = name; this.author = author; this.price = price; } public String getName() { return name; } public void setName(String name) { this.name = name; } public String getAuthor() { return author; } public void setAuthor(String author) { this.author = author; } public double getPrice() { return price; } public void setPrice(double price) { this.price = price; } @Override public String toString() { return \"Book{\" + \"name='\" + name + '\\'' + \", author='\" + author + '\\'' + \", price=\" + price + '}'; } } Collection接口遍历对象方式2- for循环增强 增强for循环，可以代替iterator迭代器，特点：增强for循环就是简化版的iterator,本质一样，只能用于遍历集合或数组 基本语法： for(元素类型 元素名： 集合名或数组名){ ​ 访问元素 } public class CollectionFor { public static void main(String[] args) { Collection&lt;Book&gt; books = new ArrayList&lt;&gt;(); books.add(new Book(\"三国演义\",\"罗贯中\",10.1)); books.add(new Book(\"红楼梦\",\"曹雪芹\",10.2)); books.add(new Book(\"西游记\",\"吴承恩\",11.1)); // 增强for 集合或数组 // 底层还是迭代器 // 简化版的迭代器 for (Book book : books) { System.out.println(\"book = \" + book); } } } List接口常用和常用方法List接口基本介绍： List接口是Collection接口的子接口 List集合类的元素有序（添加和取出的顺序一致）、且可重复 List集合中的每个元素都有对应的索引，即支持索引 List容器中的元素都对应一个整型的序号记载其在容器中的位置，根据序号取出容器中的元素 JDK常用实现类：ArrayLsit、LinkedList、Vector public class List_ { public static void main(String[] args) { // 1.List集合中的元素有序（添加和取出的顺序一致）、可重复 List&lt;Object&gt; list = new ArrayList&lt;&gt;(); list.add(\"jack\"); list.add(\"tom\"); list.add(\"hhh\"); list.add(\"jack\"); System.out.println(list); //2. List集合的每个元素都有其对应的顺序索引，支持索引 0开始的 System.out.println(list.get(1)); } } List接口的常用方法 List集合里添加了一些根据索引来操作集合元素的方法 void add(int index, Object ele): 在index位置插入ele元素 boolean addAll(int index, Collection eles): index位置添加eles Object get(int index): 获取索引为index的元素 int indexOf(Object obj): obj在集合中首次出现的位置 int lastIndexOf(Object obj): obj在集合中最后一次出现的位置 Object remove(int index): 移除index位置上的元素并返回 Object set(int index, Object ele): 设置index的元素为ele List subList(int fromIndex,int toIndex): 返回从fromIndex到toIndex位置的子集合，前闭后开 public class ListMethod { public static void main(String[] args) { List&lt;Object&gt; list = new ArrayList&lt;&gt;(); // add方法 list.add(\"jack\"); list.add(\"tom\"); list.add(\"mary\"); // add(index) list.add(1,\"hsp\"); System.out.println(list); // addAll方法 ArrayList&lt;Object&gt; list2 = new ArrayList&lt;&gt;(); list2.add(\"new1\"); list2.add(\"new2\"); list2.add(\"new1\"); list.addAll(1,list2); System.out.println(list); // Object get(int index): 获取索引为index的元素 System.out.println(list.indexOf(\"tom\")); // int lastIndexOf(Object obj): obj在集合中最后一次出现的位置 System.out.println(list.lastIndexOf(\"new1\")); // Object remove(int index): 移除index位置上的元素并返回 System.out.println(list.remove(0)); System.out.println(list); //Object set(int index, Object ele): 设置index的元素为ele list.set(1,\"1111\"); System.out.println(list); //List subList(int fromIndex,int toIndex): 返回从fromIndex到toIndex位置的子集合 List&lt;Object&gt; objects = list.subList(0, 1); System.out.println(objects); } } List的三种遍历方式[ArrayList,LinkedList,Vector] 方式1： iterator 方式2：增强for 方式3：普通for 方式4： foreach ArrayList源码分析本次使用的JDK版本为JDK1.8 案例一 空参构造 public class ArrayList_ { @Test public void test1(){ List list = new ArrayList(); } } 源码分析 public class ArrayList&lt;E&gt; extends AbstractList&lt;E&gt; implements List&lt;E&gt;, RandomAccess, Cloneable, java.io.Serializable { private static final long serialVersionUID = 8683452581122892189L; /** * 默认初始容量 */ private static final int DEFAULT_CAPACITY = 10; /** * 空数组. */ private static final Object[] EMPTY_ELEMENTDATA = {}; /** * * 默认容量的空数组 * */ private static final Object[] DEFAULTCAPACITY_EMPTY_ELEMENTDATA = {}; /** * * 储存集合元素的数组 */ transient Object[] elementData; // non-private to simplify nested class access /** * 集合的大小 */ private int size; public ArrayList() { this.elementData = DEFAULTCAPACITY_EMPTY_ELEMENTDATA; } } 空参构造时初始化为空数组 案例二 有参构造 public class ArrayList_ { @Test public void test1(){ List list = new ArrayList(10); } } 源码分析 public ArrayList(int initialCapacity) { if (initialCapacity &gt; 0) { this.elementData = new Object[initialCapacity]; } else if (initialCapacity == 0) { this.elementData = EMPTY_ELEMENTDATA; } else { throw new IllegalArgumentException(\"Illegal Capacity: \"+ initialCapacity); } } 输入的参数n &gt; 0时，初始化为长度为n的数组。 输入的参数n = 0时， 仍然赋值为空数组 输入的参数 n &lt; 0时则抛出异常 案例三 ArrayList(Collection&lt;? extends E&gt; c) public class ArrayList_ { @Test public void test1(){ ArrayList&lt;Object&gt; list1 = new ArrayList&lt;&gt;(); list1.add(1); list1.add(2); list1.add(3); list1.add(4); List list = new ArrayList(list1); } } 源码分析 public ArrayList(Collection&lt;? extends E&gt; c) { // 输入的Collection接口实现类转为数组赋给elementData elementData = c.toArray(); // elementData的长度赋值size,并判断是否等于0 if ((size = elementData.length) != 0) { // 判断elementData 和 Object[] 是否为不一样的类型 if (elementData.getClass() != Object[].class) //如果不一样,使用Arrays的copyOf方法进行元素的拷贝 elementData = Arrays.copyOf(elementData, size, Object[].class); } else { // 输入的Collection接口实现类长度为0，赋值为空数组 this.elementData = EMPTY_ELEMENTDATA; } } 初始化elementData和size,使将c拷贝给elementData，c的长度赋给size 注： Arrays.copyOf( )源码 public static &lt;T,U&gt; T[] copyOf(U[] original, int newLength, Class&lt;? extends T[]&gt; newType) { @SuppressWarnings(\"unchecked\") // //用三元运算符进行判断,不管结果如何都是创建一个新数组 T[] copy = ((Object)newType == (Object)Object[].class) ? (T[]) new Object[newLength] : (T[]) Array.newInstance(newType.getComponentType(), newLength); // 将数组的内容拷贝到 copy 该数组中 System.arraycopy(original, 0, copy, 0, Math.min(original.length, newLength)); // 返回拷贝元素成功后的数组 return copy; } public static native void arraycopy(Object src, int srcPos, Object dest, int destPos, int length); native:调用底层C语言写的程序 arraycopy（）作用：拷贝数组 src参数：源数组 srcPos参数：从src数组的第几个元素开始赋值 dest参数：目标数组 destPos参数：指定从dest数组的第几个元素开始。 length参数：指定从src数组拿几个元素来赋值到dest数组 需要注意src复制应该在dest的范围内，否则会报错 参考代码： @Test public void test2(){ int[] src_arr = {1,2,3,4}; int[] dest = new int[10]; System.arraycopy(src_arr,1,dest,6,3); System.out.println(Arrays.toString(dest)); } //////////////////////////////////////////////////// [0, 0, 0, 0, 0, 0, 2, 3, 4, 0] 相比于System.arraycopy()函数，Arrays.copy()函数自己生成dest数组并控制length，避免报错 @Test public void test2(){ Integer[] src_arr = {1,2,3,4}; Object[] ints = Arrays.copyOf(src_arr, 10,Object[].class); System.out.println(Arrays.toString(ints)); } //////////////////////////////////// [1, 2, 3, 4, null, null, null, null, null, null] 添加方法 public boolean add(E e) 添加单个元素 @Test public void test3(){ ArrayList&lt;Object&gt; list1 = new ArrayList&lt;&gt;(); list1.add(1); System.out.println(list1.toString()); } 底层源码 public boolean add(E e) { // 调用方法对内部容量进行校验 ensureCapacityInternal(size + 1); elementData[size++] = e; return true; } private void ensureCapacityInternal(int minCapacity) { //判断集合存数据的数组是否等于空容量的数组 if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) { //通过最小容量和默认容量 求出较大值 (用于第一次扩容) minCapacity = Math.max(DEFAULT_CAPACITY, minCapacity); } //将if中计算出来的容量传递给下一个方法,继续校验 ensureExplicitCapacity(minCapacity); } private void ensureExplicitCapacity(int minCapacity) { //实际修改集合次数++ (在扩容的过程中没用,主要是用于迭代器中) modCount++; //判断最小容量 - 数组长度是否大于 0 if (minCapacity - elementData.length &gt; 0) //将第一次计算出来的容量传递给 核心扩容方法 grow(minCapacity); } private void grow(int minCapacity) { //记录数组的实际长度,此时由于木有存储元素,长度为0 int oldCapacity = elementData.length; //核心扩容算法 原容量的1.5倍 int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1); //判断新容量 - 最小容量 是否小于 0, 如果是第一次调用add方法必然小于 if (newCapacity - minCapacity &lt; 0) //还是将最小容量赋值给新容量 newCapacity = minCapacity; //判断新容量-最大数组大小 是否&gt;0,如果条件满足就计算出一个超大容量 if (newCapacity - MAX_ARRAY_SIZE &gt; 0) newCapacity = hugeCapacity(minCapacity); // 调用数组工具类方法,创建一个新数组,将新数组的地址赋值给elementData elementData = Arrays.copyOf(elementData, newCapacity); } 检查数组的容量是否足够 足够：直接添加 不足：扩容 1.5倍扩容 第一次扩容后如果容量还是⼩于minCapacity，就将容量扩充为minCapacity，一般是初始化new ArrayList()时 第一次扩容： newCapacity = 0， minCapacity = 10 ===&gt;newCapacity = minCapacity = 10; public void add(int index, E element) 在指定索引处添加元素 public static void main(String[] args) { ArrayList&lt;Integer&gt; list1 = new ArrayList&lt;&gt;(); list1.add(1); list1.add(2); list1.add(3); list1.add(4); list1.add(5); list1.add(2,112); list1.add(6); System.out.println(list1.toString()); } ///////////////////////////// [1, 2, 112, 3, 4, 5, 6] 源码： public void add(int index, E element) { // 检查范围 rangeCheckForAdd(index); //调用方法检验是否要扩容,且让增量++ ensureCapacityInternal(size + 1); System.arraycopy(elementData, index, elementData, index + 1, size - index); elementData[index] = element; size++; } // 超出指定范围就报错 private void rangeCheckForAdd(int index) { if (index &gt; size || index &lt; 0) throw new IndexOutOfBoundsException(outOfBoundsMsg(index)); } 检查角标 空间检查，如果有需要就进行扩容 插入元素 删除方法 public E remove(int index)根据索引删除元素 @Test public void test122() { ArrayList&lt;Integer&gt; list1 = new ArrayList&lt;&gt;(); list1.add(1); list1.add(2); list1.remove(1); System.out.println(list1.toString()); } ///////////////////// [1] 源码： public E remove(int index) { // 范围检查 rangeCheck(index); //增量++ modCount++; //将index对应的元素赋值给 oldValue E oldValue = elementData(index); //计算集合需要移动元素个数 int numMoved = size - index - 1; //如果需要移动元素个数大于0,就使用arrayCopy方法进行拷贝 //注意:数据源和数据目的就是elementData if (numMoved &gt; 0) System.arraycopy(elementData, index+1, elementData, index, numMoved); //将源集合最后一个元素置为null,尽早让垃圾回收机制对其进行回收 elementData[--size] = null; // clear to let GC do its work //返回被删除的元素 return oldValue; } private void rangeCheck(int index) { // 传入的下标超过集合的大小就会抛异常 if (index &gt;= size) throw new IndexOutOfBoundsException(outOfBoundsMsg(index)); } E elementData(int index) { return (E) elementData[index]; } 无论是add方法还是remove方法，都是通过复制数组移位的方式实现。 步骤： 检查角标 计算需要移动的个数，移动 删除最后一个元素，设置为null，让GC回收 修改方法 public E set(int index, E element)根据索引修改集合元素 @Test public void test123() { ArrayList&lt;Integer&gt; list1 = new ArrayList&lt;&gt;(); list1.add(1); list1.add(2); list1.add(21); list1.add(22); list1.set(2,666666); System.out.println(list1.toString()); } //////////////////////////////////////////////// [1, 2, 666666, 22] 源码： public E set(int index, E element) { // 范围检查 rangeCheck(index); // 去旧值 E oldValue = elementData(index); // 设新值 elementData[index] = element; // 返回旧值 return oldValue; } 获取方法public E get(int index)根据索引获取元素 @Test public void test12113() { ArrayList&lt;Integer&gt; list1 = new ArrayList&lt;&gt;(); list1.add(1); list1.add(2); list1.add(21); list1.add(22); list1.get(3); System.out.println( list1.get(3)); } /////////////////////////////////////// 22 源码： public E get(int index) { // 范围检查 rangeCheck(index); // 取出索引中的值 return elementData(index); } 转换方法 public String toString() 把集合所有 @Test public void testStr() { ArrayList&lt;String&gt; list1 = new ArrayList&lt;&gt;(); list1.add(\"1\"); list1.add(\"2\"); list1.add(\"21\"); System.out.println( list1.toString()); } ////////////////////////////////////////////////// [1, 2, 21] 源码： public class ArrayList&lt;E&gt; extends AbstractList&lt;E&gt; { public Iterator&lt;E&gt; iterator() { return new Itr(); } //ArrayList集合内部类 private class Itr implements Iterator&lt;E&gt; { int cursor; int lastRet = -1; //将实际修改集合次数赋值给预期修改次数 ,注意只会赋值一次 // 以后在迭代器获取元素的时候,每次都会判断集合实际修改次数是否和预期修改次数一致 // 如果不一致就会产生并发修改异常 int expectedModCount = modCount; // 判断光标 和 集合的大小 是否不相等 // public boolean hasNext() { return cursor != size; } public E next() { checkForComodification(); int i = cursor; if (i &gt;= size) throw new NoSuchElementException(); Object[] elementData = ArrayList.this.elementData; if (i &gt;= elementData.length) throw new ConcurrentModificationException(); cursor = i + 1; return (E) elementData[lastRet = i]; } final void checkForComodification() { if (modCount != expectedModCount) throw new ConcurrentModificationException(); } } ///////////////////////////////////////////////////////// //ArrayList亲爹 public abstract class AbstractList&lt;E&gt; extends AbstractCollection&lt;E&gt; {} //ArrayList亲爷爷 public abstract class AbstractCollection&lt;E&gt; { public String toString() { //注意:此时相当于用ArrayList对象在调用iterator()方法 获取迭代器 //那么这个时候需要先看看ArrayList中的iterator()方法 Iterator&lt;E&gt; it = iterator(); //调用ArrayList中hasNext方法判断是否有元素,如果hasNext()方法返回false //那么就toString方法就返回一个 \"[]\" if (! it.hasNext()) return \"[]\"; //创建StringBuilder,对集合的内容进行拼接,避免字符串频繁拼接产生很多无效对象 StringBuilder sb = new StringBuilder(); sb.append('['); for (;;) { E e = it.next(); sb.append(e == this ? \"(this Collection)\" : e); if (! it.hasNext()) return sb.append(']').toString(); sb.append(',').append(' '); } } } 迭代器 public Iterator&lt;E&gt; iterator() 普通迭代器 迭代器遍历集合 @Test public void testIterator1() { ArrayList&lt;String&gt; list1 = new ArrayList&lt;&gt;(); list1.add(\"1\"); list1.add(\"2\"); list1.add(\"21\"); Iterator&lt;String&gt; iterator = list1.iterator(); while (iterator.hasNext()){ String next = iterator.next(); System.out.println(next); } } /////////////////////////////////////////////// 1 2 21 已知集合：List list = new ArrayList();里面有三个元素：”hello”、”Java”、”PHP”，使用迭代器遍历集合看有没有”PHP”这个元素，如果有，就使用集合对象删除该元素 // 创建集合对象 List&lt;String&gt; List list = new ArrayList&lt;String&gt;(); // 添加元素 list.add(\"hello\"); list.add(\"Java\"); list.add(\"PHP\"); // 获取迭代器 Iterator&lt;String&gt; it = list.iterator(); // 遍历集合 while (it.hasNext()) { String s = it.next(); if (s.equals(\"PHP\")) { list.remove(\"PHP\"); } } //////////////////////////////////////////// 并发修改异常 java.util.ConcurrentModificationException at java.util.ArrayList$Itr.checkForComodification(ArrayList.java:901) at java.util.ArrayList$Itr.next(ArrayList.java:851) at com.qxd.arraylist_.ArrayList_.testIterator2(ArrayList_.java:104) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50) at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47) at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17) at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325) at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78) at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57) at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290) at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71) at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288) at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58) at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268) at org.junit.runners.ParentRunner.run(ParentRunner.java:363) at org.junit.runner.JUnitCore.run(JUnitCore.java:137) at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68) at com.intellij.rt.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:33) at com.intellij.rt.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:230) at com.intellij.rt.junit.JUnitStarter.main(JUnitStarter.java:58) 源码：从迭代器中进入源码 public class ArrayList&lt;E&gt; { public Iterator&lt;E&gt; iterator() { return new Itr(); } // ArrayList内部类 private class Itr implements Iterator&lt;E&gt; { int cursor;// 光标，下一个要返回的索引值 int lastRet = -1; // 最后一个返回元素的索引 //将实际修改集合次数 赋值 给预期修改次数 //在迭代的过程中,只要实际修改次数和预期修改次数不一致就会产生并发修改异常 //由于expectedModCount是Itr的成员变量,那么只会被赋值一次!!! //同时由于集合调用了三次add方法,那么实际修改集合次数就是 3,因此expectedModCount的值也是 3 int expectedModCount = modCount; public boolean hasNext() { return cursor != size; } //获取元素的方法 public E next() { //每次获取元素,会先调用该方法校验 预期修改次数是否 == 实际修改次数 checkForComodification(); //把下一个元素的索引赋值给i int i = cursor; //判断是否有元素 if (i &gt;= size) throw new NoSuchElementException(); //将集合底层存储数据的数组赋值给迭代器的局部变量elementData Object[] elementData = ArrayList.this.elementData; //再次判断,如果下一个元素的索引大于集合底层存储元素的长度 并发修改异常 //注意,尽管会产生并发修改异常,但是这里显示不是我们要的结果 if (i &gt;= elementData.length) throw new ConcurrentModificationException(); //每次成功获取到元素,下一个元素的索引都是当前索引+1 cursor = i + 1; //返回元素 return (E) elementData[lastRet = i]; } final void checkForComodification() { //如果预期修改次数 和 实际修改次数不相等 就产生并发修改异常 if (modCount != expectedModCount) throw new ConcurrentModificationException(); } } //集合的remove方法 遍历的方法 public boolean remove(Object o) { if (o == null) { for (int index = 0; index &lt; size; index++) if (elementData[index] == null) { fastRemove(index); return true; } } else { for (int index = 0; index &lt; size; index++) if (o.equals(elementData[index])) { fastRemove(index); return true; } } return false; } private void fastRemove(int index) { //最最最关键的一个操作,集合实际修改次数++,那么这个时候由原来的3变成4 //but迭代器的预期修改次数还是3!!! modCount++; int numMoved = size - index - 1; if (numMoved &gt; 0) System.arraycopy(elementData, index+1, elementData, index, numMoved); //还有一个很关键的操作,集合的长度也发生了改变 elementData[--size] = null; // clear to let GC do its work } } 同上 list添加字符的顺序变了 @Test public void testIterator2() { // 创建集合对象 List&lt;String&gt; List list = new ArrayList&lt;String&gt;(); // 添加元素 list.add(\"hello\"); list.add(\"PHP\"); list.add(\"Java\"); // 获取迭代器 Iterator&lt;String&gt; it = list.iterator(); // 遍历集合 while (it.hasNext()) { String s = it.next(); System.out.println(s); if (s.equals(\"PHP\")) { list.remove(\"PHP\"); } } System.out.println(list); } /////////////////////////////////////// hello PHP /// 可以发现迭代器没有输出\"java\"就结束了，实际上就走了两步，不会遇到上述并发修改异常 [hello, Java] 下面的程序仍然抛并发修改异常 因为删除了第一个“PHP”后modCount = 5, 而expectedModCount在初始化的时候只有4，所以在checkForComodification()方法校验时抛异常 @Test public void testIterator2() { // 创建集合对象 List&lt;String&gt; List list = new ArrayList&lt;String&gt;(); // 添加元素 list.add(\"hello\"); list.add(\"PHP\"); list.add(\"Java\"); list.add(\"Java\"); // 获取迭代器 Iterator&lt;String&gt; it = list.iterator(); // 遍历集合 while (it.hasNext()) { String s = it.next(); System.out.println(s); if (s.equals(\"PHP\")) { list.remove(\"PHP\"); } } System.out.println(list); } // 仍然抛并发修改异常 defalult void remove()迭代器中的remove()方法，删除集合中的元素 public void testIterator3() { // 创建集合对象 List&lt;String&gt; List list = new ArrayList&lt;String&gt;(); // 添加元素 list.add(\"hello\"); list.add(\"PHP\"); list.add(\"Java\"); list.add(\"Java\"); // 获取迭代器 Iterator&lt;String&gt; it = list.iterator(); // 遍历集合 while (it.hasNext()) { String s = it.next(); System.out.println(s); if (s.equals(\"PHP\")) { it.remove(); } } System.out.println(list); } /////////////////////////////////////////////////////// hello PHP Java Java [hello, Java, Java] 源码: 在ArrayList中的实现类 //迭代器删除元素方法 public void remove() { //判断最后返回元素的索引是否小于0,满足条件就产生 非法状态异常 if (lastRet &lt; 0) throw new IllegalStateException(); //校验是否会产生并发修改异常,第一次调用不会,因为与其修改次数和实际修改次数一致 checkForComodification(); try { ArrayList.this.remove(lastRet); cursor = lastRet; lastRet = -1; //再次将集合实际修改次数赋值给预期修改次数,那么这个时候不管集合自身是否删除成功 //那么实际修改次数和预期修改次数又一致了,所以并不会产生并发修改异常 expectedModCount = modCount; } catch (IndexOutOfBoundsException ex) { throw new ConcurrentModificationException(); } } 结论： 迭代器remove方法底层调用的还是集合自身的remove方法删除元素 之所以不会产生并发修改异常，其原因是因为在迭代器的remove方法中会再次将 集合时机修改次数赋值给预期修改次数 清空方法 public void clear()清空所有数据 @Test public void testClear() { // 创建集合对象 List&lt;String&gt; List list = new ArrayList&lt;String&gt;(); // 添加元素 list.add(\"hello\"); list.add(\"PHP\"); list.add(\"Java\"); list.add(\"Java\"); list.add(null); list.clear(); System.out.println(list); } //////////////////////// [] 源码： public void clear() { modCount++; for (int i = 0; i &lt; size; i++) elementData[i] = null; size = 0; } 包含方法 public boolean contains(Object o) 判断集合是否包含指定元素 @Test public void testContains() { // 创建集合对象 List&lt;String&gt; List list = new ArrayList&lt;String&gt;(); // 添加元素 list.add(\"hello\"); list.add(\"PHP\"); list.add(\"Java\"); list.add(\"Java\"); list.add(null); System.out.println(list.contains(null)); System.out.println(list.contains(\"Java\")); } ///////////////// true false 源码： public boolean contains(Object o) { return indexOf(o) &gt;= 0; } public int indexOf(Object o) { if (o == null) { for (int i = 0; i &lt; size; i++) if (elementData[i]==null) return i; } else { for (int i = 0; i &lt; size; i++) if (o.equals(elementData[i])) return i; } return -1; } 结论：通过循环遍历一个一个比对得到是否包含 判断集合是否为空 public boolean isEmpty() @Test public void testEmpty() { // 创建集合对象 List&lt;String&gt; List list = new ArrayList&lt;String&gt;(); // 添加元素 list.add(\"hello\"); list.add(\"PHP\"); list.add(\"Java\"); list.add(\"Java\"); list.add(null); System.out.println(list.isEmpty()); System.out.println(list); } ////////////////////////////////////////// false [hello, PHP, Java, Java, null] 源码： public boolean isEmpty() { return size == 0; } 结论： 通过判断集合的长度是否为0来判断集合是否为空。","categories":[{"name":"java基础","slug":"java基础","permalink":"https://bowonqin.github.io/categories/java%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"java基础","slug":"java基础","permalink":"https://bowonqin.github.io/tags/java%E5%9F%BA%E7%A1%80/"},{"name":"java集合","slug":"java集合","permalink":"https://bowonqin.github.io/tags/java%E9%9B%86%E5%90%88/"}],"author":"qxd"},{"title":"jdk8特性","slug":"java基础/jdk8特性","date":"2021-12-26T09:56:57.000Z","updated":"2021-12-27T08:03:28.328Z","comments":true,"path":"posts/jdk8.html","link":"","permalink":"https://bowonqin.github.io/posts/jdk8.html","excerpt":"","text":"JDK8新特性黑马程序员JDK8新特性课程听课笔记BILIBILI听课网址：黑马程序员听课网址 Lambda表达式介绍使用匿名内部类存在的问题当需要启动一个线程去完成任务时，通常会通过 Runnable 接口来定义任务内容，并使用 Thread 类来启动该线程。传统写法如下： public class Demo01LambdaIntro { public static void main(String[] args) { new Thread(new Runnable() { @Override public void run() { System.out.println(\"新线程执行代码啦\"); } }).start(); } } 由于面向对象的语法要求，首先创建一个 Runnable 接口的匿名内部类对象来指定线程要执行的任务内容，再将其交给一个线程来启动。代码分析:对于 Runnable 的匿名内部类用法，可以分析出几点内容： Thread 类需要 Runnable 接口作为参数，其中的抽象 run 方法是用来指定线程任务内容的核心。 为了指定 run 的方法体，不得不需要 Runnable 接口的实现类。 为了省去定义一个 Runnable 实现类的麻烦，不得不使用匿名内部类。 必须覆盖重写抽象 run 方法，所以方法名称、方法参数、方法返回值不得不再写一遍，且不能写错。 而实际上，似乎只有方法体才是关键所在。 Lambda初体验Lambda是一个匿名函数，可以理解为一段可以传递的代码。Lambda表达式写法,代码如下： public class Demo01LambdaIntro { public static void main(String[] args) { // 体验Lambda表达式 new Thread(() -&gt; { System.out.println(\"Lambda表达式执行啦\"); }).start(); // Lambda表达式的好处: 可以简化匿名内部类,让代码更加精简 } } Lambda的优点简化匿名内部类的使用，语法更加简单。 Lambda表达式标准格式Lambda省去面向对象的条条框框，Lambda的标准格式格式由3个部分组成： (参数类型 参数名称) -&gt; { 代码体; } 格式说明： (参数类型 参数名称): 参数列表 {代码体;}: 方法体 -&gt; ：箭头，分隔参数列表和方法体有参有返回值的Lambda下面举例演示 java.util.Comparator 接口的使用场景代码，其中的抽象方法定义为： public abstract int compare(T o1, T o2); 当需要对一个对象集合进行排序时， Collections.sort 方法需要一个 Comparator 接口实例来指定排序的规则。匿名内部类写法 @Data public class Person { private String name; private int age; private int height; } public class Demo03LambdaParam { public static void main(String[] args) { ArrayList&lt;Person&gt; persons = new ArrayList&lt;&gt;(); persons.add(new Person(\"刘德华\", 58, 174)); persons.add(new Person(\"张学友\", 58, 176)); persons.add(new Person(\"刘德华\", 54, 171)); persons.add(new Person(\"黎明\", 53, 178)); // 对集合中的数据进行排序 Collections.sort(persons, new Comparator&lt;Person&gt;() { @Override public int compare(Person o1, Person o2) { return o1.getAge() - o2.getAge(); // 升序排序 } }); list.forEach(new Consumer&lt;Integer&gt;() { @Override public void accept(Integer integer) { System.out.println(integer); } } ); } } Lambda写法 public class Demo03LambdaParam { public static void main(String[] args) { ArrayList&lt;Person&gt; persons = new ArrayList&lt;&gt;(); persons.add(new Person(\"刘德华\", 58, 174)); persons.add(new Person(\"张学友\", 58, 176)); persons.add(new Person(\"刘德华\", 54, 171)); persons.add(new Person(\"黎明\", 53, 178)); // 对集合中的数据进行排序 Collections.sort(persons, ( o1, o2) -&gt; { return o2.getAge() - o1.getAge(); // 降序 }); list.forEach((s) -&gt; { System.out.println(s); }); } } Lambda表达式实现原理自定义接口 public interface Swimmable { public abstract void swimming(); } 匿名内部类实现 public class Demo04LambdaImpl { public static void main(String[] args) { // 匿名内部类在编译后会形成一个新的类.$ goSwimming(new Swimmable() { @Override public void swimming() { System.out.println(\"使用匿名内部类实现游泳\"); } }); } public static void goSwimming(Swimmable swimmable) { swimmable.swimming(); } } 可以看到匿名内部类在编译后生成一个类：Demo04LambdaImpl$1.class 使用XJad反编译这个类，得到如下代码： // Decompiled by Jad v1.5.8e2. Copyright 2001 Pavel Kouznetsov. // Jad home page: http://kpdus.tripod.com/jad.html // Decompiler options: packimports(3) fieldsfirst ansi space // Source File Name: Demo04LambdaImpl.java package com.jdk8.demo01lambda; import java.io.PrintStream; // Referenced classes of package com.jdk8.demo01lambda: // Swimmable, Demo04LambdaImpl static class Demo04LambdaImpl$1 implements Swimmable { public void swimming() { System.out.println(\"使用匿名内部类实现游泳\"); } Demo04LambdaImpl$1() { } } Lambda实现 public class Demo04LambdaImpl { public static void main(String[] args) { goSwimming(() -&gt; { System.out.println(\"Lambda表达式中的游泳\"); }); } public static void goSwimming(Swimmable swimmable) { swimmable.swimming(); } } 运行程序，控制台可以得到预期的结果，但是并没有出现一个新的类，也就是说Lambda并没有在编译的时候产生一个新的类。使用XJad对这个类进行反编译，发现XJad报错。使用了Lambda后XJad反编译工具无法反编译。我们使用JDK自带的一个工具： javap ，对字节码进行反汇编，查看字节码指令。在DOS命令行输入： javap -c -p 文件名.class -c：表示对代码进行反汇编 -p：显示所有类和成员 反汇编后效果如下： public class com.jdk8.demo01lambda.Demo04LambdaImpl { public com.jdk8.demo01lambda.Demo04LambdaImpl(); Code: 0: aload_0 1: invokespecial #1 // Method java/lang/Object.\"&lt;init&gt;\":()V 4: return public static void main(java.lang.String[]); Code: 0: invokedynamic #2, 0 // InvokeDynamic #0:swimming:()Lcom/jdk8/demo01lambda/Swimmable; 5: invokestatic #3 // Method goSwimming:(Lcom/jdk8/demo01lambda/Swimmable;)V 8: return public static void goSwimming(com.jdk8.demo01lambda.Swimmable); Code: 0: aload_0 1: invokeinterface #4, 1 // InterfaceMethod com/jdk8/demo01lambda/Swimmable.swimming:()V 6: return private static void lambda$main$0(); Code: 0: getstatic #5 // Field java/lang/System.out:Ljava/io/PrintStream; 3: ldc #6 // String Lambda表达式中的游泳 5: invokevirtual #7 // Method java/io/PrintStream.println:(Ljava/lang/String;)V 8: return } 可以看到在类中多出了一个私有的静态方法 lambda$main$0 。这个方法里面放的是什么内容呢？我们通过断点调试来看看： 可以确认上述方法里面放的就是Lambda中的内容，我们可以这么理解该方法： public class Demo04LambdaImpl { public static void main(String[] args) { ... } private static void lambda$main$0() { System.out.println(\"Lambda游泳\"); } } 如何调用这个方法呢？其实Lambda在运行的时候会生成一个内部类，为了验证是否生成内部类，可以在运行时加上 -Djdk.internal.lambda.dumpProxyClasses ，加上这个参数后，运行时会将生成的内部类class码输出到一个文件中。使用java命令如下： java -Djdk.internal.lambda.dumpProxyClasses 要运行的包名.类名 根据上面的格式，在命令行输入以下命令： G:\\病情期间\\项目\\jdk8\\target\\classes&gt;java -Djdk.internal.lambda.dumpProxyClasses com.jdk8.demo01lambda.Demo04LambdaImpl Lambda表达式中的游泳 执行完毕，可以看到生成一个新的类，效果如下： 反编译这个字节码文件，内容如下： // Decompiled by Jad v1.5.8e2. Copyright 2001 Pavel Kouznetsov. // Jad home page: http://kpdus.tripod.com/jad.html // Decompiler options: packimports(3) fieldsfirst ansi space package com.jdk8.demo01lambda; // Referenced classes of package com.jdk8.demo01lambda: // Swimmable, Demo04LambdaImpl final class Demo04LambdaImpl$$Lambda$1 implements Swimmable { public void swimming() { Demo04LambdaImpl.lambda$main$0(); } private Demo04LambdaImpl$$Lambda$1() { } } 可以看到这个匿名内部类实现了 Swimmable 接口，并且重写了 swimming 方法， swimming 方法调用Lambda中的内容。最后可以将Lambda理解为： public class Demo04LambdaImpl { public static void main(String[] args) { goSwimming(new Swimmable() { public void swimming() { Demo04LambdaImpl.lambda$main$0(); } }); } private static void lambda$main$0() { System.out.println(\"Lambda表达式游泳\"); } public static void goSwimming(Swimmable swimmable) { swimmable.swimming(); } } 小结匿名内部类在编译的时候会一个class文件Lambda在程序运行的时候形成一个类 在类中新增一个方法,这个方法的方法体就是Lambda表达式中的代码 还会形成一个匿名内部类,实现接口,重写抽象方法 在接口的重写方法中会调用新生成的方法 Lambda省略格式在Lambda标准格式的基础上，使用省略写法的规则为： 小括号内参数的类型可以省略 如果小括号内有且仅有一个参数，则小括号可以省略 如果大括号内有且仅有一个语句，可以同时省略大括号、return关键字及语句分号 省略前 (int a) -&gt; { return new Person(); } 省略后 a -&gt; new Person() Lambda的前提条件Lambda的语法非常简洁，但是Lambda表达式不是随便使用的，使用时有几个条件要特别注意： 方法的参数或局部变量类型必须为接口才能使用Lambda 接口中有且仅有一个抽象方法// 只有一个抽象方法的接口称为函数式接口,我们就能使用Lambda interface Flyable { // 接口中有且仅有一个抽象方法 public abstract void eat(); // public abstract void eat2(); } public class Demo06LambdaCondition { public static void main(String[] args) { // 方法的参数或局部变量类型必须为接口才能使用Lambda test(() -&gt; { }); Runnable r = new Runnable() { @Override public void run() { System.out.println(\"aa\"); } }; Flyable f = () -&gt; { System.out.println(\"我会飞啦\"); }; } public static void test(Flyable a) { new Person() { }; } } 函数式接口函数式接口在Java中是指：有且仅有一个抽象方法的接口。FunctionalInterface注解与 @Override 注解的作用类似，Java 8中专门为函数式接口引入了一个新的注解：@FunctionalInterface 。该注解可用于一个接口的定义上： // 只有一个抽象方法的接口称为函数式接口,我们就能使用Lambda @FunctionalInterface // 检测这个接口是不是只有一个抽象方法 interface Flyable { // 接口中有且仅有一个抽象方法 public abstract void eat(); // public abstract void eat2(); } 一旦使用该注解来定义接口，编译器将会强制检查该接口是否确实有且仅有一个抽象方法，否则将会报错。不过，即使不使用该注解，只要满足函数式接口的定义，这仍然是一个函数式接口，使用起来都一样。 Lambda表达式VS匿名内部类了解Lambda和匿名内部类在使用上的区别 所需的类型不一样 匿名内部类,需要的类型可以是类,抽象类,接口 Lambda表达式,需要的类型必须是接口 抽象方法的数量不一样 匿名内部类所需的接口中抽象方法的数量随意 Lambda表达式所需的接口只能有一个抽象方法 实现原理不同 匿名内部类是在编译后会形成class Lambda表达式是在程序运行的时候动态生成class 当接口中只有一个抽象方法时,建议使用Lambda表达式,其他其他情况还是需要使用匿名内部类 JDK8接口新增的两个方法JDK8接口增强JDK8以前的接口 interface 接口名 { 静态常量; 抽象方法; } JDK 8对接口的增强，接口还可以有默认方法和静态方法JDK 8的接口： interface 接口名 { 静态常量; 抽象方法; 默认方法; 静态方法; } JDK8接口引入默认方法的背景JDK8之前版本：如果给接口新增抽象方法，所有实现类都必须重写这个抽象方法。不利于接口的扩展 interface A { public abstract void test1(); // 接口新增抽象方法,所有实现类都需要去重写这个方法,非常不利于接口的扩展 public abstract void test2(); } class B implements A { @Override public void test1() { System.out.println(\"BB test1\"); } // 接口新增抽象方法,所有实现类都需要去重写这个方法 @Override public void test2() { System.out.println(\"BB test2\"); } } class C implements A { @Override public void test1() { System.out.println(\"CC test1\"); } // 接口新增抽象方法,所有实现类都需要去重写这个方法 @Override public void test2() { System.out.println(\"CC test2\"); } } 例如，JDK 8 时在Map接口中增加了 forEach 方法: public interface Map&lt;K, V&gt; { ... abstract void forEach(BiConsumer&lt;? super K, ? super V&gt; action); } 如果在Map接口中增加一个抽象方法，所有的实现类都需要去实现这个方法，那么工程量时巨大的。因此，在JDK 8时为接口新增了默认方法，效果如下： public interface Map&lt;K, V&gt; { ... default void forEach(BiConsumer&lt;? super K, ? super V&gt; action) { ... } } 接口中的默认方法实现类不必重写，可以直接使用，实现类也可以根据需要重写。这样就方便接口的扩展。 接口默认方法的定义格式interface 接口名 { 修饰符 default 返回值类型 方法名() { 代码; } } 默认接口方法的使用1.直接使用2.实现类重写 public class Demo02UseDefaultFunction { public static void main(String[] args) { BB bb = new BB(); bb.test01(); CC cc = new CC(); cc.test01(); } } interface AA { public default void test01() { System.out.println(\"我是接口AA默认方法\"); } } // 默认方法使用方式一: 实现类可以直接使用 class BB implements AA { } // 默认方法使用方式二: 实现类可以重写接口默认方法 class CC implements AA { @Override public void test01() { System.out.println(\"我是CC类重写的默认方法\"); } } 接口静态方法interface 接口名 { 修饰符 static 返回值类型 方法名() { 代码; } } 直接使用接口名调用即可：接口名.静态方法名(); public class Demo03UseStaticFunction { public static void main(String[] args) { BBB bbb = new BBB(); // bbb.test01(); // 使用接口名.静态方法名(); AAA.test01(); } } interface AAA { public static void test01() { System.out.println(\"我是接口静态方法\"); } } class BBB implements AAA { // @Override // public static void test01() { // System.out.println(\"我是接口静态方法\"); // } } 接口默认方法VS静态方法 默认方法通过实例调用，静态方法通过接口名调用。 默认方法可以被继承，实现类可以直接使用接口默认方法，也可以重写接口默认方法。 静态方法不能被继承，实现类不能重写接口静态方法，只能使用接口名调用。 常用内置式函数式接口为了更加方便地使用Lambda,JDK提供了大量的函数式接口。主要在java.util.function包中 Supplier接口 @FunctionalInterface public interface Supplier&lt;T&gt; { /** * Gets a result. * * @return a result */ T get(); } Consumer接口 @FunctionalInterface public interface Consumer&lt;T&gt; { /** * Performs this operation on the given argument. * * @param t the input argument */ void accept(T t); } Function接口 @FunctionalInterface public interface Function&lt;T, R&gt; { /** * Applies this function to the given argument. * * @param t the function argument * @return the function result */ R apply(T t); } Predicate接口 @FunctionalInterface public interface Predicate&lt;T&gt; { /** * Evaluates this predicate on the given argument. * * @param t the input argument * @return {@code true} if the input argument matches the predicate, * otherwise {@code false} */ boolean test(T t); } Suppiler接口它意味着”供给” , 对应的Lambda表达式需要“对外提供”一个符合泛型类型的对象数据使用Lambda表达式返回数组元素最大值使用 Supplier 接口作为方法参数类型，通过Lambda表达式求出int数组中的最大值。提示：接口的泛型请使用java.lang.Integer 类。 public class Demo02Supplier { // 使用Lambda表达式返回数组元素最大值 public static void main(String[] args) { System.out.println(\"开始了\"); printMax(() -&gt; { int[] arr = {11, 99, 88, 77, 22}; Arrays.sort(arr); // 升序排序 return arr[arr.length - 1]; }); } public static void printMax(Supplier&lt;Integer&gt; supplier) { System.out.println(\"aa\"); int max = supplier.get(); System.out.println(\"max = \" + max); } } Consumer接口java.util.function.Consumer 接口则正好相反，它不是生产一个数据，而是消费一个数据，其数据类型由泛型参数决定。使用Lambda表达式将一个字符串转成大写和小写的字符串Consumer消费型接口，可以拿到accept方法参数传递过来的数据进行处理, 有参无返回的接口。基本使用如： public class Demo03Consumer { // 使用Lambda表达式将一个字符串转成大写的字符串 public static void main(String[] args) { System.out.println(\"开始啦\"); printHello((String str) -&gt; { System.out.println(str.toUpperCase()); }); } public static void printHello(Consumer&lt;String&gt; consumer) { System.out.println(\"aaa\"); consumer.accept(\"Hello World\"); } } 默认方法：andThen如果一个方法的参数和返回值全都是 Consumer 类型，那么就可以实现效果：消费一个数据的时候，首先做一个操作，然后再做一个操作，实现组合。而这个方法就是 Consumer 接口中的default方法 andThen 。下面是JDK的源代码： default Consumer&lt;T&gt; andThen(Consumer&lt;? super T&gt; after) { Objects.requireNonNull(after); return (T t) -&gt; { accept(t); after.accept(t); }; } 备注： java.util.Objects 的 requireNonNull 静态方法将会在参数为null时主动抛出NullPointerException 异常。这省去了重复编写if语句和抛出空指针异常的麻烦。 要想实现组合，需要两个或多个Lambda表达式即可，而 andThen 的语义正是“一步接一步”操作。例如两个步骤组合的情况： public class Demo04ConsumerAndThen { // 使用Lambda表达式先将一个字符串转成小写的字符串,再转成大写 public static void main(String[] args) { System.out.println(\"开始啦\"); printHello((String str) -&gt; { System.out.println(str.toLowerCase()); }, (String str) -&gt; { System.out.println(str.toUpperCase()); }); } public static void printHello(Consumer&lt;String&gt; c1, Consumer&lt;String&gt; c2) { System.out.println(\"aa\"); String str = \"Hello World\"; // c1.accept(str); // c2.accept(str); c2.andThen(c1).accept(str); } } 运行结果将会首先打印完全大写的HELLO，然后打印完全小写的hello。当然，通过链式写法可以实现更多步骤的组合。 Function接口java.util.function.Function&lt;T,R&gt; 接口用来根据一个类型的数据得到另一个类型的数据，前者称为前置条件，后者称为后置条件。有参数有返回值。Function转换型接口，对apply方法传入的T类型数据进行处理，返回R类型的结果，有参有返回的接口。使用的场景例如：将 String 类型转换为 Integer 类型。 public class Demo05Function { // 使用Lambda表达式将字符串转成数字 public static void main(String[] args) { System.out.println(\"开始\"); getNumber((String str) -&gt; { int i = Integer.parseInt(str); return i; }); } public static void getNumber(Function&lt;String, Integer&gt; function) { System.out.println(\"aa\"); Integer num1 = function.apply(\"10\"); System.out.println(\"num1 = \" + num1); } } andThen方法用法同Consumer接口 Predicate接口有时候我们需要对某种类型的数据进行判断，从而得到一个boolean值结果。这时可以使用java.util.function.Predicate 接口。 使用Lambda判断一个人名如果超过3个字就认为是很长的名字 public class Demo07Predicate { // 使用Lambda判断一个人名如果超过3个字就认为是很长的名字 public static void main(String[] args) { System.out.println(\"开始啦\"); isLongName((String name) -&gt; { return name.length() &gt; 3; }); } public static void isLongName(Predicate&lt;String&gt; predicate) { System.out.println(\"aa\"); boolean isLong = predicate.test(\"迪丽热巴\"); System.out.println(\"是否是长名字: \" + isLong); } } 默认方法：and既然是条件判断，就会存在与、或、非三种常见的逻辑关系。其中将两个 Predicate 条件使用“与”逻辑连接起来实现“并且”的效果时，可以使用default方法 and 。其JDK源码为： default Predicate&lt;T&gt; and(Predicate&lt;? super T&gt; other) { Objects.requireNonNull(other); return (t) -&gt; test(t) &amp;&amp; other.test(t); } 使用Lambda表达式判断一个字符串中即包含W,也包含Hand方法使用Lambda表达式判断一个字符串中包含W或者包含Hor方法使用Lambda表达式判断一个字符串中即不包含Wnegate方法 public class Demo08Predicate_And_Or_Negate { // 使用Lambda表达式判断一个字符串中即包含W,也包含H // 使用Lambda表达式判断一个字符串中包含W或者包含H // 使用Lambda表达式判断一个字符串中不包含W public static void main(String[] args) { test((String str) -&gt; { // 判断是否包含W return str.contains(\"W\"); }, (String str) -&gt; { // 判断是否包含H return str.contains(\"H\"); }); } public static void test(Predicate&lt;String&gt; p1, Predicate&lt;String&gt; p2) { // String str = \"Hello orld\"; // boolean b1 = p1.test(str); // boolean b2 = p2.test(str); // if (b1 &amp;&amp; b2) { // System.out.println(\"即包含W,也包含H\"); // } // 使用Lambda表达式判断一个字符串中即包含W,也包含H String str = \"Hello World\"; boolean b = p1.and(p2).test(str); if (b) { System.out.println(\"即包含W,也包含H\"); } // 使用Lambda表达式判断一个字符串中包含W或者包含H boolean b1 = p1.or(p2).test(str); if (b1) { System.out.println(\"包含W或者包含H\"); } // 使用Lambda表达式判断一个字符串中不包含W boolean b2 = p1.negate().test(\"Hello W\"); // negate相当于取反 !boolean if (b2) { System.out.println(\"不包含W\"); } } } Lambda的冗余场景使用Lambda表达式求一个数组的和 public class Demo01MethodRefIntro { // 求一个数组的和 public static void getMax(int[] arr) { int sum = 0; for (int n : arr) { sum += n; } System.out.println(sum); } public static void main(String[] args) { // 使用Lambda表达式求一个数组的和 printMax(arr -&gt; getMax(arr)); } public static void printMax(Consumer&lt;int[]&gt; consumer) { int[] arr = {11, 22, 33, 44, 55}; consumer.accept(arr); } } 方法引用简化 public class Demo01MethodRefIntro { // 求一个数组的和 public static void getMax(int[] arr) { int sum = 0; for (int n : arr) { sum += n; } System.out.println(sum); } public static void main(String[] args) { // 使用Lambda表达式求一个数组的和 // printMax(arr -&gt; getMax(arr)); // 使用方法引用 // 让这个指定的方法去重写接口的抽象方法,到时候调用接口的抽象方法就是调用传递过去的这个方法 printMax(Demo01MethodRefIntro::getMax); } public static void printMax(Consumer&lt;int[]&gt; consumer) { int[] arr = {11, 22, 33, 44, 55}; consumer.accept(arr); } } 请注意其中的双冒号 :: 写法，这被称为“方法引用”，是一种新的语法。 方法引用的场景符号 - ::说明 - 双冒号为方法引用运算符，而它所在的表达式被称为方法引用。应用场景 - 如果Lambda所要实现的方案 , 已经有其他方法存在相同方案，那么则可以使用方法引用。方法引用在JDK 8中使用方式相当灵活，有以下几种形式： instanceName::methodName 对象::方法名 ClassName::staticMethodName 类名::静态方法 ClassName::methodName 类名::普通方法 ClassName::new 类名::new 调用的构造器 TypeName[]::new String[]::new 调用数组的构造器 对象名::引用成员方法@Test public void test01() { Date now = new Date(); /*Supplier&lt;Long&gt; su1 = () -&gt; { return now.getTime(); };*/ // 使用方法引用 Supplier&lt;Long&gt; su1 = now::getTime; Long aLong = su1.get(); System.out.println(\"aLong = \" + aLong); // 注意:方法引用有两个注意事项 // 1.被引用的方法，参数要和接口中抽象方法的参数一样 // 2.当接口抽象方法有返回值时，被引用的方法也必须有返回值 // Supplier&lt;Long&gt; su3 = now::setTime; // su3.get(); // Supplier&lt;Long&gt; su4 = now::setDate; // su4.get(); } 方法引用的注意事项: 被引用的方法，参数要和接口中抽象方法的参数一样 当接口抽象方法有返回值时，被引用的方法也必须有返回值 类名::引用静态方法@Test public void test02() { /*Supplier&lt;Long&gt; su = () -&gt; { return System.currentTimeMillis(); };*/ Supplier&lt;Long&gt; su = System::currentTimeMillis; Long time = su.get(); System.out.println(\"time = \" + time); } 类名::引用实例方法Java面向对象中，类名只能调用静态方法，类名引用实例方法是有前提的，实际上是拿第一个参数作为方法的调用者。 @Test public void test03() { /*Function&lt;String, Integer&gt; f1 = (String str) -&gt; { return str.length(); };*/ // 类名::实例方法(注意:类名::类名::实例方法实际上会将第一个参数作为方法的调用者) Function&lt;String, Integer&gt; f1 = String::length; int length = f1.apply(\"hello\"); System.out.println(\"length = \" + length); // BiFunction&lt;String, Integer, String&gt; f2 = String::substring; // 相当于这样的Lambda BiFunction&lt;String, Integer, String&gt; f2 = (String str, Integer index) -&gt; { return str.substring(index); }; String str2 = f2.apply(\"helloworld\", 3); System.out.println(\"str2 = \" + str2); // loworld } 类名::new引用构造器@Data public class Person { private String name; private int age; @Test public void test04() { /*Supplier&lt;Person&gt; su1 = () -&gt; { return new Person(); };*/ Supplier&lt;Person&gt; su1 = Person::new; Person person = su1.get(); System.out.println(\"person = \" + person); /*BiFunction&lt;String, Integer, Person&gt; bif = (String name, Integer age) -&gt; { return new Person(name, age); };*/ BiFunction&lt;String, Integer, Person&gt; bif = Person::new; Person p2 = bif.apply(\"凤姐\", 18); System.out.println(\"p2 = \" + p2); } 数组::new 引用数组构造器数组也是 Object 的子类对象，所以同样具有构造器，只是语法稍有不同。 // 类型[]::new @Test public void test05() { /*Function&lt;Integer, int[]&gt; f1 = (Integer length) -&gt; { return new int[length]; };*/ Function&lt;Integer, int[]&gt; f1 = int[]::new; int[] arr1 = f1.apply(10); System.out.println(Arrays.toString(arr1)); } 方法引用是对Lambda表达式符合特定情况下的一种缩写，它使得我们的Lambda表达式更加的精简，也可以理解为Lambda表达式的缩写形式 , 不过要注意的是方法引用只能”引用”已经存在的方法! Stream流集合处理数据的弊端当我们需要对集合中的元素进行操作的时候，除了必需的添加、删除、获取外，最典型的就是集合遍历。我们来体验集合操作数据的弊端，需求如下： 一个ArrayList集合中存储有以下数据:张无忌,周芷若,赵敏,张强,张三丰 需求:1.拿到所有姓张的 2.拿到名字长度为3个字的 3.打印这些数据 public class Demo01Intro { public static void main(String[] args) throws InterruptedException { // 一个ArrayList集合中存储有以下数据:张无忌,周芷若,赵敏,张强,张三丰 // 需求:1.拿到所有姓张的 2.拿到名字长度为3个字的 3.打印这些数据 ArrayList&lt;String&gt; list = new ArrayList&lt;&gt;(); Collections.addAll(list, \"张无忌\", \"周芷若\", \"赵敏\", \"张强\", \"张三丰\"); System.out.println(\"-----------\"); // 1.拿到所有姓张的 ArrayList&lt;String&gt; zhangList = new ArrayList&lt;&gt;(); // {\"张无忌\", \"张强\", \"张三丰\"} for (String name : list) { if (name.startsWith(\"张\")) { zhangList.add(name); } } // 2.拿到名字长度为3个字的 ArrayList&lt;String&gt; threeList = new ArrayList&lt;&gt;(); // {\"张无忌\", \"张三丰\"} for (String name : zhangList) { if (name.length() == 3) { threeList.add(name); } } // 3.打印这些数据 for (String name : threeList) { System.out.println(name); } } } 循环遍历的弊端:这段代码中含有三个循环，每一个作用不同: 首先筛选所有姓张的人； 然后筛选名字有三个字的人; 最后进行对结果进行打印输出 Stream的更优写法 public class Demo01Intro { public static void main(String[] args) throws InterruptedException { // 一个ArrayList集合中存储有以下数据:张无忌,周芷若,赵敏,张强,张三丰 // 需求:1.拿到所有姓张的 2.拿到名字长度为3个字的 3.打印这些数据 ArrayList&lt;String&gt; list = new ArrayList&lt;&gt;(); Collections.addAll(list, \"张无忌\", \"周芷若\", \"赵敏\", \"张强\", \"张三丰\",\"张11\"); // 1.拿到所有姓张的 2.拿到名字长度为3个字的 3.打印这些数据 list.stream().filter(s -&gt; s.startsWith(\"张\")).filter(s -&gt; s.length() == 3).forEach(System.out::println); } } Stream API能让我们快速完成许多复杂的操作，如筛选、切片、映射、查找、去除重复，统计，匹配和归约。 获取Stream流的两种方式 所有的Collection集合都可以通过stream默认方法获取流 Stream接口的静态方法of可以获取数组对应的流 方式1： 根据Collection获取流public interface Collection{ default Stream&lt;E&gt; stream() { return StreamSupport.stream(spliterator(), false); } } public class Demo02GetStream { public static void main(String[] args) { // 方式1 : 根据Collection获取流 // Collection接口中有一个默认的方法: default Stream&lt;E&gt; stream() List&lt;String&gt; list = new ArrayList&lt;&gt;(); Stream&lt;String&gt; stream1 = list.stream(); Set&lt;String&gt; set = new HashSet&lt;&gt;(); Stream&lt;String&gt; stream2 = set.stream(); // ... } } java.util.Map 接口不是 Collection 的子接口，所以获取对应的流需要分key、value或entry等情况： public class Demo02GetStream { public static void main(String[] args) { // 方式1 : 根据Collection获取流 // Collection接口中有一个默认的方法: default Stream&lt;E&gt; stream() Map&lt;String, String&gt; map = new HashMap&lt;&gt;(); Stream&lt;String&gt; stream3 = map.keySet().stream(); Stream&lt;String&gt; stream4 = map.values().stream(); Stream&lt;Map.Entry&lt;String, String&gt;&gt; stream5 = map.entrySet().stream(); } } 方式2： Stream中的静态方法of获取流由于数组对象不可能添加默认方法，所以 Stream 接口中提供了静态方法 of ，使用很简单： public class Demo02GetStream { public static void main(String[] args) { // 方式2 : Stream中的静态方法of获取流 // static&lt;T&gt; Stream&lt;T&gt; of(T... values) Stream&lt;String&gt; stream6 = Stream.of(\"aa\", \"bb\", \"cc\"); String[] strs = {\"aa\", \"bb\", \"cc\"}; Stream&lt;String&gt; stream7 = Stream.of(strs); // 基本数据类型的数组行不行?不行的,会将整个数组看做一个元素进行操作. int[] arr = {11, 22, 33}; Stream&lt;int[]&gt; stream8 = Stream.of(arr); } } Sream常用方法 终结方法：不支持链式调用 count: 统计个数 long foreach: 逐一处理 void 非终结方法：支持链式调用 filter: 过滤 limit: 取用前几个 skip： 跳过前几个 map: 映射 concat: 组合 Stream注意事项 Stream只能操作一次 Stream返回新的流 Stream不调用终结方法，中间的操作不会执行public class Demo03StreamNotice { public static void main(String[] args) { Stream&lt;String&gt; stream = Stream.of(\"aa\", \"bb\", \"cc\"); // 1. Stream只能操作一次 // long count = stream.count(); // long count2 = stream.count(); // 2. Stream方法返回的是新的流 // Stream&lt;String&gt; limit = stream.limit(1); // System.out.println(\"stream\" + stream); // System.out.println(\"limit\" + limit); // 3. Stream不调用终结方法，中间的操作不会执行 就是不加count()方法，中间的打印语句不会执行 stream.filter((s) -&gt; { System.out.println(s); return true; }).count(); } } Stram流的foreach方法遍历数据@Test public void testForEach() { List&lt;String&gt; one = new ArrayList&lt;&gt;(); Collections.addAll(one, \"迪丽热巴\", \"宋远桥\", \"苏星河\", \"老子\", \"庄子\", \"孙子\"); /*// 得到流 // 调用流中的方法 one.stream().forEach((String str) -&gt; { System.out.println(str); }); // Lambda可以省略 one.stream().forEach(str -&gt; System.out.println(str));*/ // Lambda可以转成方法引用 one.stream().forEach(System.out::println); } Stream流的count方法统计个数@Test public void testCount() { List&lt;String&gt; one = new ArrayList&lt;&gt;(); Collections.addAll(one, \"迪丽热巴\", \"宋远桥\", \"苏星河\", \"老子\", \"庄子\", \"孙子\"); long count = one.stream().count(); System.out.println(count); } Stream流的filter方法过滤数据 @Test public void testFilter() { List&lt;String&gt; one = new ArrayList&lt;&gt;(); Collections.addAll(one, \"迪丽热巴\", \"宋远桥\", \"苏星河\", \"老子\", \"庄子\", \"孙子\"); // 得到名字长度为3个字的人(过滤) // filter(Predicate&lt;? super T&gt; predicate) one.stream().filter((String s) -&gt; { return s.length() == 3; }).forEach(System.out::println); System.out.println(\"---------------------\"); one.stream().filter(s -&gt; s.length() == 3).forEach(System.out::println); } Stream流的limit方法参数是一个long型，如果集合当前长度大于参数则进行截取。否则不进行操作。基本使用： @Test public void testLimit() { List&lt;String&gt; one = new ArrayList&lt;&gt;(); Collections.addAll(one, \"迪丽热巴\", \"宋远桥\", \"苏星河\", \"老子\", \"庄子\", \"孙子\"); // 获取前3个数据 one.stream() .limit(3) .forEach(System.out::println); } Stream流的skip方法如果流的当前长度大于n，则跳过前n个；否则将会得到一个长度为0的空流。基本使用： @Test public void testSkip() { List&lt;String&gt; one = new ArrayList&lt;&gt;(); Collections.addAll(one, \"迪丽热巴\", \"宋远桥\", \"苏星河\", \"老子\", \"庄子\", \"孙子\"); // 跳过前两个数据 one.stream() .skip(2) .forEach(System.out::println); } Stream流的map方法如果需要将流中的元素映射到另一个流中，可以使用 map 方法。 @Test public void testMap() { Stream&lt;String&gt; original = Stream.of(\"11\", \"22\", \"33\"); // Map可以将一种类型的流转换成另一种类型的流 // 将Stream流中的字符串转成Integer /*Stream&lt;Integer&gt; stream = original.map((String s) -&gt; { return Integer.parseInt(s); });*/ // original.map(s -&gt; Integer.parseInt(s)).forEach(System.out::println); original.map(Integer::parseInt).forEach(System.out::println); } Stream流的sorted方法排序 @Test public void testSorted() { // sorted(): 根据元素的自然顺序排序 // sorted(Comparator&lt;? super T&gt; comparator): 根据比较器指定的规则排序 Stream&lt;Integer&gt; stream = Stream.of(33, 22, 11, 55); // stream.sorted().forEach(System.out::println); /*stream.sorted((Integer i1, Integer i2) -&gt; { return i2 - i1; }).forEach(System.out::println);*/ stream.sorted((i1, i2) -&gt; i2 - i1).forEach(System.out::println); } Stream流的distinct方法去除重复数据 @Test public void testDistinct() { Stream&lt;Integer&gt; stream = Stream.of(22, 33, 22, 11, 33); stream.distinct().forEach(System.out::println); Stream&lt;String&gt; stream1 = Stream.of(\"aa\", \"bb\", \"aa\", \"bb\", \"cc\"); stream1.distinct().forEach(System.out::println); } 自定义类型去重 // distinct对自定义对象去除重复 @Test public void testDistinct2() { Stream&lt;Person&gt; stream = Stream.of( new Person(\"貂蝉\", 18), new Person(\"杨玉环\", 20), new Person(\"杨玉环\", 20), new Person(\"西施\", 16), new Person(\"西施\", 16), new Person(\"王昭君\", 25) ); stream.distinct().forEach(System.out::println); } 重写了Person类中的hashcode()和eqauls()方法，自定义类型是根据对象的hashCode和equals来去除重复元素的。 Stream流的match方法需要判断数据是否匹配指定的条件 @Test public void testMatch() { Stream&lt;Integer&gt; stream = Stream.of(5, 3, 6, 1); // boolean b = stream.allMatch(i -&gt; i &gt; 0); // allMatch: 匹配所有元素,所有元素都需要满足条件 // boolean b = stream.anyMatch(i -&gt; i &gt; 5); // anyMatch: 匹配某个元素,只要有其中一个元素满足条件即可 boolean b = stream.noneMatch(i -&gt; i &lt; 0); // noneMatch: 匹配所有元素,所有元素都不满足条件 System.out.println(b); } Stream流的find方法如果需要找到某些数据，可以使用 find 相关方法。 @Test public void testFind() { Stream&lt;Integer&gt; stream = Stream.of(33, 11, 22, 5); // 找第一个元素 // Optional&lt;Integer&gt; first = stream.findFirst(); Optional&lt;Integer&gt; first = stream.findAny(); System.out.println(first.get()); } Stream流的max和min方法找最大最小值 @Test public void testMax_Min() { // 获取最大值 // 1, 3, 5, 6 Optional&lt;Integer&gt; max = Stream.of(5, 3, 6, 1).max((o1, o2) -&gt; o1 - o2); System.out.println(\"最大值: \" + max.get()); // 获取最小值 // 1, 3, 5, 6 Optional&lt;Integer&gt; min = Stream.of(5, 3, 6, 1).min((o1, o2) -&gt; o1 - o2); System.out.println(\"最小值: \" + min.get()); } Stream流的reduce方法所有数据归纳得到一个数据 @Test public void testReduce() { // T reduce(T identity, BinaryOperator&lt;T&gt; accumulator); // T identity: 默认值 // BinaryOperator&lt;T&gt; accumulator: 对数据进行处理的方式 // reduce如何执行? // 第一次, 将默认值赋值给x, 取出集合第一元素赋值给y // 第二次, 将上一次返回的结果赋值x, 取出集合第二元素赋值给y // 第三次, 将上一次返回的结果赋值x, 取出集合第三元素赋值给y // 第四次, 将上一次返回的结果赋值x, 取出集合第四元素赋值给y int reduce = Stream.of(4, 5, 3, 9).reduce(0, (x, y) -&gt; { System.out.println(\"x = \" + x + \", y = \" + y); return x + y; }); System.out.println(\"reduce = \" + reduce); // 21 // 获取最大值 Integer max = Stream.of(4, 5, 3, 9).reduce(0, (x, y) -&gt; { return x &gt; y ? x : y; }); System.out.println(\"max = \" + max); } Stream流的map和reduce组合使用@Test public void testMapReduce() { // 求出所有年龄的总和 // 1.得到所有的年龄 // 2.让年龄相加 Integer totalAge = Stream.of( new Person(\"刘德华\", 58), new Person(\"张学友\", 56), new Person(\"郭富城\", 54), new Person(\"黎明\", 52)) .map(Person::getAge).reduce(0, Integer::sum); System.out.println(\"totalAge = \" + totalAge); // 找出最大年龄 // 1.得到所有的年龄 // 2.获取最大的年龄 Integer maxAge = Stream.of( new Person(\"刘德华\", 58), new Person(\"张学友\", 56), new Person(\"郭富城\", 54), new Person(\"黎明\", 52)) .map(Person::getAge) .reduce(0, (x, y) -&gt; x &gt; y ? x : y); System.out.println(\"maxAge = \" + maxAge); // 统计 a 出现的次数 // 1 0 0 1 0 1 Integer count = Stream.of(\"a\", \"c\", \"b\", \"a\", \"b\", \"a\") .map(s -&gt; s.equals(\"a\") ? 1 : 0) .reduce(0, Integer::sum); System.out.println(\"count = \" + count); long count1 = Stream.of(\"a\", \"c\", \"b\", \"a\", \"b\", \"a\").filter(s -&gt; s.equals(\"a\")).count(); System.out.println(count1); } Stream流的mapToInt将Stream中的Integer类型数据转成int类型 @Test public void testNumericStream() { // Integer占用的内存比int多,在Stream流操作中会自动装箱和拆箱 Stream&lt;Integer&gt; stream = Stream.of(1, 2, 3, 4, 5); // 把大于3的打印出来 // stream.filter(n -&gt; n &gt; 3).forEach(System.out::println); // IntStream mapToInt(ToIntFunction&lt;? super T&gt; mapper); // IntStream: 内部操作的是int类型的数据,就可以节省内存,减少自动装箱和拆箱 /*IntStream intStream = Stream.of(1, 2, 3, 4, 5).mapToInt((Integer n) -&gt; { return n.intValue(); });*/ IntStream intStream = Stream.of(1, 2, 3, 4, 5).mapToInt(Integer::intValue); intStream.filter(n -&gt; n &gt; 3).forEach(System.out::println); } Stream流的concat方法两个流合并成为一个流 @Test public void testContact() { Stream&lt;String&gt; streamA = Stream.of(\"张三\"); Stream&lt;String&gt; streamB = Stream.of(\"李四\"); // 合并成一个流 Stream&lt;String&gt; newStream = Stream.concat(streamA, streamB); // 注意:合并流之后,不能操作之前的流啦. // streamA.forEach(System.out::println); newStream.forEach(System.out::println); } Stream综合案例现在有两个 ArrayList 集合存储队伍当中的多个成员姓名，要求使用传统的for循环（或增强for循环）依次进行以下若干操作步骤： 第一个队伍只要名字为3个字的成员姓名； 第一个队伍筛选之后只要前3个人； 第二个队伍只要姓张的成员姓名； 第二个队伍筛选之后不要前2个人； 将两个队伍合并为一个队伍； 根据姓名创建 Person 对象； 打印整个队伍的Person对象信息。public class Demo05 { public static void main(String[] args) { // 第一个队伍 List&lt;String&gt; one = List.of(\"迪丽热巴\", \"宋远桥\", \"苏星河\", \"老子\", \"庄子\", \"孙子\", \"洪七公\"); // 第二个队伍 List&lt;String&gt; two = List.of(\"古力娜扎\", \"张无忌\", \"张三丰\", \"赵丽颖\", \"张二狗\", \"张天爱\", \"张三\"); // 1.第一个队伍只要名字为3个字的成员姓名; // 2.第一个队伍筛选之后只要前3个人; Stream&lt;String&gt; streamA = one.stream() .filter(s -&gt; s.length() == 3) .limit(3); // 3.第二个队伍只要姓张的成员姓名; // 4.第二个队伍筛选之后不要前2个人; Stream&lt;String&gt; streamB = two.stream() .filter(s -&gt; s.startsWith(\"张\")) .skip(2); // 5.将两个队伍合并为一个队伍; Stream&lt;String&gt; streamAB = Stream.concat(streamA, streamB); // 6.根据姓名创建`Person`对象; // 7.打印整个队伍的Person对象信息。 streamAB.map(Person2::new).forEach(System.out::println); } } 收集Stream流中的结果Stream流中的结果到集合中 // 将流中数据收集到集合中 @Test public void testStreamToCollection() { Stream&lt;String&gt; stream = Stream.of(\"aa\", \"bb\", \"cc\", \"bb\"); // 将流中数据收集到集合中 // collect收集流中的数据到集合中 List&lt;String&gt; list = stream.collect(Collectors.toList()); System.out.println(\"list = \" + list); Stream&lt;String&gt; stream2 = Stream.of(\"aa\", \"bb\", \"cc\", \"bb\"); Set&lt;String&gt; set = stream2.collect(Collectors.toSet()); System.out.println(\"set = \" + set); // 收集到指定的集合中ArrayList Stream&lt;String&gt; stream3 = Stream.of(\"aa\", \"bb\", \"cc\", \"bb\"); ArrayList&lt;String&gt; arrayList = stream3.collect(Collectors.toCollection(ArrayList::new)); System.out.println(\"arrayList = \" + arrayList); Stream&lt;String&gt; stream4 = Stream.of(\"aa\", \"bb\", \"cc\", \"bb\"); HashSet&lt;String&gt; hashSet = stream4.collect(Collectors.toCollection(HashSet::new)); System.out.println(\"hashSet = \" + hashSet); } Stream流中的结果到数组中 // 将流中数据收集到数组中 @Test public void testStreamToArray() { Stream&lt;String&gt; stream1 = Stream.of(\"aa\", \"bb\", \"cc\"); // 转成Object数组不方便 Object[] objects = stream1.toArray(); for (Object o : objects) { System.out.println(\"o = \" + o); } Stream&lt;String&gt; stream2 = Stream.of(\"aa\", \"bb\", \"cc\"); String[] strings = stream2.toArray(String[]::new); for (String string : strings) { System.out.println(\"string = \" + string + \", 长度: \" + string.length()); } } 对流中数据进行聚合计算 // 其他收集流中数据的方式(相当于数据库中的聚合函数) @Test public void testStreamToOther() { Stream&lt;Student&gt; studentStream1 = Stream.of( new Student(\"赵丽颖\", 58, 95), new Student(\"杨颖\", 56, 88), new Student(\"迪丽热巴\", 56, 99), new Student(\"柳岩\", 52, 77)); // 获取最大值 Optional&lt;Student&gt; max = studentStream1.collect(Collectors.maxBy((s1, s2) -&gt; s1.getSocre() - s2.getSocre())); System.out.println(\"最大值: \" + max.get()); Stream&lt;Student&gt; studentStream2 = Stream.of( new Student(\"赵丽颖\", 58, 95), new Student(\"杨颖\", 56, 88), new Student(\"迪丽热巴\", 56, 99), new Student(\"柳岩\", 52, 77)); // 获取最小值 Optional&lt;Student&gt; min = studentStream2.collect(Collectors.minBy((s1, s2) -&gt; s1.getSocre() - s2.getSocre())); System.out.println(\"最小值: \" + min.get()); Stream&lt;Student&gt; studentStream3 = Stream.of( new Student(\"赵丽颖\", 58, 95), new Student(\"杨颖\", 56, 88), new Student(\"迪丽热巴\", 56, 99), new Student(\"柳岩\", 52, 77)); // 求总和 Integer sum = studentStream3.collect(Collectors.summingInt(s -&gt; s.getAge())); System.out.println(\"总和: \" + sum); Stream&lt;Student&gt; studentStream4 = Stream.of( new Student(\"赵丽颖\", 58, 95), new Student(\"杨颖\", 56, 88), new Student(\"迪丽热巴\", 56, 99), new Student(\"柳岩\", 52, 77)); // 平均值 Double avg = studentStream4.collect(Collectors.averagingInt(s -&gt; s.getSocre())); // Double avg = studentStream4.collect(Collectors.averagingInt(Student::getSocre)); System.out.println(\"平均值: \" + avg); Stream&lt;Student&gt; studentStream5 = Stream.of( new Student(\"赵丽颖\", 58, 95), new Student(\"杨颖\", 56, 88), new Student(\"迪丽热巴\", 56, 99), new Student(\"柳岩\", 52, 77)); // 统计数量 Long count = studentStream5.collect(Collectors.counting()); System.out.println(\"统计数量: \" + count); } 对流中的数据进行分组 // 分组 @Test public void testGroup() { Stream&lt;Student&gt; studentStream = Stream.of( new Student(\"赵丽颖\", 52, 95), new Student(\"杨颖\", 56, 88), new Student(\"迪丽热巴\", 56, 55), new Student(\"柳岩\", 52, 33)); // Map&lt;Integer, List&lt;Student&gt;&gt; map = studentStream.collect(Collectors.groupingBy(Student::getAge)); // 将分数大于60的分为一组,小于60分成另一组 Map&lt;String, List&lt;Student&gt;&gt; map = studentStream.collect(Collectors.groupingBy((s) -&gt; { if (s.getSocre() &gt; 60) { return \"及格\"; } else { return \"不及格\"; } })); map.forEach((k, v) -&gt; { System.out.println(k + \"::\" + v); }); } 对流中数据进行多级分组 // 多级分组 @Test public void testCustomGroup() { Stream&lt;Student&gt; studentStream = Stream.of( new Student(\"赵丽颖\", 52, 95), new Student(\"杨颖\", 56, 88), new Student(\"迪丽热巴\", 56, 55), new Student(\"柳岩\", 52, 33)); // 先根据年龄分组,每组中在根据成绩分组 // groupingBy(Function&lt;? super T, ? extends K&gt; classifier, Collector&lt;? super T, A, D&gt; downstream) Map&lt;Integer, Map&lt;String, List&lt;Student&gt;&gt;&gt; map = studentStream.collect(Collectors.groupingBy(Student::getAge, Collectors.groupingBy((s) -&gt; { if (s.getSocre() &gt; 60) { return \"及格\"; } else { return \"不及格\"; } }))); // 遍历 map.forEach((k, v) -&gt; { System.out.println(k); // v还是一个map,再次遍历 v.forEach((k2, v2) -&gt; { System.out.println(\"\\t\" + k2 + \" == \" + v2); }); }); } 对流中数据进行分区 // 分区 @Test public void testPartition() { Stream&lt;Student&gt; studentStream = Stream.of( new Student(\"赵丽颖\", 52, 95), new Student(\"杨颖\", 56, 88), new Student(\"迪丽热巴\", 56, 55), new Student(\"柳岩\", 52, 33)); Map&lt;Boolean, List&lt;Student&gt;&gt; map = studentStream.collect(Collectors.partitioningBy(s -&gt; { return s.getSocre() &gt; 60; })); map.forEach((k, v) -&gt; { System.out.println(k + \" :: \" + v); }); } 结果 false :: [Student{name='迪丽热巴', age=56, socre=55}, Student{name='柳岩', age=52, socre=33}] true :: [Student{name='赵丽颖', age=52, socre=95}, Student{name='杨颖', age=56, socre=88}] 对流中数据进行拼接 // 拼接 @Test public void testJoining() { Stream&lt;Student&gt; studentStream = Stream.of( new Student(\"赵丽颖\", 52, 95), new Student(\"杨颖\", 56, 88), new Student(\"迪丽热巴\", 56, 99), new Student(\"柳岩\", 52, 77)); // 根据一个字符串拼接: 赵丽颖__杨颖__迪丽热巴__柳岩 // String names = studentStream.map(Student::getName).collect(Collectors.joining(\"__\")); // 根据三个字符串拼接 String names = studentStream.map(Student::getName).collect(Collectors.joining(\"__\", \"^_^\", \"V_V\")); System.out.println(\"names = \" + names); } 结果 names = ^_^赵丽颖__杨颖__迪丽热巴__柳岩V_V 并行Stream流串行Stream流在一个线程上执行 @Test public void test0Serial() { Stream.of(4, 5, 3, 9, 1, 2, 6) .filter(s -&gt; { System.out.println(Thread.currentThread() + \"::\" + s); return s &gt; 3; }).count(); } 结果 Thread[main,5,main]::4 Thread[main,5,main]::5 Thread[main,5,main]::3 Thread[main,5,main]::9 Thread[main,5,main]::1 Thread[main,5,main]::2 Thread[main,5,main]::6 并行Stream流parallelStream其实就是一个并行执行的流。它通过默认的ForkJoinPool，可能提高多线程任务的速度。 获取并行Stream流的两种方式 直接获取并行的流 将串行流转成并行流@Test public void testgetParallelStream() { // 掌握获取并行Stream流的两种方式 // 方式一:直接获取并行的Stream流 List&lt;String&gt; list = new ArrayList&lt;&gt;(); Stream&lt;String&gt; stream = list.parallelStream(); // 方式二:将串行流转成并行流 Stream&lt;String&gt; parallel = list.stream().parallel(); } 并行操作代码@Test public void testParallel() { long count = Stream.of(4, 5, 3, 9, 1, 2, 6) .parallel() // 转成并行流 .filter(s -&gt; { System.out.println(Thread.currentThread() + \"::\" + s); return s &gt; 3; }) .count(); System.out.println(\"count = \" + count); } 并行和串行Stream流的效率对比使用for循环，串行Stream流，并行Stream流来对5亿个数字求和。看消耗的时间。 public class Demo07Parallel { private static final int times = 500000000; long start; @Before public void init() { start = System.currentTimeMillis(); } @After public void destory() { long end = System.currentTimeMillis(); System.out.println(\"消耗时间:\" + (end - start)); } // 并行的Stream : 消耗时间:115 @Test public void testParallelStream() { LongStream.rangeClosed(0, times).parallel().reduce(0, Long::sum); } // 串行的Stream : 消耗时间:804 @Test public void testStream() { // 得到5亿个数字,并求和 LongStream.rangeClosed(0, times).reduce(0, Long::sum); } // 使用for循环 : 消耗时间:174 @Test public void testFor() { int sum = 0; for (int i = 0; i &lt; times; i++) { sum += i; } } } parallelStream的效率是最高的Stream并行处理的过程会分而治之，也就是将一个大任务切分成多个小任务，这表示每个任务都是一个操作。 parallelStream线程安全问题 // parallelStream线程安全问题 @Test public void parallelStreamNotice() { ArrayList&lt;Integer&gt; list = new ArrayList&lt;&gt;(); IntStream.rangeClosed(1, 1000) .parallel() .forEach(i -&gt; { list.add(i); }); System.out.println(\"list = \" + list.size()); } 运行结果list不等于1000解决方法： 加锁、使用线程安全的集合或者调用Stream的 toArray() / collect() 操作就是满足线程安全的了。 @Test public void parallelStreamNotice() { ArrayList&lt;Integer&gt; list = new ArrayList&lt;&gt;(); // 解决parallelStream线程安全问题方案一: 使用同步代码块 Object obj = new Object(); IntStream.rangeClosed(1, 1000) .parallel() .forEach(i -&gt; { synchronized (obj) { list.add(i); } }); System.out.println(\"list = \" + list.size()); // 解决parallelStream线程安全问题方案二: 使用线程安全的集合 // Vector&lt;Integer&gt; v = new Vector(); List&lt;Integer&gt; synchronizedList = Collections.synchronizedList(list); IntStream.rangeClosed(1, 1000) .parallel() .forEach(i -&gt; { synchronizedList.add(i); }); System.out.println(\"list = \" + synchronizedList.size()); // 解决parallelStream线程安全问题方案三: 调用Stream流的collect/toArray List&lt;Integer&gt; collect = IntStream.rangeClosed(1, 1000) .parallel() .boxed() .collect(Collectors.toList()); System.out.println(\"collect.size = \" + collect.size()); } Fork/Join框架parallelStream使用的是Fork/Join框架。Fork/Join框架自JDK 7引入。Fork/Join框架可以将一个大任务拆分为很多小任务来异步执行。 Fork/Join框架主要包含三个模块： 线程池：ForkJoinPool 任务对象：ForkJoinTask 执行任务的线程：ForkJoinWorkerThread Optional类Optional是一个没有子类的工具类，Optional是一个可以为null的容器对象。它的作用主要就是为了解决避免Null检查，防止NullPointerException。 Optional的基本使用Optional类的创建方式： Optional.of(T t) : 创建一个 Optional 实例 Optional.empty() : 创建一个空的 Optional 实例 Optional.ofNullable(T t):若 t 不为 null,创建 Optional 实例,否则创建空实例 Optional类的常用方法： isPresent() : 判断是否包含值,包含值返回true，不包含值返回false get() : 如果Optional有值则将其返回，否则抛出NoSuchElementException orElse(T t) : 如果调用对象包含值，返回该值，否则返回参数t orElseGet(Supplier s) :如果调用对象包含值，返回该值，否则返回 s 获取的值 map(Function f): 如果有值对其处理，并返回处理后的Optional，否则返回 Optional.empty() Test: @Test public void test02() { // 1.创建Optional对象 // of:只能传入一个具体值,不能传入null // ofNullable: 既可以传入具体值,也可以传入null // empty: 存入的是null Optional&lt;String&gt; op1 = Optional.of(\"凤姐\"); //Optional&lt;String&gt; op11 = Optional.of(null); //报错 Optional&lt;String&gt; op2 = Optional.ofNullable(\"如花\"); Optional&lt;String&gt; op22 = Optional.ofNullable(null); Optional&lt;Object&gt; op3 = Optional.empty(); // 2.isPresent: 判断Optional中是否有具体值, 有值返回true,没有值返回false boolean present = op3.isPresent(); System.out.println(\"present = \" + present); // 3.get: 获取Optional中的值,如果有值就返回值具体值,没有值就报错 // System.out.println(op3.get()); if (op1.isPresent()) { System.out.println(op1.get()); } else { System.out.println(\"没有值\"); } } Optional的高级使用@Test public void test03() { // Optional&lt;String&gt; userNameO = Optional.of(\"凤姐\"); Optional&lt;String&gt; userNameO = Optional.empty(); // orElse: 如果Optional中有值,就取出这个值,如果没有值就使用参数指定的值 String name = userNameO.orElse(\"如花吗?\"); System.out.println(\"name = \" + name); } @Test public void test04() { // Optional&lt;String&gt; userNameO = Optional.of(\"凤姐\"); Optional&lt;String&gt; userNameO = Optional.empty(); // 存在做的什么 // ifPresent: 如果有值就调用参数 userNameO.ifPresent(s -&gt; { System.out.println(\"有值: \" + s); }); // ifPresentOrElse: 存在做的什么,不存在做点什么 userNameO.ifPresentOrElse(s -&gt; { System.out.println(\"有值: \" + s); }, () -&gt; { System.out.println(\"没有值\"); }); } @Test public void test05() { User u = new User(\"Hello\", 18); // getUpperUserName1(u); Optional&lt;User&gt; op = Optional.of(u); System.out.println(getUpperUserName2(op)); } // 定义一个方法将User中的用户名转成大写并返回 // 使用Optional方式 public String getUpperUserName2(Optional&lt;User&gt; op) { /*String upperName = op.map(u -&gt; u.getUserName()) .map(s -&gt; s.toUpperCase()) .orElse(\"null\");*/ String upperName = op.map(User::getUserName) .map(String::toUpperCase) .orElse(\"null\"); return upperName; } // 定义一个方法将User中的用户名转成大写并返回 // 使用传统方式 public String getUpperUserName1(User u) { if (u != null) { String userName = u.getUserName(); if (userName != null) { return userName.toUpperCase(); } else { return null; } } else { return null; } } Optional是一个可以为null的容器对象。orElse，ifPresent，ifPresentOrElse，map等方法避免对null的判断，写出更加优雅的代码。 JDK8新的时间和日期API旧版日期API存在的问题 设计很差： 在java.util和java.sql的包中都有日期类，java.util.Date同时包含日期和时间，而java.sql.Date仅包含日期。此外用于格式化和解析的类在java.text包中定义。 非线程安全：java.util.Date 是非线程安全的，所有的日期类都是可变的，这是Java日期类最大的问题之一。 时区处理麻烦：日期类并不提供国际化，没有时区支持，因此Java引入了java.util.Calendar和java.util.TimeZone类，但他们同样存在上述所有的问题。 新日期时间APIJDK 8中增加了一套全新的日期时间API，这套API设计合理，是线程安全的。新的日期及时间API位于 java.time 包中，下面是一些关键类。 LocalDate ：表示日期，包含年月日，格式为 2019-10-16 LocalTime ：表示时间，包含时分秒，格式为 16:38:54.158549300 LocalDateTime ：表示日期时间，包含年月日，时分秒，格式为 2018-09-06T15:33:56.750 DateTimeFormatter ：日期时间格式化类 Instant：时间戳，表示一个特定的时间瞬间 Duration：用于计算2个时间(LocalTime，时分秒)的距离 Period：用于计算2个日期(LocalDate，年月日)的距离 ZonedDateTime ：包含时区的时间 JDK 8的日期和时间类LocalDate、LocalTime、LocalDateTime类的实例是不可变的对象，分别表示使用 ISO-8601 日历系统的日期、时间、日期和时间。它们提供了简单的日期或时间，并不包含当前的时间信息，也不包含与时区相关的信息。 @Test public void testLocalDate() { // LocalDate: 表示日期,有年月日 LocalDate date = LocalDate.of(2018, 8, 8); System.out.println(\"date = \" + date); LocalDate now = LocalDate.now(); System.out.println(\"now = \" + now); System.out.println(now.getYear()); System.out.println(now.getMonthValue()); System.out.println(now.getDayOfMonth()); } @Test public void testLocalTime() { // LocalTime: 表示时间,有时分秒 LocalTime time = LocalTime.of(13, 26, 39); System.out.println(\"time = \" + time); LocalTime now = LocalTime.now(); System.out.println(\"now = \" + now); System.out.println(now.getHour()); System.out.println(now.getMinute()); System.out.println(now.getSecond()); System.out.println(now.getNano()); } @Test public void testLocalDateTime() { // LocalDateTime: LocalDate + LocalTime 有年月日 时分秒 LocalDateTime dateTime = LocalDateTime.of(2018, 7, 12, 13, 28, 59); System.out.println(\"dateTime = \" + dateTime); LocalDateTime now = LocalDateTime.now(); System.out.println(\"now = \" + now); System.out.println(now.getY System.out.println(now.getMonthValue()); System.out.println(now.getDayOfMonth()); System.out.println(now.getHour()); System.out.println(now.getMinute()); System.out.println(now.getSecond()); } 对日期时间的修改，对已存在的LocalDate对象，创建它的修改版，最简单的方式是使用withAttribute方法。 withAttribute方法会创建对象的一个副本，并按照需要修改它的属性。以下所有的方法都返回了一个修改属性的对象，他们不会影响原来的对象。 // 修改时间 @Test public void testLocalDateTime2() { LocalDateTime now = LocalDateTime.now(); // 修改时间,修改后返回新的时间对象 LocalDateTime dateTime = now.withYear(9102); System.out.println(\"dateTime = \" + dateTime); System.out.println(\"now == dateTime: \" + (now == dateTime)); // 增加或减去时间 // plus: 增加指定的时间 // minus: 减去指定的时间 System.out.println(now.plusYears(2)); System.out.println(now.minusYears(10)); } // 比较时间 @Test public void testEquals() { LocalDateTime dateTime = LocalDateTime.of(2018, 7, 12, 13, 28, 59); LocalDateTime now = LocalDateTime.now(); System.out.println(now.isAfter(dateTime)); // true System.out.println(now.isBefore(dateTime)); // false System.out.println(now.isEqual(dateTime)); // false } JDK8时间格式化和解析通过 java.time.format.DateTimeFormatter 类可以进行日期时间解析与格式化。 // 日期格式化 @Test public void test04() { // 创建一个日期时间 LocalDateTime now = LocalDateTime.now(); // 格式化 // 指定时间的格式 // JDK自带的时间格式 // DateTimeFormatter dtf = DateTimeFormatter.ISO_DATE_TIME; DateTimeFormatter dtf = DateTimeFormatter.ofPattern(\"yyyy年MM月dd HH时mm分ss秒\"); String format = now.format(dtf); System.out.println(\"format = \" + format); // 解析 for (int i = 0; i &lt; 50; i++) { new Thread(() -&gt; { LocalDateTime parse = LocalDateTime.parse(\"2016年09月20 15时16分16秒\", dtf); System.out.println(\"parse = \" + parse); }).start(); } } 线程安全的 JDK8的Instant类Instant 时间戳/时间线，内部保存了从1970年1月1日 00:00:00以来的秒和纳秒 // 时间戳 @Test public void test07() { // Instant内部保存了秒和纳秒,一般不是给用户使用的,而是方便我们程序做一些统计的. Instant now = Instant.now(); System.out.println(\"now = \" + now); // 2019-10-19T07:30:42.629520400Z Instant plus = now.plusSeconds(20); System.out.println(\"plus = \" + plus); Instant minus = now.minusSeconds(20); System.out.println(\"minus = \" + minus); // 得到秒纳秒 System.out.println(now.getEpochSecond()); System.out.println(now.getNano()); } JDK 8的计算日期时间差类Duration/Period类: 计算日期时间差。 Duration：用于计算2个时间(LocalTime，时分秒)的距离 Period：用于计算2个日期(LocalDate，年月日)的距离 // Duration/Period类: 计算日期时间差 @Test public void test08() { // Duration计算时间的距离 LocalTime now = LocalTime.now(); LocalTime time = LocalTime.of(14, 15, 20); Duration duration = Duration.between(time, now); System.out.println(\"相差的天数:\" + duration.toDays()); System.out.println(\"相差的小时数:\" + duration.toHours()); System.out.println(\"相差的分钟数:\" + duration.toMinutes()); System.out.println(\"相差的秒数:\" + duration.toSeconds()); // Period计算日期的距离 LocalDate nowDate = LocalDate.now(); LocalDate date = LocalDate.of(1998, 8, 8); // 让后面的时间减去前面的时间 Period period = Period.between(date, nowDate); System.out.println(\"相差的年:\" + period.getYears()); System.out.println(\"相差的月:\" + period.getMonths()); System.out.println(\"相差的天:\" + period.getDays()); } JDK8时间校正器将日期调整到“下一个月的第一天”等操作。可以通过时间校正器来进行。 TemporalAdjuster : 时间校正器 TemporalAdjusters : 该类通过静态方法提供了大量的常用TemporalAdjuster的实现。 // TemporalAdjuster类:自定义调整时间 @Test public void test09() { LocalDateTime now = LocalDateTime.now(); // 将日期调整到“下一个月的第一天”操作。 TemporalAdjuster firstDayOfNextMonth = temporal -&gt; { // temporal要调整的时间 LocalDateTime dateTime = (LocalDateTime) temporal; return dateTime.plusMonths(1).withDayOfMonth(1); // 下一个月的第一天 }; // JDK中自带了很多时间调整器 // LocalDateTime newDateTime = now.with(firstDayOfNextMonth); LocalDateTime newDateTime = now.with(TemporalAdjusters.firstDayOfNextYear()); System.out.println(\"newDateTime = \" + newDateTime); } JDK 8设置日期时间的时区Java8 中加入了对时区的支持，LocalDate、LocalTime、LocalDateTime是不带时区的，带时区的日期时间类分别为：ZonedDate、ZonedTime、ZonedDateTime。其中每个时区都对应着 ID，ID的格式为 “区域/城市” 。例如 ：Asia/Shanghai 等。 ZoneId：该类中包含了所有的时区信息。 // 设置日期时间的时区 @Test public void test10() { // 1.获取所有的时区ID // ZoneId.getAvailableZoneIds().forEach(System.out::println); // 不带时间,获取计算机的当前时间 LocalDateTime now = LocalDateTime.now(); // 中国使用的东八区的时区.比标准时间早8个小时 System.out.println(\"now = \" + now); // 2.操作带时区的类 // now(Clock.systemUTC()): 创建世界标准时间 ZonedDateTime bz = ZonedDateTime.now(Clock.systemUTC()); System.out.println(\"bz = \" + bz); // now(): 使用计算机的默认的时区,创建日期时间 ZonedDateTime now1 = ZonedDateTime.now(); System.out.println(\"now1 = \" + now1); // 2019-10-19T16:19:44.007153500+08:00[Asia/Shanghai] // 使用指定的时区创建日期时间 ZonedDateTime now2 = ZonedDateTime.now(ZoneId.of(\"America/Vancouver\")); System.out.println(\"now2 = \" + now2); // 2019-10-19T01:53:41.225898600-07:00[America/Vancouver] // 修改时区 // withZoneSameInstant: 即更改时区,也更改时间 ZonedDateTime withZoneSameInstant = now2.withZoneSameInstant(ZoneId.of(\"Asia/Shanghai\")); System.out.println(\"withZoneSameInstant = \" + withZoneSameInstant); // 2019-10-19T16:53:41.225898600+08:00[Asia/Shanghai] // withZoneSameLocal: 只更改时区,不更改时间 ZonedDateTime withZoneSameLocal = now2.withZoneSameLocal(ZoneId.of(\"Asia/Shanghai\")); System.out.println(\"withZoneSameLocal = \" + withZoneSameLocal); // 2019-10-19T01:54:52.058871300+08:00[Asia/Shanghai] } 小结详细学习了新的日期是时间相关类，LocalDate表示日期,包含年月日,LocalTime表示时间,包含时分秒,LocalDateTime = LocalDate + LocalTime,时间的格式化和解析,通过DateTimeFormatter类型进行。 学习了Instant类,方便操作秒和纳秒,一般是给程序使用的.学习Duration/Period计算日期或时间的距离,还使用时间调 整器方便的调整时间,学习了带时区的3个类ZoneDate/ZoneTime/ZoneDateTime。 JDK8新的时间和日期API的优势： 新版的日期和时间API中，日期和时间对象是不可变的。操纵的日期不会影响老值，而是新生成一个实例。 新的API提供了两种不同的时间表示方式，有效地区分了人和机器的不同需求。 TemporalAdjuster可以更精确的操纵日期，还可以自定义日期调整器。 线程安全 JDK 8重复注解与类型注解在JDK 8中使用**@Repeatable**注解定义重复注解。 重复注解的使用步骤： 定义重复的注解容器注解 // 1.定义重复的注解容器注解 @Retention(RetentionPolicy.RUNTIME) @interface MyTests { // 这是重复注解的容器 MyTest[] value(); } 定义一个可以重复的注解 // 2.定义一个可以重复的注解 @Retention(RetentionPolicy.RUNTIME) @Repeatable(MyTests.class) @interface MyTest { String value(); } 配置多个重复的注解 @MyTest(\"ta\") @MyTest(\"tb\") @MyTest(\"tc\") public class Demo01 { ... } 解析得到指定注解 @MyTest(\"ta\") @MyTest(\"tb\") @MyTest(\"tc\") public class Demo01 { @Test @MyTest(\"ma\") @MyTest(\"mb\") public void test() { } public static void main(String[] args) throws NoSuchMethodException { // 4.解析重复注解 // 获取类上的重复注解 // getAnnotationsByType是新增的API用户获取重复的注解 MyTest[] annotationsByType = Demo01.class.getAnnotationsByType(MyTest.class); for (MyTest myTest : annotationsByType) { System.out.println(myTest); } System.out.println(\"----------\"); // 获取方法上的重复注解 MyTest[] tests = Demo01.class.getMethod(\"test\").getAnnotationsByType(MyTest.class); for (MyTest test : tests) { System.out.println(test); } } } 类型注解的使用JDK8为@Target元注解新增了两种类型： TYPE_PARAMETER,TYPE_USE。 TYPE_PARAMETER: 表示该注解能写在类型参数的声明语句中。 类型参数声明如： TYPE_USE: 表示注解可以再任何用到类型的地方使用。 TYPE_PARAMETER的使用 @Target(ElementType.TYPE_PARAMETER) @interface TypeParam { } public class Demo02 &lt;@TypeParam T&gt; { public &lt;@TypeParam E extends Integer&gt; void test01() { } } TYPE_USE的使用 @Target(ElementType.TYPE_USE) @interface NotNull { } public class Demo02 &lt;@TypeParam T&gt; { private @NotNull int a = 10; public void test(@NotNull String str, @NotNull int a) { @NotNull double d = 10.1; } public &lt;@TypeParam E extends Integer&gt; void test01() { } } 小结通过@Repeatable元注解可以定义可重复注解， TYPE_PARAMETER 可以让注解放在泛型上， TYPE_USE 可以让注解放在类型的前面","categories":[{"name":"java基础","slug":"java基础","permalink":"https://bowonqin.github.io/categories/java%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"java基础","slug":"java基础","permalink":"https://bowonqin.github.io/tags/java%E5%9F%BA%E7%A1%80/"},{"name":"jdk","slug":"jdk","permalink":"https://bowonqin.github.io/tags/jdk/"}],"author":"qxd"},{"title":"Mysql(数据处理之增删改)","slug":"mysql/第11章-数据处理之增删改","date":"2021-12-23T12:35:16.000Z","updated":"2021-12-23T12:58:47.481Z","comments":true,"path":"posts/mysql11.html","link":"","permalink":"https://bowonqin.github.io/posts/mysql11.html","excerpt":"","text":"第11章_数据处理之增删改康师傅（宋红康老师）听课笔记 BILIBILI听课网址：[宋红康]MySQL数据库（安装/基础/高级/优化）_哔哩哔哩_bilibili 1. 插入数据1.1 实际问题 解决方式：使用 INSERT 语句向表中插入数据。 1.2 方式1：VALUES的方式添加使用这种语法一次只能向表中插入一条数据。 情况1：为表的所有字段按默认顺序插入数据 INSERT INTO 表名 VALUES (value1,value2,....); 值列表中需要为表的每一个字段指定值，并且值的顺序必须和数据表中字段定义时的顺序相同。 举例： INSERT INTO departments VALUES (70, 'Pub', 100, 1700); INSERT INTO departments VALUES (100, 'Finance', NULL, NULL); 情况2：为表的指定字段插入数据 INSERT INTO 表名(column1 [, column2, …, columnn]) VALUES (value1 [,value2, …, valuen]); 为表的指定字段插入数据，就是在INSERT语句中只向部分字段中插入值，而其他字段的值为表定义时的默认值。 在 INSERT 子句中随意列出列名，但是一旦列出，VALUES中要插入的value1,….valuen需要与column1,…columnn列一一对应。如果类型不同，将无法插入，并且MySQL会产生错误。 举例： INSERT INTO departments(department_id, department_name) VALUES (80, 'IT'); 情况3：同时插入多条记录 INSERT语句可以同时向数据表中插入多条记录，插入时指定多个值列表，每个值列表之间用逗号分隔开，基本语法格式如下： INSERT INTO table_name VALUES (value1 [,value2, …, valuen]), (value1 [,value2, …, valuen]), …… (value1 [,value2, …, valuen]); 或者 INSERT INTO table_name(column1 [, column2, …, columnn]) VALUES (value1 [,value2, …, valuen]), (value1 [,value2, …, valuen]), …… (value1 [,value2, …, valuen]); 举例： mysql&gt; INSERT INTO emp(emp_id,emp_name) -&gt; VALUES (1001,'shkstart'), -&gt; (1002,'atguigu'), -&gt; (1003,'Tom'); Query OK, 3 rows affected (0.00 sec) Records: 3 Duplicates: 0 Warnings: 0 使用INSERT同时插入多条记录时，MySQL会返回一些在执行单行插入时没有的额外信息，这些信息的含义如下：● Records：表明插入的记录条数。● Duplicates：表明插入时被忽略的记录，原因可能是这些记录包含了重复的主键值。● Warnings：表明有问题的数据值，例如发生数据类型转换。 一个同时插入多行记录的INSERT语句等同于多个单行插入的INSERT语句，但是多行的INSERT语句在处理过程中效率更高。因为MySQL执行单条INSERT语句插入多行数据比使用多条INSERT语句快，所以在插入多条记录时最好选择使用单条INSERT语句的方式插入。 小结： VALUES也可以写成VALUE，但是VALUES是标准写法。 字符和日期型数据应包含在单引号中。 1.3 方式2：将查询结果插入到表中INSERT还可以将SELECT语句查询的结果插入到表中，此时不需要把每一条记录的值一个一个输入，只需要使用一条INSERT语句和一条SELECT语句组成的组合语句即可快速地从一个或多个表中向一个表中插入多行。 基本语法格式如下： INSERT INTO 目标表名 (tar_column1 [, tar_column2, …, tar_columnn]) SELECT (src_column1 [, src_column2, …, src_columnn]) FROM 源表名 [WHERE condition] 在 INSERT 语句中加入子查询。 不必书写 VALUES 子句。 子查询中的值列表应与 INSERT 子句中的列名对应。 举例： INSERT INTO emp2 SELECT * FROM employees WHERE department_id = 90; INSERT INTO sales_reps(id, name, salary, commission_pct) SELECT employee_id, last_name, salary, commission_pct FROM employees WHERE job_id LIKE '%REP%'; 2. 更新数据 使用 UPDATE 语句更新数据。语法如下： UPDATE table_name SET column1=value1, column2=value2, … , column=valuen [WHERE condition] 可以一次更新多条数据。 如果需要回滚数据，需要保证在DML前，进行设置：SET AUTOCOMMIT = FALSE; 使用 WHERE 子句指定需要更新的数据。 UPDATE employees SET department_id = 70 WHERE employee_id = 113; 如果省略 WHERE 子句，则表中的所有数据都将被更新。 UPDATE copy_emp SET department_id = 110; 更新中的数据完整性错误 UPDATE employees SET department_id = 55 WHERE department_id = 110; 说明：不存在 55 号部门 3. 删除数据 使用 DELETE 语句从表中删除数据 DELETE FROM table_name [WHERE &lt;condition&gt;]; table_name指定要执行删除操作的表；“[WHERE ]”为可选参数，指定删除条件，如果没有WHERE子句，DELETE语句将删除表中的所有记录。 使用 WHERE 子句删除指定的记录。 DELETE FROM departments WHERE department_name = 'Finance'; 如果省略 WHERE 子句，则表中的全部数据将被删除 DELETE FROM copy_emp; 删除中的数据完整性错误 DELETE FROM departments WHERE department_id = 60; 说明：You cannot delete a row that contains a primary key that is used as a foreign key in another table. 4. MySQL8新特性：计算列什么叫计算列呢？简单来说就是某一列的值是通过别的列计算得来的。例如，a列值为1、b列值为2，c列不需要手动插入，定义a+b的结果为c的值，那么c就是计算列，是通过别的列计算得来的。 在MySQL 8.0中，CREATE TABLE 和 ALTER TABLE 中都支持增加计算列。下面以CREATE TABLE为例进行讲解。 举例：定义数据表tb1，然后定义字段id、字段a、字段b和字段c，其中字段c为计算列，用于计算a+b的值。首先创建测试表tb1，语句如下： CREATE TABLE tb1( id INT, a INT, b INT, c INT GENERATED ALWAYS AS (a + b) VIRTUAL ); 插入演示数据，语句如下： INSERT INTO tb1(a,b) VALUES (100,200); 查询数据表tb1中的数据，结果如下： mysql&gt; SELECT * FROM tb1; +------+------+------+------+ | id | a | b | c | +------+------+------+------+ | NULL | 100 | 200 | 300 | +------+------+------+------+ 1 row in set (0.00 sec) 更新数据中的数据，语句如下： mysql&gt; UPDATE tb1 SET a = 500; Query OK, 0 rows affected (0.00 sec) Rows matched: 1 Changed: 0 Warnings: 0 5. 综合案例# 1、创建数据库test01_library # 2、创建表 books，表结构如下： 字段名 字段说明 数据类型 id 书编号 INT name 书名 VARCHAR(50) authors 作者 VARCHAR(100) price 价格 FLOAT pubdate 出版日期 YEAR note 说明 VARCHAR(100) num 库存 INT # 3、向books表中插入记录 # 1）不指定字段名称，插入第一条记录 # 2）指定所有字段名称，插入第二记录 # 3）同时插入多条记录（剩下的所有记录） id name authors price pubdate note num 1 Tal of AAA Dickes 23 1995 novel 11 2 EmmaT Jane lura 35 1993 joke 22 3 Story of Jane Jane Tim 40 2001 novel 0 4 Lovey Day George Byron 20 2005 novel 30 5 Old land Honore Blade 30 2010 law 0 6 The Battle Upton Sara 30 1999 medicine 40 7 Rose Hood Richard haggard 28 2008 cartoon 28 # 4、将小说类型(novel)的书的价格都增加5。 # 5、将名称为EmmaT的书的价格改为40，并将说明改为drama。 # 6、删除库存为0的记录。 # 7、统计书名中包含a字母的书 # 8、统计书名中包含a字母的书的数量和库存总量 # 9、找出“novel”类型的书，按照价格降序排列 # 10、查询图书信息，按照库存量降序排列，如果库存量相同的按照note升序排列 # 11、按照note分类统计书的数量 # 12、按照note分类统计书的库存量，显示库存量超过30本的 # 13、查询所有图书，每页显示5本，显示第二页 # 14、按照note分类统计书的库存量，显示库存量最多的 # 15、查询书名达到10个字符的书，不包括里面的空格 # 16、查询书名和类型，其中note值为novel显示小说，law显示法律，medicine显示医药，cartoon显示卡通，joke显示笑话 # 17、查询书名、库存，其中num值超过30本的，显示滞销，大于0并低于10的，显示畅销，为0的显示需要无货 # 18、统计每一种note的库存量，并合计总量 # 19、统计每一种note的数量，并合计总量 # 20、统计库存量前三名的图书 # 21、找出最早出版的一本书 # 22、找出novel中价格最高的一本书 # 23、找出书名中字数最多的一本书，不含空格 答案： #1、创建数据库test01_library CREATE DATABASE IF NOT EXISTS test01_library CHARACTER SET 'utf8'; #指定使用哪个数据库 USE test01_library; #2、创建表 books CREATE TABLE books( id INT, name VARCHAR(50), `authors` VARCHAR(100) , price FLOAT, pubdate YEAR , note VARCHAR(100), num INT ); #3、向books表中插入记录 # 1）不指定字段名称，插入第一条记录 INSERT INTO books VALUES(1,'Tal of AAA','Dickes',23,1995,'novel',11); # 2）指定所有字段名称，插入第二记录 INSERT INTO books (id,name,`authors`,price,pubdate,note,num) VALUES(2,'EmmaT','Jane lura',35,1993,'Joke',22); # 3）同时插入多条记录（剩下的所有记录） INSERT INTO books (id,name,`authors`,price,pubdate,note,num) VALUES (3,'Story of Jane','Jane Tim',40,2001,'novel',0), (4,'Lovey Day','George Byron',20,2005,'novel',30), (5,'Old land','Honore Blade',30,2010,'Law',0), (6,'The Battle','Upton Sara',30,1999,'medicine',40), (7,'Rose Hood','Richard haggard',28,2008,'cartoon',28); # 4、将小说类型(novel)的书的价格都增加5。 UPDATE books SET price=price+5 WHERE note = 'novel'; # 5、将名称为EmmaT的书的价格改为40，并将说明改为drama。 UPDATE books SET price=40,note='drama' WHERE name='EmmaT'; # 6、删除库存为0的记录。 DELETE FROM books WHERE num=0; # 7、统计书名中包含a字母的书 SELECT * FROM books WHERE name LIKE '%a%'; # 8、统计书名中包含a字母的书的数量和库存总量 SELECT COUNT(*),SUM(num) FROM books WHERE name LIKE '%a%'; # 9、找出“novel”类型的书，按照价格降序排列 SELECT * FROM books WHERE note = 'novel' ORDER BY price DESC; # 10、查询图书信息，按照库存量降序排列，如果库存量相同的按照note升序排列 SELECT * FROM books ORDER BY num DESC,note ASC; # 11、按照note分类统计书的数量 SELECT note,COUNT(*) FROM books GROUP BY note; # 12、按照note分类统计书的库存量，显示库存量超过30本的 SELECT note,SUM(num) FROM books GROUP BY note HAVING SUM(num)&gt;30; # 13、查询所有图书，每页显示5本，显示第二页 SELECT * FROM books LIMIT 5,5; # 14、按照note分类统计书的库存量，显示库存量最多的 SELECT note,SUM(num) sum_num FROM books GROUP BY note ORDER BY sum_num DESC LIMIT 0,1; # 15、查询书名达到10个字符的书，不包括里面的空格 SELECT * FROM books WHERE CHAR_LENGTH(REPLACE(name,' ',''))&gt;=10; /* 16、查询书名和类型， 其中note值为 novel显示小说，law显示法律，medicine显示医药，cartoon显示卡通，joke显示笑话 */ SELECT name AS \"书名\" ,note, CASE note WHEN 'novel' THEN '小说' WHEN 'law' THEN '法律' WHEN 'medicine' THEN '医药' WHEN 'cartoon' THEN '卡通' WHEN 'joke' THEN '笑话' END AS \"类型\" FROM books; # 17、查询书名、库存，其中num值超过30本的，显示滞销，大于0并低于10的，显示畅销，为0的显示需要无货 SELECT name,num,CASE WHEN num&gt;30 THEN '滞销' WHEN num&gt;0 AND num&lt;10 THEN '畅销' WHEN num=0 THEN '无货' ELSE '正常' END AS \"库存状态\" FROM books; # 18、统计每一种note的库存量，并合计总量 SELECT IFNULL(note,'合计总库存量') AS note,SUM(num) FROM books GROUP BY note WITH ROLLUP; # 19、统计每一种note的数量，并合计总量 SELECT IFNULL(note,'合计总数') AS note,COUNT(*) FROM books GROUP BY note WITH ROLLUP; # 20、统计库存量前三名的图书 SELECT * FROM books ORDER BY num DESC LIMIT 0,3; # 21、找出最早出版的一本书 SELECT * FROM books ORDER BY pubdate ASC LIMIT 0,1; # 22、找出novel中价格最高的一本书 SELECT * FROM books WHERE note = 'novel' ORDER BY price DESC LIMIT 0,1; # 23、找出书名中字数最多的一本书，不含空格 SELECT * FROM books ORDER BY CHAR_LENGTH(REPLACE(name,' ','')) DESC LIMIT 0,1;","categories":[{"name":"Mysql基础篇","slug":"Mysql基础篇","permalink":"https://bowonqin.github.io/categories/Mysql%E5%9F%BA%E7%A1%80%E7%AF%87/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"https://bowonqin.github.io/tags/Mysql/"},{"name":"数据库","slug":"数据库","permalink":"https://bowonqin.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"author":"qxd"},{"title":"Mysql(创建和管理表)","slug":"mysql/第10章-创建和管理表","date":"2021-12-23T12:14:27.000Z","updated":"2021-12-23T12:45:12.227Z","comments":true,"path":"posts/mysql10.html","link":"","permalink":"https://bowonqin.github.io/posts/mysql10.html","excerpt":"","text":"第10章_创建和管理表康师傅（宋红康老师）听课笔记 BILIBILI听课网址：[宋红康]MySQL数据库（安装/基础/高级/优化）_哔哩哔哩_bilibili 1. 基础知识1.1 一条数据存储的过程存储数据是处理数据的第一步。只有正确地把数据存储起来，我们才能进行有效的处理和分析。否则，只能是一团乱麻，无从下手。 那么，怎样才能把用户各种经营相关的、纷繁复杂的数据，有序、高效地存储起来呢？ 在 MySQL 中，一个完整的数据存储过程总共有 4 步，分别是创建数据库、确认字段、创建数据表、插入数据。 我们要先创建一个数据库，而不是直接创建数据表呢？ 因为从系统架构的层次上看，MySQL 数据库系统从大到小依次是数据库服务器、数据库、数据表、数据表的行与列。 MySQL 数据库服务器之前已经安装。所以，我们就从创建数据库开始。 1.2 标识符命名规则 数据库名、表名不得超过30个字符，变量名限制为29个 必须只能包含 A–Z, a–z, 0–9, _共63个字符 数据库名、表名、字段名等对象名中间不要包含空格 同一个MySQL软件中，数据库不能同名；同一个库中，表不能重名；同一个表中，字段不能重名 必须保证你的字段没有和保留字、数据库系统或常用方法冲突。如果坚持使用，请在SQL语句中使用`（着重号）引起来 保持字段名和类型的一致性：在命名字段并为其指定数据类型的时候一定要保证一致性，假如数据类型在一个表里是整数，那在另一个表里可就别变成字符型了 1.3 MySQL中的数据类型 类型 类型举例 整数类型 TINYINT、SMALLINT、MEDIUMINT、INT(或INTEGER)、BIGINT 浮点类型 FLOAT、DOUBLE 定点数类型 DECIMAL 位类型 BIT 日期时间类型 YEAR、TIME、DATE、DATETIME、TIMESTAMP 文本字符串类型 CHAR、VARCHAR、TINYTEXT、TEXT、MEDIUMTEXT、LONGTEXT 枚举类型 ENUM 集合类型 SET 二进制字符串类型 BINARY、VARBINARY、TINYBLOB、BLOB、MEDIUMBLOB、LONGBLOB JSON类型 JSON对象、JSON数组 空间数据类型 单值：GEOMETRY、POINT、LINESTRING、POLYGON；集合：MULTIPOINT、MULTILINESTRING、MULTIPOLYGON、GEOMETRYCOLLECTION 其中，常用的几类类型介绍如下： 数据类型 描述 INT 从-2^31到2^31-1的整型数据。存储大小为 4个字节 CHAR(size) 定长字符数据。若未指定，默认为1个字符，最大长度255 VARCHAR(size) 可变长字符数据，根据字符串实际长度保存，必须指定长度 FLOAT(M,D) 单精度，占用4个字节，M=整数位+小数位，D=小数位。 D&lt;=M&lt;=255,0&lt;=D&lt;=30，默认M+D&lt;=6 DOUBLE(M,D) 双精度，占用8个字节，D&lt;=M&lt;=255,0&lt;=D&lt;=30，默认M+D&lt;=15 DECIMAL(M,D) 高精度小数，占用M+2个字节，D&lt;=M&lt;=65，0&lt;=D&lt;=30，最大取值范围与DOUBLE相同。 DATE 日期型数据，格式’YYYY-MM-DD’ BLOB 二进制形式的长文本数据，最大可达4G TEXT 长文本数据，最大可达4G 2. 创建和管理数据库2.1 创建数据库 方式1：创建数据库 CREATE DATABASE 数据库名; 方式2：创建数据库并指定字符集 CREATE DATABASE 数据库名 CHARACTER SET 字符集; 方式3：判断数据库是否已经存在，不存在则创建数据库（推荐） CREATE DATABASE IF NOT EXISTS 数据库名; 如果MySQL中已经存在相关的数据库，则忽略创建语句，不再创建数据库。 注意：DATABASE 不能改名。一些可视化工具可以改名，它是建新库，把所有表复制到新库，再删旧库完成的。 2.2 使用数据库 查看当前所有的数据库 SHOW DATABASES; #有一个S，代表多个数据库 查看当前正在使用的数据库 SELECT DATABASE(); #使用的一个 mysql 中的全局函数 查看指定库下所有的表 SHOW TABLES FROM 数据库名; 查看数据库的创建信息 SHOW CREATE DATABASE 数据库名; 或者： SHOW CREATE DATABASE 数据库名\\G 使用/切换数据库 USE 数据库名; 注意：要操作表格和数据之前必须先说明是对哪个数据库进行操作，否则就要对所有对象加上“数据库名.”。 2.3 修改数据库 更改数据库字符集 ALTER DATABASE 数据库名 CHARACTER SET 字符集; #比如：gbk、utf8等 2.4 删除数据库 方式1：删除指定的数据库 DROP DATABASE 数据库名; 方式2：删除指定的数据库（推荐） DROP DATABASE IF EXISTS 数据库名; 3. 创建表3.1 创建方式1 必须具备： CREATE TABLE权限 存储空间 语法格式： CREATE TABLE [IF NOT EXISTS] 表名( 字段1, 数据类型 [约束条件] [默认值], 字段2, 数据类型 [约束条件] [默认值], 字段3, 数据类型 [约束条件] [默认值], …… [表约束条件] ); 加上了IF NOT EXISTS关键字，则表示：如果当前数据库中不存在要创建的数据表，则创建数据表；如果当前数据库中已经存在要创建的数据表，则忽略建表语句，不再创建数据表。 必须指定： 表名 列名(或字段名)，数据类型，长度 可选指定： 约束条件 默认值 创建表举例1： -- 创建表 CREATE TABLE emp ( -- int类型 emp_id INT, -- 最多保存20个中英文字符 emp_name VARCHAR(20), -- 总位数不超过15位 salary DOUBLE, -- 日期类型 birthday DATE ); DESC emp; MySQL在执行建表语句时，将id字段的类型设置为int(11)，这里的11实际上是int类型指定的显示宽度，默认的显示宽度为11。也可以在创建数据表的时候指定数据的显示宽度。 创建表举例2： CREATE TABLE dept( -- int类型，自增 deptno INT(2) AUTO_INCREMENT, dname VARCHAR(14), loc VARCHAR(13), -- 主键 PRIMARY KEY (deptno) ); DESCRIBE dept; 在MySQL 8.x版本中，不再推荐为INT类型指定显示长度，并在未来的版本中可能去掉这样的语法。 3.2 创建方式2 使用 AS subquery 选项，将创建表和插入数据结合起来 指定的列和子查询中的列要一一对应 通过列名和默认值定义列 CREATE TABLE emp1 AS SELECT * FROM employees; CREATE TABLE emp2 AS SELECT * FROM employees WHERE 1=2; -- 创建的emp2是空表 CREATE TABLE dept80 AS SELECT employee_id, last_name, salary*12 ANNSAL, hire_date FROM employees WHERE department_id = 80; DESCRIBE dept80; 3.3 查看数据表结构在MySQL中创建好数据表之后，可以查看数据表的结构。MySQL支持使用DESCRIBE/DESC语句查看数据表结构，也支持使用SHOW CREATE TABLE语句查看数据表结构。 语法格式如下： SHOW CREATE TABLE 表名\\G 使用SHOW CREATE TABLE语句不仅可以查看表创建时的详细语句，还可以查看存储引擎和字符编码。 4. 修改表修改表指的是修改数据库中已经存在的数据表的结构。 使用 ALTER TABLE 语句可以实现： 向已有的表中添加列 修改现有表中的列 删除现有表中的列 重命名现有表中的列 4.1 追加一个列语法格式如下： ALTER TABLE 表名 ADD 【COLUMN】 字段名 字段类型 【FIRST|AFTER 字段名】; 举例： ALTER TABLE dept80 ADD job_id varchar(15); 4.2 修改一个列 可以修改列的数据类型，长度、默认值和位置 修改字段数据类型、长度、默认值、位置的语法格式如下： ALTER TABLE 表名 MODIFY 【COLUMN】 字段名1 字段类型 【DEFAULT 默认值】【FIRST|AFTER 字段名2】; 举例： ALTER TABLE dept80 MODIFY last_name VARCHAR(30); ALTER TABLE dept80 MODIFY salary double(9,2) default 1000; 对默认值的修改只影响今后对表的修改 此外，还可以通过此种方式修改列的约束。这里暂先不讲。 4.3 重命名一个列使用 CHANGE old_column new_column dataType子句重命名列。语法格式如下： ALTER TABLE 表名 CHANGE 【column】 列名 新列名 新数据类型; 举例： ALTER TABLE dept80 CHANGE department_name dept_name varchar(15); 4.4 删除一个列删除表中某个字段的语法格式如下： ALTER TABLE 表名 DROP 【COLUMN】字段名 举例： ALTER TABLE dept80 DROP COLUMN job_id; 5. 重命名表 方式一：使用RENAME RENAME TABLE emp TO myemp; 方式二： ALTER table dept RENAME [TO] detail_dept; -- [TO]可以省略 必须是对象的拥有者 6. 删除表 在MySQL中，当一张数据表没有与其他任何数据表形成关联关系时，可以将当前数据表直接删除。 数据和结构都被删除 所有正在运行的相关事务被提交 所有相关索引被删除 语法格式： DROP TABLE [IF EXISTS] 数据表1 [, 数据表2, …, 数据表n]; IF EXISTS的含义为：如果当前数据库中存在相应的数据表，则删除数据表；如果当前数据库中不存在相应的数据表，则忽略删除语句，不再执行删除数据表的操作。 举例： DROP TABLE dept80; DROP TABLE 语句不能回滚 7. 清空表 TRUNCATE TABLE语句： 删除表中所有的数据 释放表的存储空间 举例： TRUNCATE TABLE detail_dept; TRUNCATE语句不能回滚，而使用 DELETE 语句删除数据，可以回滚 对比： SET autocommit = FALSE; DELETE FROM emp2; #TRUNCATE TABLE emp2; SELECT * FROM emp2; ROLLBACK; SELECT * FROM emp2; 阿里开发规范： 【参考】TRUNCATE TABLE 比 DELETE 速度快，且使用的系统和事务日志资源少，但 TRUNCATE 无事务且不触发 TRIGGER，有可能造成事故，故不建议在开发代码中使用此语句。 说明：TRUNCATE TABLE 在功能上与不带 WHERE 子句的 DELETE 语句相同。 8. 内容拓展拓展1：阿里巴巴《Java开发手册》之MySQL字段命名 【强制】表名、字段名必须使用小写字母或数字，禁止出现数字开头，禁止两个下划线中间只出现数字。数据库字段名的修改代价很大，因为无法进行预发布，所以字段名称需要慎重考虑。 正例：aliyun_admin，rdc_config，level3_name 反例：AliyunAdmin，rdcConfig，level_3_name 【强制】禁用保留字，如 desc、range、match、delayed 等，请参考 MySQL 官方保留字。 【强制】表必备三字段：id, gmt_create, gmt_modified。 说明：其中 id 必为主键，类型为BIGINT UNSIGNED、单表时自增、步长为 1。gmt_create, gmt_modified 的类型均为 DATETIME 类型，前者现在时表示主动式创建，后者过去分词表示被动式更新 【推荐】表的命名最好是遵循 “业务名称_表的作用”。 正例：alipay_task 、 force_project、 trade_config 【推荐】库名与应用名称尽量一致。 【参考】合适的字符存储长度，不但节约数据库表空间、节约索引存储，更重要的是提升检索速度。 正例：无符号值可以避免误存负数，且扩大了表示范围。 拓展2：如何理解清空表、删除表等操作需谨慎？！表删除操作将把表的定义和表中的数据一起删除，并且MySQL在执行删除操作时，不会有任何的确认信息提示，因此执行删除操时应当慎重。在删除表前，最好对表中的数据进行备份，这样当操作失误时可以对数据进行恢复，以免造成无法挽回的后果。 同样的，在使用 ALTER TABLE 进行表的基本修改操作时，在执行操作过程之前，也应该确保对数据进行完整的备份，因为数据库的改变是无法撤销的，如果添加了一个不需要的字段，可以将其删除；相同的，如果删除了一个需要的列，该列下面的所有数据都将会丢失。 拓展3：MySQL8新特性—DDL的原子化在MySQL 8.0版本中，InnoDB表的DDL支持事务完整性，即DDL操作要么成功要么回滚。DDL操作回滚日志写入到data dictionary数据字典表mysql.innodb_ddl_log（该表是隐藏的表，通过show tables无法看到）中，用于回滚操作。通过设置参数，可将DDL操作日志打印输出到MySQL错误日志中。 分别在MySQL 5.7版本和MySQL 8.0版本中创建数据库和数据表，结果如下： CREATE DATABASE mytest; USE mytest; CREATE TABLE book1( book_id INT , book_name VARCHAR(255) ); SHOW TABLES; （1）在MySQL 5.7版本中，测试步骤如下：删除数据表book1和数据表book2，结果如下： mysql&gt; DROP TABLE book1,book2; ERROR 1051 (42S02): Unknown table 'mytest.book2' 再次查询数据库中的数据表名称，结果如下： mysql&gt; SHOW TABLES; Empty set (0.00 sec) 从结果可以看出，虽然删除操作时报错了，但是仍然删除了数据表book1。 （2）在MySQL 8.0版本中，测试步骤如下：删除数据表book1和数据表book2，结果如下： mysql&gt; DROP TABLE book1,book2; ERROR 1051 (42S02): Unknown table 'mytest.book2' 再次查询数据库中的数据表名称，结果如下： mysql&gt; show tables; +------------------+ | Tables_in_mytest | +------------------+ | book1 | +------------------+ 1 row in set (0.00 sec) 从结果可以看出，数据表book1并没有被删除。","categories":[{"name":"Mysql基础篇","slug":"Mysql基础篇","permalink":"https://bowonqin.github.io/categories/Mysql%E5%9F%BA%E7%A1%80%E7%AF%87/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"https://bowonqin.github.io/tags/Mysql/"},{"name":"数据库","slug":"数据库","permalink":"https://bowonqin.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"author":"qxd"},{"title":"Mysql(子查询)","slug":"mysql/第09章-子查询","date":"2021-12-21T09:41:43.000Z","updated":"2021-12-21T11:32:51.216Z","comments":true,"path":"posts/mysql9.html","link":"","permalink":"https://bowonqin.github.io/posts/mysql9.html","excerpt":"","text":"第09章_子查询康师傅（宋红康老师）听课笔记 BILIBILI听课网址：[宋红康]MySQL数据库（安装/基础/高级/优化）_哔哩哔哩_bilibili 子查询指一个查询语句嵌套在另一个查询语句内部的查询，这个特性从MySQL 4.1开始引入。 SQL 中子查询的使用大大增强了 SELECT 查询的能力，因为很多时候查询需要从结果集中获取数据，或者需要从同一个表中先计算得出一个数据结果，然后与这个数据结果（可能是某个标量，也可能是某个集合）进行比较。 1. 需求分析与问题解决1.1 实际问题 现有解决方式： #方式一： SELECT salary FROM employees WHERE last_name = 'Abel'; SELECT last_name,salary FROM employees WHERE salary &gt; 11000; #方式二：自连接 SELECT e2.last_name,e2.salary FROM employees e1,employees e2 WHERE e1.last_name = 'Abel' AND e1.`salary` &lt; e2.`salary` #方式三：子查询 SELECT last_name,salary FROM employees WHERE salary &gt; ( SELECT salary FROM employees WHERE last_name = 'Abel' ); 1.2 子查询的基本使用 子查询的基本语法结构： 子查询（内查询）在主查询之前一次执行完成。 子查询的结果被主查询（外查询）使用 。 注意事项 子查询要包含在括号内 将子查询放在比较条件的右侧 单行操作符对应单行子查询，多行操作符对应多行子查询 1.3 子查询的分类分类方式1： 我们按内查询的结果返回一条还是多条记录，将子查询分为单行子查询、多行子查询。 单行子查询 多行子查询 分类方式2： 我们按内查询是否被执行多次，将子查询划分为相关(或关联)子查询和不相关(或非关联)子查询。 子查询从数据表中查询了数据结果，如果这个数据结果只执行一次，然后这个数据结果作为主查询的条件进行执行，那么这样的子查询叫做不相关子查询。 同样，如果子查询需要执行多次，即采用循环的方式，先从外部查询开始，每次都传入子查询进行查询，然后再将结果反馈给外部，这种嵌套的执行方式就称为相关子查询。 2. 单行子查询2.1 单行比较操作符 操作符 含义 = equal to &gt; greater than &gt;= greater than or equal to &lt; less than &lt;= less than or equal to &lt;&gt; not equal to 2.2 代码示例题目：查询工资大于149号员工工资的员工的信息 题目：返回job_id与141号员工相同，salary比143号员工多的员工姓名，job_id和工资 SELECT last_name, job_id, salary FROM employees WHERE job_id = (SELECT job_id FROM employees WHERE employee_id = 141) AND salary &gt; (SELECT salary FROM employees WHERE employee_id = 143); 题目：返回公司工资最少的员工的last_name,job_id和salary SELECT last_name, job_id, salary FROM employees WHERE salary = (SELECT MIN(salary) FROM employees); 题目：查询与141号或174号员工的manager_id和department_id相同的其他员工的employee_id，manager_id，department_id 实现方式1：不成对比较 SELECT employee_id, manager_id, department_id FROM employees WHERE manager_id IN (SELECT manager_id FROM employees WHERE employee_id IN (174,141)) AND department_id IN (SELECT department_id FROM employees WHERE employee_id IN (174,141)) AND employee_id NOT IN(174,141); 实现方式2：成对比较 SELECT employee_id, manager_id, department_id FROM employees WHERE (manager_id, department_id) IN (SELECT manager_id, department_id FROM employees WHERE employee_id IN (141,174)) AND employee_id NOT IN (141,174); 2.3 HAVING 中的子查询 首先执行子查询。 向主查询中的HAVING 子句返回结果。 题目：查询最低工资大于50号部门最低工资的部门id和其最低工资 SELECT department_id, MIN(salary) FROM employees GROUP BY department_id HAVING MIN(salary) &gt; (SELECT MIN(salary) FROM employees WHERE department_id = 50); 2.4 CASE中的子查询在CASE表达式中使用单列子查询： 题目：显式员工的employee_id,last_name和location。其中，若员工department_id与location_id为1800的department_id相同，则location为’Canada’，其余则为’USA’。 SELECT employee_id, last_name, (CASE department_id WHEN (SELECT department_id FROM departments WHERE location_id = 1800) THEN 'Canada' ELSE 'USA' END) location FROM employees; 2.5 子查询中的空值问题SELECT last_name, job_id FROM employees WHERE job_id = (SELECT job_id FROM employees WHERE last_name = 'Haas'); 子查询不返回任何行 2.5 非法使用子查询SELECT employee_id, last_name FROM employees WHERE salary = (SELECT MIN(salary) FROM employees GROUP BY department_id); 多行子查询使用单行比较符 3. 多行子查询 也称为集合比较子查询 内查询返回多行 使用多行比较操作符 3.1 多行比较操作符 操作符 含义 IN 等于列表中的任意一个 ANY 需要和单行比较操作符一起使用，和子查询返回的某一个值比较 ALL 需要和单行比较操作符一起使用，和子查询返回的所有值比较 SOME 实际上是ANY的别名，作用相同，一般常使用ANY 体会 ANY 和 ALL 的区别 3.2 代码示例题目：返回其它job_id中比job_id为‘IT_PROG’部门任一工资低的员工的员工号、姓名、job_id 以及salary 题目：返回其它job_id中比job_id为‘IT_PROG’部门所有工资都低的员工的员工号、姓名、job_id以及salary 题目：查询平均工资最低的部门id #方式1： SELECT department_id FROM employees GROUP BY department_id HAVING AVG(salary) = ( SELECT MIN(avg_sal) FROM ( SELECT AVG(salary) avg_sal FROM employees GROUP BY department_id ) dept_avg_sal ) #方式2： SELECT department_id FROM employees GROUP BY department_id HAVING AVG(salary) &lt;= ALL ( SELECT AVG(salary) avg_sal FROM employees GROUP BY department_id ) 3.3 空值问题SELECT last_name FROM employees WHERE employee_id NOT IN ( SELECT manager_id FROM employees ); 4. 相关子查询4.1 相关子查询执行流程如果子查询的执行依赖于外部查询，通常情况下都是因为子查询中的表用到了外部的表，并进行了条件关联，因此每执行一次外部查询，子查询都要重新计算一次，这样的子查询就称之为关联子查询。 相关子查询按照一行接一行的顺序执行，主查询的每一行都执行一次子查询。 说明：子查询中使用主查询中的列 4.2 代码示例题目：查询员工中工资大于本部门平均工资的员工的last_name,salary和其department_id 方式一：相关子查询 方式二：在 FROM 中使用子查询 SELECT last_name,salary,e1.department_id FROM employees e1,(SELECT department_id,AVG(salary) dept_avg_sal FROM employees GROUP BY department_id) e2 WHERE e1.`department_id` = e2.department_id AND e2.dept_avg_sal &lt; e1.`salary`; from型的子查询：子查询是作为from的一部分，子查询要用()引起来，并且要给这个子查询取别名，把它当成一张“临时的虚拟的表”来使用。 在ORDER BY 中使用子查询： 题目：查询员工的id,salary,按照department_name 排序 SELECT employee_id,salary FROM employees e ORDER BY ( SELECT department_name FROM departments d WHERE e.`department_id` = d.`department_id` ); 题目：若employees表中employee_id与job_history表中employee_id相同的数目不小于2，输出这些相同id的员工的employee_id,last_name和其job_id SELECT e.employee_id, last_name,e.job_id FROM employees e WHERE 2 &lt;= (SELECT COUNT(*) FROM job_history WHERE employee_id = e.employee_id); 4.3 EXISTS 与 NOT EXISTS关键字 关联子查询通常也会和 EXISTS操作符一起来使用，用来检查在子查询中是否存在满足条件的行。 如果在子查询中不存在满足条件的行： 条件返回 FALSE 继续在子查询中查找 如果在子查询中存在满足条件的行： 不在子查询中继续查找 条件返回 TRUE NOT EXISTS关键字表示如果不存在某种条件，则返回TRUE，否则返回FALSE。 题目：查询公司管理者的employee_id，last_name，job_id，department_id信息 方式一： SELECT employee_id, last_name, job_id, department_id FROM employees e1 WHERE EXISTS ( SELECT * FROM employees e2 WHERE e2.manager_id = e1.employee_id); 方式二：自连接 SELECT DISTINCT e1.employee_id, e1.last_name, e1.job_id, e1.department_id FROM employees e1 JOIN employees e2 WHERE e1.employee_id = e2.manager_id; 方式三： SELECT employee_id,last_name,job_id,department_id FROM employees WHERE employee_id IN ( SELECT DISTINCT manager_id FROM employees ); 题目：查询departments表中，不存在于employees表中的部门的department_id和department_name SELECT department_id, department_name FROM departments d WHERE NOT EXISTS (SELECT 'X' FROM employees WHERE department_id = d.department_id); 4.4 相关更新UPDATE table1 alias1 SET column = (SELECT expression FROM table2 alias2 WHERE alias1.column = alias2.column); 使用相关子查询依据一个表中的数据更新另一个表的数据。 题目：在employees中增加一个department_name字段，数据为员工对应的部门名称 # 1） ALTER TABLE employees ADD(department_name VARCHAR2(14)); # 2） UPDATE employees e SET department_name = (SELECT department_name FROM departments d WHERE e.department_id = d.department_id); 4.4 相关删除DELETE FROM table1 alias1 WHERE column operator (SELECT expression FROM table2 alias2 WHERE alias1.column = alias2.column); 使用相关子查询依据一个表中的数据删除另一个表的数据。 题目：删除表employees中，其与emp_history表皆有的数据 DELETE FROM employees e WHERE employee_id in (SELECT employee_id FROM emp_history WHERE employee_id = e.employee_id); 5. 抛一个思考题问题：谁的工资比Abel的高？ 解答： #方式1：自连接 SELECT e2.last_name,e2.salary FROM employees e1,employees e2 WHERE e1.last_name = 'Abel' AND e1.`salary` &lt; e2.`salary` #方式2：子查询 SELECT last_name,salary FROM employees WHERE salary &gt; ( SELECT salary FROM employees WHERE last_name = 'Abel' ); 问题：以上两种方式有好坏之分吗？ 解答：自连接方式好！ 题目中可以使用子查询，也可以使用自连接。一般情况建议你使用自连接，因为在许多 DBMS 的处理过程中，对于自连接的处理速度要比子查询快得多。 可以这样理解：子查询实际上是通过未知表进行查询后的条件判断，而自连接是通过已知的自身数据表进行条件判断，因此在大部分 DBMS 中都对自连接处理进行了优化。","categories":[{"name":"Mysql基础篇","slug":"Mysql基础篇","permalink":"https://bowonqin.github.io/categories/Mysql%E5%9F%BA%E7%A1%80%E7%AF%87/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"https://bowonqin.github.io/tags/Mysql/"},{"name":"数据库","slug":"数据库","permalink":"https://bowonqin.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"author":"qxd"},{"title":"Mysql(子查询)","slug":"第09章-子查询","date":"2021-12-21T09:41:43.000Z","updated":"2021-12-21T11:32:51.216Z","comments":true,"path":"posts/mysql9.html","link":"","permalink":"https://bowonqin.github.io/posts/mysql9.html","excerpt":"","text":"第09章_子查询康师傅（宋红康老师）听课笔记 BILIBILI听课网址：[宋红康]MySQL数据库（安装/基础/高级/优化）_哔哩哔哩_bilibili 子查询指一个查询语句嵌套在另一个查询语句内部的查询，这个特性从MySQL 4.1开始引入。 SQL 中子查询的使用大大增强了 SELECT 查询的能力，因为很多时候查询需要从结果集中获取数据，或者需要从同一个表中先计算得出一个数据结果，然后与这个数据结果（可能是某个标量，也可能是某个集合）进行比较。 1. 需求分析与问题解决1.1 实际问题 现有解决方式： #方式一： SELECT salary FROM employees WHERE last_name = 'Abel'; SELECT last_name,salary FROM employees WHERE salary &gt; 11000; #方式二：自连接 SELECT e2.last_name,e2.salary FROM employees e1,employees e2 WHERE e1.last_name = 'Abel' AND e1.`salary` &lt; e2.`salary` #方式三：子查询 SELECT last_name,salary FROM employees WHERE salary &gt; ( SELECT salary FROM employees WHERE last_name = 'Abel' ); 1.2 子查询的基本使用 子查询的基本语法结构： 子查询（内查询）在主查询之前一次执行完成。 子查询的结果被主查询（外查询）使用 。 注意事项 子查询要包含在括号内 将子查询放在比较条件的右侧 单行操作符对应单行子查询，多行操作符对应多行子查询 1.3 子查询的分类分类方式1： 我们按内查询的结果返回一条还是多条记录，将子查询分为单行子查询、多行子查询。 单行子查询 多行子查询 分类方式2： 我们按内查询是否被执行多次，将子查询划分为相关(或关联)子查询和不相关(或非关联)子查询。 子查询从数据表中查询了数据结果，如果这个数据结果只执行一次，然后这个数据结果作为主查询的条件进行执行，那么这样的子查询叫做不相关子查询。 同样，如果子查询需要执行多次，即采用循环的方式，先从外部查询开始，每次都传入子查询进行查询，然后再将结果反馈给外部，这种嵌套的执行方式就称为相关子查询。 2. 单行子查询2.1 单行比较操作符 操作符 含义 = equal to &gt; greater than &gt;= greater than or equal to &lt; less than &lt;= less than or equal to &lt;&gt; not equal to 2.2 代码示例题目：查询工资大于149号员工工资的员工的信息 题目：返回job_id与141号员工相同，salary比143号员工多的员工姓名，job_id和工资 SELECT last_name, job_id, salary FROM employees WHERE job_id = (SELECT job_id FROM employees WHERE employee_id = 141) AND salary &gt; (SELECT salary FROM employees WHERE employee_id = 143); 题目：返回公司工资最少的员工的last_name,job_id和salary SELECT last_name, job_id, salary FROM employees WHERE salary = (SELECT MIN(salary) FROM employees); 题目：查询与141号或174号员工的manager_id和department_id相同的其他员工的employee_id，manager_id，department_id 实现方式1：不成对比较 SELECT employee_id, manager_id, department_id FROM employees WHERE manager_id IN (SELECT manager_id FROM employees WHERE employee_id IN (174,141)) AND department_id IN (SELECT department_id FROM employees WHERE employee_id IN (174,141)) AND employee_id NOT IN(174,141); 实现方式2：成对比较 SELECT employee_id, manager_id, department_id FROM employees WHERE (manager_id, department_id) IN (SELECT manager_id, department_id FROM employees WHERE employee_id IN (141,174)) AND employee_id NOT IN (141,174); 2.3 HAVING 中的子查询 首先执行子查询。 向主查询中的HAVING 子句返回结果。 题目：查询最低工资大于50号部门最低工资的部门id和其最低工资 SELECT department_id, MIN(salary) FROM employees GROUP BY department_id HAVING MIN(salary) &gt; (SELECT MIN(salary) FROM employees WHERE department_id = 50); 2.4 CASE中的子查询在CASE表达式中使用单列子查询： 题目：显式员工的employee_id,last_name和location。其中，若员工department_id与location_id为1800的department_id相同，则location为’Canada’，其余则为’USA’。 SELECT employee_id, last_name, (CASE department_id WHEN (SELECT department_id FROM departments WHERE location_id = 1800) THEN 'Canada' ELSE 'USA' END) location FROM employees; 2.5 子查询中的空值问题SELECT last_name, job_id FROM employees WHERE job_id = (SELECT job_id FROM employees WHERE last_name = 'Haas'); 子查询不返回任何行 2.5 非法使用子查询SELECT employee_id, last_name FROM employees WHERE salary = (SELECT MIN(salary) FROM employees GROUP BY department_id); 多行子查询使用单行比较符 3. 多行子查询 也称为集合比较子查询 内查询返回多行 使用多行比较操作符 3.1 多行比较操作符 操作符 含义 IN 等于列表中的任意一个 ANY 需要和单行比较操作符一起使用，和子查询返回的某一个值比较 ALL 需要和单行比较操作符一起使用，和子查询返回的所有值比较 SOME 实际上是ANY的别名，作用相同，一般常使用ANY 体会 ANY 和 ALL 的区别 3.2 代码示例题目：返回其它job_id中比job_id为‘IT_PROG’部门任一工资低的员工的员工号、姓名、job_id 以及salary 题目：返回其它job_id中比job_id为‘IT_PROG’部门所有工资都低的员工的员工号、姓名、job_id以及salary 题目：查询平均工资最低的部门id #方式1： SELECT department_id FROM employees GROUP BY department_id HAVING AVG(salary) = ( SELECT MIN(avg_sal) FROM ( SELECT AVG(salary) avg_sal FROM employees GROUP BY department_id ) dept_avg_sal ) #方式2： SELECT department_id FROM employees GROUP BY department_id HAVING AVG(salary) &lt;= ALL ( SELECT AVG(salary) avg_sal FROM employees GROUP BY department_id ) 3.3 空值问题SELECT last_name FROM employees WHERE employee_id NOT IN ( SELECT manager_id FROM employees ); 4. 相关子查询4.1 相关子查询执行流程如果子查询的执行依赖于外部查询，通常情况下都是因为子查询中的表用到了外部的表，并进行了条件关联，因此每执行一次外部查询，子查询都要重新计算一次，这样的子查询就称之为关联子查询。 相关子查询按照一行接一行的顺序执行，主查询的每一行都执行一次子查询。 说明：子查询中使用主查询中的列 4.2 代码示例题目：查询员工中工资大于本部门平均工资的员工的last_name,salary和其department_id 方式一：相关子查询 方式二：在 FROM 中使用子查询 SELECT last_name,salary,e1.department_id FROM employees e1,(SELECT department_id,AVG(salary) dept_avg_sal FROM employees GROUP BY department_id) e2 WHERE e1.`department_id` = e2.department_id AND e2.dept_avg_sal &lt; e1.`salary`; from型的子查询：子查询是作为from的一部分，子查询要用()引起来，并且要给这个子查询取别名，把它当成一张“临时的虚拟的表”来使用。 在ORDER BY 中使用子查询： 题目：查询员工的id,salary,按照department_name 排序 SELECT employee_id,salary FROM employees e ORDER BY ( SELECT department_name FROM departments d WHERE e.`department_id` = d.`department_id` ); 题目：若employees表中employee_id与job_history表中employee_id相同的数目不小于2，输出这些相同id的员工的employee_id,last_name和其job_id SELECT e.employee_id, last_name,e.job_id FROM employees e WHERE 2 &lt;= (SELECT COUNT(*) FROM job_history WHERE employee_id = e.employee_id); 4.3 EXISTS 与 NOT EXISTS关键字 关联子查询通常也会和 EXISTS操作符一起来使用，用来检查在子查询中是否存在满足条件的行。 如果在子查询中不存在满足条件的行： 条件返回 FALSE 继续在子查询中查找 如果在子查询中存在满足条件的行： 不在子查询中继续查找 条件返回 TRUE NOT EXISTS关键字表示如果不存在某种条件，则返回TRUE，否则返回FALSE。 题目：查询公司管理者的employee_id，last_name，job_id，department_id信息 方式一： SELECT employee_id, last_name, job_id, department_id FROM employees e1 WHERE EXISTS ( SELECT * FROM employees e2 WHERE e2.manager_id = e1.employee_id); 方式二：自连接 SELECT DISTINCT e1.employee_id, e1.last_name, e1.job_id, e1.department_id FROM employees e1 JOIN employees e2 WHERE e1.employee_id = e2.manager_id; 方式三： SELECT employee_id,last_name,job_id,department_id FROM employees WHERE employee_id IN ( SELECT DISTINCT manager_id FROM employees ); 题目：查询departments表中，不存在于employees表中的部门的department_id和department_name SELECT department_id, department_name FROM departments d WHERE NOT EXISTS (SELECT 'X' FROM employees WHERE department_id = d.department_id); 4.4 相关更新UPDATE table1 alias1 SET column = (SELECT expression FROM table2 alias2 WHERE alias1.column = alias2.column); 使用相关子查询依据一个表中的数据更新另一个表的数据。 题目：在employees中增加一个department_name字段，数据为员工对应的部门名称 # 1） ALTER TABLE employees ADD(department_name VARCHAR2(14)); # 2） UPDATE employees e SET department_name = (SELECT department_name FROM departments d WHERE e.department_id = d.department_id); 4.4 相关删除DELETE FROM table1 alias1 WHERE column operator (SELECT expression FROM table2 alias2 WHERE alias1.column = alias2.column); 使用相关子查询依据一个表中的数据删除另一个表的数据。 题目：删除表employees中，其与emp_history表皆有的数据 DELETE FROM employees e WHERE employee_id in (SELECT employee_id FROM emp_history WHERE employee_id = e.employee_id); 5. 抛一个思考题问题：谁的工资比Abel的高？ 解答： #方式1：自连接 SELECT e2.last_name,e2.salary FROM employees e1,employees e2 WHERE e1.last_name = 'Abel' AND e1.`salary` &lt; e2.`salary` #方式2：子查询 SELECT last_name,salary FROM employees WHERE salary &gt; ( SELECT salary FROM employees WHERE last_name = 'Abel' ); 问题：以上两种方式有好坏之分吗？ 解答：自连接方式好！ 题目中可以使用子查询，也可以使用自连接。一般情况建议你使用自连接，因为在许多 DBMS 的处理过程中，对于自连接的处理速度要比子查询快得多。 可以这样理解：子查询实际上是通过未知表进行查询后的条件判断，而自连接是通过已知的自身数据表进行条件判断，因此在大部分 DBMS 中都对自连接处理进行了优化。","categories":[],"tags":[],"author":"qxd"},{"title":"Mysql(聚合函数)","slug":"mysql/第08章-聚合函数","date":"2021-12-21T08:15:03.000Z","updated":"2021-12-21T09:32:17.363Z","comments":true,"path":"posts/mysql8.html","link":"","permalink":"https://bowonqin.github.io/posts/mysql8.html","excerpt":"","text":"第08章_聚合函数康师傅（宋红康老师）听课笔记 BILIBILI听课网址：[宋红康]MySQL数据库（安装/基础/高级/优化）_哔哩哔哩_bilibili 我们上一章讲到了 SQL 单行函数。实际上 SQL 函数还有一类，叫做聚合（或聚集、分组）函数，它是对一组数据进行汇总的函数，输入的是一组数据的集合，输出的是单个值。 1. 聚合函数介绍 什么是聚合函数 聚合函数作用于一组数据，并对一组数据返回一个值。 聚合函数类型 AVG() SUM() MAX() MIN() COUNT() 聚合函数语法 聚合函数不能嵌套调用。比如不能出现类似“AVG(SUM(字段名称))”形式的调用。 1.1 AVG和SUM函数可以对数值型数据使用AVG 和 SUM 函数。 SELECT AVG(salary), MAX(salary),MIN(salary), SUM(salary) FROM employees WHERE job_id LIKE '%REP%'; 1.2 MIN和MAX函数可以对任意数据类型的数据使用 MIN 和 MAX 函数。 SELECT MIN(hire_date), MAX(hire_date) FROM employees; 1.3 COUNT函数 COUNT(*)返回表中记录总数，适用于任意数据类型。 SELECT COUNT(*) FROM employees WHERE department_id = 50; COUNT(expr) 返回expr不为空的记录总数。 SELECT COUNT(commission_pct) FROM employees WHERE department_id = 50; 问题：用count(*)，count(1)，count(列名)谁好呢? 其实，对于MyISAM引擎的表是没有区别的。这种引擎内部有一计数器在维护着行数。 Innodb引擎的表用count(*),count(1)直接读行数，复杂度是O(n)，因为innodb真的要去数一遍。但好于具体的count(列名)。 问题：能不能使用count(列名)替换count(*)? 不要使用 count(列名)来替代 count(*)，count(*)是 SQL92 定义的标准统计行数的语法，跟数据库无关，跟 NULL 和非 NULL 无关。 说明：count(*)会统计值为 NULL 的行，而 count(列名)不会统计此列为 NULL 值的行。 2. GROUP BY2.1 基本使用 可以使用GROUP BY子句将表中的数据分成若干组 SELECT column, group_function(column) FROM table [WHERE condition] [GROUP BY group_by_expression] [ORDER BY column]; 明确：WHERE一定放在FROM后面 在SELECT列表中所有未包含在组函数中的列都应该包含在 GROUP BY子句中 SELECT department_id, AVG(salary) FROM employees GROUP BY department_id ; 包含在 GROUP BY 子句中的列不必包含在SELECT 列表中 SELECT AVG(salary) FROM employees GROUP BY department_id ; 2.2 使用多个列分组 SELECT department_id dept_id, job_id, SUM(salary) FROM employees GROUP BY department_id, job_id ; 2.3 GROUP BY中使用WITH ROLLUP使用WITH ROLLUP关键字之后，在所有查询出的分组记录之后增加一条记录，该记录计算查询出的所有记录的总和，即统计记录数量。 SELECT department_id,AVG(salary) FROM employees WHERE department_id &gt; 80 GROUP BY department_id WITH ROLLUP; 注意： 当使用ROLLUP时，不能同时使用ORDER BY子句进行结果排序，即ROLLUP和ORDER BY是互相排斥的。 3. HAVING3.1 基本使用 过滤分组：HAVING子句 行已经被分组。 使用了聚合函数。 满足HAVING 子句中条件的分组将被显示。 HAVING 不能单独使用，必须要跟 GROUP BY 一起使用。 SELECT department_id, MAX(salary) FROM employees GROUP BY department_id HAVING MAX(salary)&gt;10000 ; 非法使用聚合函数 ： 不能在 WHERE 子句中使用聚合函数。如下： SELECT department_id, AVG(salary) FROM employees WHERE AVG(salary) &gt; 8000 GROUP BY department_id; 3.2 WHERE和HAVING的对比区别1：WHERE 可以直接使用表中的字段作为筛选条件，但不能使用分组中的计算函数作为筛选条件；HAVING 必须要与 GROUP BY 配合使用，可以把分组计算的函数和分组字段作为筛选条件。 这决定了，在需要对数据进行分组统计的时候，HAVING 可以完成 WHERE 不能完成的任务。这是因为，在查询语法结构中，WHERE 在 GROUP BY 之前，所以无法对分组结果进行筛选。HAVING 在 GROUP BY 之后，可以使用分组字段和分组中的计算函数，对分组的结果集进行筛选，这个功能是 WHERE 无法完成的。另外，WHERE排除的记录不再包括在分组中。 区别2：如果需要通过连接从关联表中获取需要的数据，WHERE 是先筛选后连接，而 HAVING 是先连接后筛选。 这一点，就决定了在关联查询中，WHERE 比 HAVING 更高效。因为 WHERE 可以先筛选，用一个筛选后的较小数据集和关联表进行连接，这样占用的资源比较少，执行效率也比较高。HAVING 则需要先把结果集准备好，也就是用未被筛选的数据集进行关联，然后对这个大的数据集进行筛选，这样占用的资源就比较多，执行效率也较低。 小结如下： 优点 缺点 WHERE 先筛选数据再关联，执行效率高 不能使用分组中的计算函数进行筛选 HAVING 可以使用分组中的计算函数 在最后的结果集中进行筛选，执行效率较低 开发中的选择： WHERE 和 HAVING 也不是互相排斥的，我们可以在一个查询里面同时使用 WHERE 和 HAVING。包含分组统计函数的条件用 HAVING，普通条件用 WHERE。这样，我们就既利用了 WHERE 条件的高效快速，又发挥了 HAVING 可以使用包含分组统计函数的查询条件的优点。当数据量特别大的时候，运行效率会有很大的差别。 4. SELECT的执行过程4.1 查询的结构#方式1： SELECT ...,....,... FROM ...,...,.... WHERE 多表的连接条件 AND 不包含组函数的过滤条件 GROUP BY ...,... HAVING 包含组函数的过滤条件 ORDER BY ... ASC/DESC LIMIT ...,... #方式2： SELECT ...,....,... FROM ... JOIN ... ON 多表的连接条件 JOIN ... ON ... WHERE 不包含组函数的过滤条件 AND/OR 不包含组函数的过滤条件 GROUP BY ...,... HAVING 包含组函数的过滤条件 ORDER BY ... ASC/DESC LIMIT ...,... #其中： #（1）from：从哪些表中筛选 #（2）on：关联多表查询时，去除笛卡尔积 #（3）where：从表中筛选的条件 #（4）group by：分组依据 #（5）having：在统计结果中再次筛选 #（6）order by：排序 #（7）limit：分页 4.2 SELECT执行顺序你需要记住 SELECT 查询时的两个顺序： 1. 关键字的顺序是不能颠倒的： SELECT ... FROM ... WHERE ... GROUP BY ... HAVING ... ORDER BY ... LIMIT... 2.SELECT 语句的执行顺序（在 MySQL 和 Oracle 中，SELECT 执行顺序基本相同）： FROM -&gt; WHERE -&gt; GROUP BY -&gt; HAVING -&gt; SELECT 的字段 -&gt; DISTINCT -&gt; ORDER BY -&gt; LIMIT 比如你写了一个 SQL 语句，那么它的关键字顺序和执行顺序是下面这样的： SELECT DISTINCT player_id, player_name, count(*) as num # 顺序 5 FROM player JOIN team ON player.team_id = team.team_id # 顺序 1 WHERE height &gt; 1.80 # 顺序 2 GROUP BY player.team_id # 顺序 3 HAVING num &gt; 2 # 顺序 4 ORDER BY num DESC # 顺序 6 LIMIT 2 # 顺序 7 在 SELECT 语句执行这些步骤的时候，每个步骤都会产生一个虚拟表，然后将这个虚拟表传入下一个步骤中作为输入。需要注意的是，这些步骤隐含在 SQL 的执行过程中，对于我们来说是不可见的。 4.3 SQL 的执行原理SELECT 是先执行 FROM 这一步的。在这个阶段，如果是多张表联查，还会经历下面的几个步骤： 首先先通过 CROSS JOIN 求笛卡尔积，相当于得到虚拟表 vt（virtual table）1-1； 通过 ON 进行筛选，在虚拟表 vt1-1 的基础上进行筛选，得到虚拟表 vt1-2； 添加外部行。如果我们使用的是左连接、右链接或者全连接，就会涉及到外部行，也就是在虚拟表 vt1-2 的基础上增加外部行，得到虚拟表 vt1-3。 当然如果我们操作的是两张以上的表，还会重复上面的步骤，直到所有表都被处理完为止。这个过程得到是我们的原始数据。 当我们拿到了查询数据表的原始数据，也就是最终的虚拟表 vt1，就可以在此基础上再进行 WHERE 阶段。在这个阶段中，会根据 vt1 表的结果进行筛选过滤，得到虚拟表 vt2。 然后进入第三步和第四步，也就是 GROUP 和 HAVING 阶段。在这个阶段中，实际上是在虚拟表 vt2 的基础上进行分组和分组过滤，得到中间的虚拟表 vt3 和 vt4。 当我们完成了条件筛选部分之后，就可以筛选表中提取的字段，也就是进入到 SELECT 和 DISTINCT 阶段。 首先在 SELECT 阶段会提取想要的字段，然后在 DISTINCT 阶段过滤掉重复的行，分别得到中间的虚拟表 vt5-1 和 vt5-2。 当我们提取了想要的字段数据之后，就可以按照指定的字段进行排序，也就是 ORDER BY 阶段，得到虚拟表 vt6。 最后在 vt6 的基础上，取出指定行的记录，也就是 LIMIT 阶段，得到最终的结果，对应的是虚拟表 vt7。 当然我们在写 SELECT 语句的时候，不一定存在所有的关键字，相应的阶段就会省略。 同时因为 SQL 是一门类似英语的结构化查询语言，所以我们在写 SELECT 语句的时候，还要注意相应的关键字顺序，所谓底层运行的原理，就是我们刚才讲到的执行顺序。","categories":[{"name":"Mysql基础篇","slug":"Mysql基础篇","permalink":"https://bowonqin.github.io/categories/Mysql%E5%9F%BA%E7%A1%80%E7%AF%87/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"https://bowonqin.github.io/tags/Mysql/"},{"name":"数据库","slug":"数据库","permalink":"https://bowonqin.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"author":"qxd"},{"title":"Mysql(单行函数)","slug":"mysql/第07章-单行函数","date":"2021-12-21T07:34:54.000Z","updated":"2021-12-21T09:45:10.573Z","comments":true,"path":"posts/mysql7.html","link":"","permalink":"https://bowonqin.github.io/posts/mysql7.html","excerpt":"","text":"第07章_单行函数康师傅（宋红康老师）听课笔记 BILIBILI听课网址：[宋红康]MySQL数据库（安装/基础/高级/优化）_哔哩哔哩_bilibili 1. 函数的理解1.1 什么是函数函数在计算机语言的使用中贯穿始终，函数的作用是什么呢？它可以把我们经常使用的代码封装起来，需要的时候直接调用即可。这样既提高了代码效率，又提高了可维护性。在 SQL 中我们也可以使用函数对检索出来的数据进行函数操作。使用这些函数，可以极大地提高用户对数据库的管理效率。 从函数定义的角度出发，我们可以将函数分成内置函数和自定义函数。在 SQL 语言中，同样也包括了内置函数和自定义函数。内置函数是系统内置的通用函数，而自定义函数是我们根据自己的需要编写的，本章及下一章讲解的是 SQL 的内置函数。 1.2 不同DBMS函数的差异我们在使用 SQL 语言的时候，不是直接和这门语言打交道，而是通过它使用不同的数据库软件，即 DBMS。DBMS 之间的差异性很大，远大于同一个语言不同版本之间的差异。实际上，只有很少的函数是被 DBMS 同时支持的。比如，大多数 DBMS 使用（||）或者（+）来做拼接符，而在 MySQL 中的字符串拼接函数为concat()。大部分 DBMS 会有自己特定的函数，这就意味着采用 SQL 函数的代码可移植性是很差的，因此在使用函数的时候需要特别注意。 1.3 MySQL的内置函数及分类MySQL提供了丰富的内置函数，这些函数使得数据的维护与管理更加方便，能够更好地提供数据的分析与统计功能，在一定程度上提高了开发人员进行数据分析与统计的效率。 MySQL提供的内置函数从实现的功能角度可以分为数值函数、字符串函数、日期和时间函数、流程控制函数、加密与解密函数、获取MySQL信息函数、聚合函数等。这里，我将这些丰富的内置函数再分为两类：单行函数、聚合函数（或分组函数）。 两种SQL函数 单行函数 操作数据对象 接受参数返回一个结果 只对一行进行变换 每行返回一个结果 可以嵌套 参数可以是一列或一个值 2. 数值函数2.1 基本函数 函数 用法 ABS(x) 返回x的绝对值 SIGN(X) 返回X的符号。正数返回1，负数返回-1，0返回0 PI() 返回圆周率的值 CEIL(x)，CEILING(x) 返回大于或等于某个值的最小整数 FLOOR(x) 返回小于或等于某个值的最大整数 LEAST(e1,e2,e3…) 返回列表中的最小值 GREATEST(e1,e2,e3…) 返回列表中的最大值 MOD(x,y) 返回X除以Y后的余数 RAND() 返回0~1的随机值 RAND(x) 返回0~1的随机值，其中x的值用作种子值，相同的X值会产生相同的随机数 ROUND(x) 返回一个对x的值进行四舍五入后，最接近于X的整数 ROUND(x,y) 返回一个对x的值进行四舍五入后最接近X的值，并保留到小数点后面Y位 TRUNCATE(x,y) 返回数字x截断为y位小数的结果 SQRT(x) 返回x的平方根。当X的值为负数时，返回NULL 举例： SELECT ABS(-123),ABS(32),SIGN(-23),SIGN(43),PI(),CEIL(32.32),CEILING(-43.23),FLOOR(32.32), FLOOR(-43.23),MOD(12,5) FROM DUAL; SELECT RAND(),RAND(),RAND(10),RAND(10),RAND(-1),RAND(-1) FROM DUAL; SELECT ROUND(12.33),ROUND(12.343,2),ROUND(12.324,-1),TRUNCATE(12.66,1),TRUNCATE(12.66,-1) FROM DUAL; 2.2 角度与弧度互换函数 函数 用法 RADIANS(x) 将角度转化为弧度，其中，参数x为角度值 DEGREES(x) 将弧度转化为角度，其中，参数x为弧度值 SELECT RADIANS(30),RADIANS(60),RADIANS(90),DEGREES(2*PI()),DEGREES(RADIANS(90)) FROM DUAL; 2.3 三角函数 函数 用法 SIN(x) 返回x的正弦值，其中，参数x为弧度值 ASIN(x) 返回x的反正弦值，即获取正弦为x的值。如果x的值不在-1到1之间，则返回NULL COS(x) 返回x的余弦值，其中，参数x为弧度值 ACOS(x) 返回x的反余弦值，即获取余弦为x的值。如果x的值不在-1到1之间，则返回NULL TAN(x) 返回x的正切值，其中，参数x为弧度值 ATAN(x) 返回x的反正切值，即返回正切值为x的值 ATAN2(m,n) 返回两个参数的反正切值 COT(x) 返回x的余切值，其中，X为弧度值 举例： ATAN2(M,N)函数返回两个参数的反正切值。与ATAN(X)函数相比，ATAN2(M,N)需要两个参数，例如有两个点point(x1,y1)和point(x2,y2)，使用ATAN(X)函数计算反正切值为ATAN((y2-y1)/(x2-x1))，使用ATAN2(M,N)计算反正切值则为ATAN2(y2-y1,x2-x1)。由使用方式可以看出，当x2-x1等于0时，ATAN(X)函数会报错，而ATAN2(M,N)函数则仍然可以计算。 ATAN2(M,N)函数的使用示例如下： SELECT SIN(RADIANS(30)),DEGREES(ASIN(1)),TAN(RADIANS(45)),DEGREES(ATAN(1)),DEGREES(ATAN2(1,1)) FROM DUAL; 2.4 指数与对数 函数 用法 POW(x,y)，POWER(X,Y) 返回x的y次方 EXP(X) 返回e的X次方，其中e是一个常数，2.718281828459045 LN(X)，LOG(X) 返回以e为底的X的对数，当X &lt;= 0 时，返回的结果为NULL LOG10(X) 返回以10为底的X的对数，当X &lt;= 0 时，返回的结果为NULL LOG2(X) 返回以2为底的X的对数，当X &lt;= 0 时，返回NULL mysql&gt; SELECT POW(2,5),POWER(2,4),EXP(2),LN(10),LOG10(10),LOG2(4) -&gt; FROM DUAL; +----------+------------+------------------+-------------------+-----------+---------+ | POW(2,5) | POWER(2,4) | EXP(2) | LN(10) | LOG10(10) | LOG2(4) | +----------+------------+------------------+-------------------+-----------+---------+ | 32 | 16 | 7.38905609893065 | 2.302585092994046 | 1 | 2 | +----------+------------+------------------+-------------------+-----------+---------+ 1 row in set (0.00 sec) 2.5 进制间的转换 函数 用法 BIN(x) 返回x的二进制编码 HEX(x) 返回x的十六进制编码 OCT(x) 返回x的八进制编码 CONV(x,f1,f2) 返回f1进制数变成f2进制数 mysql&gt; SELECT BIN(10),HEX(10),OCT(10),CONV(10,2,8) -&gt; FROM DUAL; +---------+---------+---------+--------------+ | BIN(10) | HEX(10) | OCT(10) | CONV(10,2,8) | +---------+---------+---------+--------------+ | 1010 | A | 12 | 2 | +---------+---------+---------+--------------+ 1 row in set (0.00 sec) 3. 字符串函数 函数 用法 ASCII(S) 返回字符串S中的第一个字符的ASCII码值 CHAR_LENGTH(s) 返回字符串s的字符数。作用与CHARACTER_LENGTH(s)相同 LENGTH(s) 返回字符串s的字节数，和字符集有关 CONCAT(s1,s2,……,sn) 连接s1,s2,……,sn为一个字符串 CONCAT_WS(x, s1,s2,……,sn) 同CONCAT(s1,s2,…)函数，但是每个字符串之间要加上x INSERT(str, idx, len, replacestr) 将字符串str从第idx位置开始，len个字符长的子串替换为字符串replacestr REPLACE(str, a, b) 用字符串b替换字符串str中所有出现的字符串a UPPER(s) 或 UCASE(s) 将字符串s的所有字母转成大写字母 LOWER(s) 或LCASE(s) 将字符串s的所有字母转成小写字母 LEFT(str,n) 返回字符串str最左边的n个字符 RIGHT(str,n) 返回字符串str最右边的n个字符 LPAD(str, len, pad) 用字符串pad对str最左边进行填充，直到str的长度为len个字符 RPAD(str ,len, pad) 用字符串pad对str最右边进行填充，直到str的长度为len个字符 LTRIM(s) 去掉字符串s左侧的空格 RTRIM(s) 去掉字符串s右侧的空格 TRIM(s) 去掉字符串s开始与结尾的空格 TRIM(s1 FROM s) 去掉字符串s开始与结尾的s1 TRIM(LEADING s1 FROM s) 去掉字符串s开始处的s1 TRIM(TRAILING s1 FROM s) 去掉字符串s结尾处的s1 REPEAT(str, n) 返回str重复n次的结果 SPACE(n) 返回n个空格 STRCMP(s1,s2) 比较字符串s1,s2的ASCII码值的大小 SUBSTR(s,index,len) 返回从字符串s的index位置其len个字符，作用与SUBSTRING(s,n,len)、MID(s,n,len)相同 LOCATE(substr,str) 返回字符串substr在字符串str中首次出现的位置，作用于POSITION(substr IN str)、INSTR(str,substr)相同。未找到，返回0 ELT(m,s1,s2,…,sn) 返回指定位置的字符串，如果m=1，则返回s1，如果m=2，则返回s2，如果m=n，则返回sn FIELD(s,s1,s2,…,sn) 返回字符串s在字符串列表中第一次出现的位置 FIND_IN_SET(s1,s2) 返回字符串s1在字符串s2中出现的位置。其中，字符串s2是一个以逗号分隔的字符串 REVERSE(s) 返回s反转后的字符串 NULLIF(value1,value2) 比较两个字符串，如果value1与value2相等，则返回NULL，否则返回value1 注意：MySQL中，字符串的位置是从1开始的。 举例： mysql&gt; SELECT FIELD('mm','hello','msm','amma'),FIND_IN_SET('mm','hello,mm,amma') -&gt; FROM DUAL; +----------------------------------+-----------------------------------+ | FIELD('mm','hello','msm','amma') | FIND_IN_SET('mm','hello,mm,amma') | +----------------------------------+-----------------------------------+ | 0 | 2 | +----------------------------------+-----------------------------------+ 1 row in set (0.00 sec) mysql&gt; SELECT NULLIF('mysql','mysql'),NULLIF('mysql', ''); +-------------------------+---------------------+ | NULLIF('mysql','mysql') | NULLIF('mysql', '') | +-------------------------+---------------------+ | NULL | mysql | +-------------------------+---------------------+ 1 row in set (0.00 sec) 4. 日期和时间函数4.1 获取日期、时间 函数 用法 CURDATE() ，CURRENT_DATE() 返回当前日期，只包含年、月、日 CURTIME() ， CURRENT_TIME() 返回当前时间，只包含时、分、秒 NOW() / SYSDATE() / CURRENT_TIMESTAMP() / LOCALTIME() / LOCALTIMESTAMP() 返回当前系统日期和时间 UTC_DATE() 返回UTC（世界标准时间）日期 UTC_TIME() 返回UTC（世界标准时间）时间 举例： SELECT CURDATE(),CURTIME(),NOW(),SYSDATE()+0,UTC_DATE(),UTC_DATE()+0,UTC_TIME(),UTC_TIME()+0 FROM DUAL; 4.2 日期与时间戳的转换 函数 用法 UNIX_TIMESTAMP() 以UNIX时间戳的形式返回当前时间。SELECT UNIX_TIMESTAMP() -&gt;1634348884 UNIX_TIMESTAMP(date) 将时间date以UNIX时间戳的形式返回。 FROM_UNIXTIME(timestamp) 将UNIX时间戳的时间转换为普通格式的时间 举例： mysql&gt; SELECT UNIX_TIMESTAMP(now()); +-----------------------+ | UNIX_TIMESTAMP(now()) | +-----------------------+ | 1576380910 | +-----------------------+ 1 row in set (0.01 sec) mysql&gt; SELECT UNIX_TIMESTAMP(CURDATE()); +---------------------------+ | UNIX_TIMESTAMP(CURDATE()) | +---------------------------+ | 1576339200 | +---------------------------+ 1 row in set (0.00 sec) mysql&gt; SELECT UNIX_TIMESTAMP(CURTIME()); +---------------------------+ | UNIX_TIMESTAMP(CURTIME()) | +---------------------------+ | 1576380969 | +---------------------------+ 1 row in set (0.00 sec) mysql&gt; SELECT UNIX_TIMESTAMP('2011-11-11 11:11:11') +---------------------------------------+ | UNIX_TIMESTAMP('2011-11-11 11:11:11') | +---------------------------------------+ | 1320981071 | +---------------------------------------+ 1 row in set (0.00 sec) mysql&gt; SELECT FROM_UNIXTIME(1576380910); +---------------------------+ | FROM_UNIXTIME(1576380910) | +---------------------------+ | 2019-12-15 11:35:10 | +---------------------------+ 1 row in set (0.00 sec) 4.3 获取月份、星期、星期数、天数等函数 函数 用法 YEAR(date) / MONTH(date) / DAY(date) 返回具体的日期值 HOUR(time) / MINUTE(time) / SECOND(time) 返回具体的时间值 MONTHNAME(date) 返回月份：January，… DAYNAME(date) 返回星期几：MONDAY，TUESDAY…..SUNDAY WEEKDAY(date) 返回周几，注意，周1是0，周2是1，。。。周日是6 QUARTER(date) 返回日期对应的季度，范围为1～4 WEEK(date) ， WEEKOFYEAR(date) 返回一年中的第几周 DAYOFYEAR(date) 返回日期是一年中的第几天 DAYOFMONTH(date) 返回日期位于所在月份的第几天 DAYOFWEEK(date) 返回周几，注意：周日是1，周一是2，。。。周六是7 举例： SELECT YEAR(CURDATE()),MONTH(CURDATE()),DAY(CURDATE()), HOUR(CURTIME()),MINUTE(NOW()),SECOND(SYSDATE()) FROM DUAL; SELECT MONTHNAME('2021-10-26'),DAYNAME('2021-10-26'),WEEKDAY('2021-10-26'), QUARTER(CURDATE()),WEEK(CURDATE()),DAYOFYEAR(NOW()), DAYOFMONTH(NOW()),DAYOFWEEK(NOW()) FROM DUAL; 4.4 日期的操作函数 函数 用法 EXTRACT(type FROM date) 返回指定日期中特定的部分，type指定返回的值 EXTRACT(type FROM date)函数中type的取值与含义： SELECT EXTRACT(MINUTE FROM NOW()),EXTRACT( WEEK FROM NOW()), EXTRACT( QUARTER FROM NOW()),EXTRACT( MINUTE_SECOND FROM NOW()) FROM DUAL; 4.5 时间和秒钟转换的函数 函数 用法 TIME_TO_SEC(time) 将 time 转化为秒并返回结果值。转化的公式为：小时*3600+分钟*60+秒 SEC_TO_TIME(seconds) 将 seconds 描述转化为包含小时、分钟和秒的时间 举例： mysql&gt; SELECT TIME_TO_SEC(NOW()); +--------------------+ | TIME_TO_SEC(NOW()) | +--------------------+ | 78774 | +--------------------+ 1 row in set (0.00 sec) mysql&gt; SELECT SEC_TO_TIME(78774); +--------------------+ | SEC_TO_TIME(78774) | +--------------------+ | 21:52:54 | +--------------------+ 1 row in set (0.12 sec) 4.6 计算日期和时间的函数第1组： 函数 用法 DATE_ADD(datetime, INTERVAL expr type)，ADDDATE(date,INTERVAL expr type) 返回与给定日期时间相差INTERVAL时间段的日期时间 DATE_SUB(date,INTERVAL expr type)，SUBDATE(date,INTERVAL expr type) 返回与date相差INTERVAL时间间隔的日期 上述函数中type的取值： 举例： SELECT DATE_ADD(NOW(), INTERVAL 1 DAY) AS col1,DATE_ADD('2021-10-21 23:32:12',INTERVAL 1 SECOND) AS col2, ADDDATE('2021-10-21 23:32:12',INTERVAL 1 SECOND) AS col3, DATE_ADD('2021-10-21 23:32:12',INTERVAL '1_1' MINUTE_SECOND) AS col4, DATE_ADD(NOW(), INTERVAL -1 YEAR) AS col5, #可以是负数 DATE_ADD(NOW(), INTERVAL '1_1' YEAR_MONTH) AS col6 #需要单引号 FROM DUAL; SELECT DATE_SUB('2021-01-21',INTERVAL 31 DAY) AS col1, SUBDATE('2021-01-21',INTERVAL 31 DAY) AS col2, DATE_SUB('2021-01-21 02:01:01',INTERVAL '1 1' DAY_HOUR) AS col3 FROM DUAL; 第2组： 函数 用法 ADDTIME(time1,time2) 返回time1加上time2的时间。当time2为一个数字时，代表的是秒，可以为负数 SUBTIME(time1,time2) 返回time1减去time2后的时间。当time2为一个数字时，代表的是秒，可以为负数 DATEDIFF(date1,date2) 返回date1 - date2的日期间隔天数 TIMEDIFF(time1, time2) 返回time1 - time2的时间间隔 FROM_DAYS(N) 返回从0000年1月1日起，N天以后的日期 TO_DAYS(date) 返回日期date距离0000年1月1日的天数 LAST_DAY(date) 返回date所在月份的最后一天的日期 MAKEDATE(year,n) 针对给定年份与所在年份中的天数返回一个日期 MAKETIME(hour,minute,second) 将给定的小时、分钟和秒组合成时间并返回 PERIOD_ADD(time,n) 返回time加上n后的时间 举例： SELECT ADDTIME(NOW(),20),SUBTIME(NOW(),30),SUBTIME(NOW(),'1:1:3'),DATEDIFF(NOW(),'2021-10-01'), TIMEDIFF(NOW(),'2021-10-25 22:10:10'),FROM_DAYS(366),TO_DAYS('0000-12-25'), LAST_DAY(NOW()),MAKEDATE(YEAR(NOW()),12),MAKETIME(10,21,23),PERIOD_ADD(20200101010101,10) FROM DUAL; mysql&gt; SELECT ADDTIME(NOW(), 50); +---------------------+ | ADDTIME(NOW(), 50) | +---------------------+ | 2019-12-15 22:17:47 | +---------------------+ 1 row in set (0.00 sec) mysql&gt; SELECT ADDTIME(NOW(), '1:1:1'); +-------------------------+ | ADDTIME(NOW(), '1:1:1') | +-------------------------+ | 2019-12-15 23:18:46 | +-------------------------+ 1 row in set (0.00 sec) mysql&gt; SELECT SUBTIME(NOW(), '1:1:1'); +-------------------------+ | SUBTIME(NOW(), '1:1:1') | +-------------------------+ | 2019-12-15 21:23:50 | +-------------------------+ 1 row in set (0.00 sec) mysql&gt; SELECT SUBTIME(NOW(), '-1:-1:-1'); +----------------------------+ | SUBTIME(NOW(), '-1:-1:-1') | +----------------------------+ | 2019-12-15 22:25:11 | +----------------------------+ 1 row in set, 1 warning (0.00 sec) mysql&gt; SELECT FROM_DAYS(366); +----------------+ | FROM_DAYS(366) | +----------------+ | 0001-01-01 | +----------------+ 1 row in set (0.00 sec) mysql&gt; SELECT MAKEDATE(2020,1); +------------------+ | MAKEDATE(2020,1) | +------------------+ | 2020-01-01 | +------------------+ 1 row in set (0.00 sec) mysql&gt; SELECT MAKEDATE(2020,32); +-------------------+ | MAKEDATE(2020,32) | +-------------------+ | 2020-02-01 | +-------------------+ 1 row in set (0.00 sec) mysql&gt; SELECT MAKETIME(1,1,1); +-----------------+ | MAKETIME(1,1,1) | +-----------------+ | 01:01:01 | +-----------------+ 1 row in set (0.00 sec) mysql&gt; SELECT PERIOD_ADD(20200101010101,1); +------------------------------+ | PERIOD_ADD(20200101010101,1) | +------------------------------+ | 20200101010102 | +------------------------------+ 1 row in set (0.00 sec) mysql&gt; SELECT TO_DAYS(NOW()); +----------------+ | TO_DAYS(NOW()) | +----------------+ | 737773 | +----------------+ 1 row in set (0.00 sec) 举例：查询 7 天内的新增用户数有多少？ SELECT COUNT(*) as num FROM new_user WHERE TO_DAYS(NOW())-TO_DAYS(regist_time)&lt;=7 4.7 日期的格式化与解析 函数 用法 DATE_FORMAT(date,fmt) 按照字符串fmt格式化日期date值 TIME_FORMAT(time,fmt) 按照字符串fmt格式化时间time值 GET_FORMAT(date_type,format_type) 返回日期字符串的显示格式 STR_TO_DATE(str, fmt) 按照字符串fmt对str进行解析，解析为一个日期 上述非GET_FORMAT函数中fmt参数常用的格式符： 格式符 说明 格式符 说明 %Y 4位数字表示年份 %y 表示两位数字表示年份 %M 月名表示月份（January,….） %m 两位数字表示月份（01,02,03。。。） %b 缩写的月名（Jan.，Feb.，….） %c 数字表示月份（1,2,3,…） %D 英文后缀表示月中的天数（1st,2nd,3rd,…） %d 两位数字表示月中的天数(01,02…) %e 数字形式表示月中的天数（1,2,3,4,5…..） %H 两位数字表示小数，24小时制（01,02..） %h和%I 两位数字表示小时，12小时制（01,02..） %k 数字形式的小时，24小时制(1,2,3) %l 数字形式表示小时，12小时制（1,2,3,4….） %i 两位数字表示分钟（00,01,02） %S和%s 两位数字表示秒(00,01,02…) %W 一周中的星期名称（Sunday…） %a 一周中的星期缩写（Sun.，Mon.,Tues.，..） %w 以数字表示周中的天数(0=Sunday,1=Monday….) %j 以3位数字表示年中的天数(001,002…) %U 以数字表示年中的第几周，（1,2,3。。）其中Sunday为周中第一天 %u 以数字表示年中的第几周，（1,2,3。。）其中Monday为周中第一天 %T 24小时制 %r 12小时制 %p AM或PM %% 表示% GET_FORMAT函数中date_type和format_type参数取值如下： 举例： mysql&gt; SELECT DATE_FORMAT(NOW(), '%H:%i:%s'); +--------------------------------+ | DATE_FORMAT(NOW(), '%H:%i:%s') | +--------------------------------+ | 22:57:34 | +--------------------------------+ 1 row in set (0.00 sec) SELECT STR_TO_DATE('09/01/2009','%m/%d/%Y') FROM DUAL; SELECT STR_TO_DATE('20140422154706','%Y%m%d%H%i%s') FROM DUAL; SELECT STR_TO_DATE('2014-04-22 15:47:06','%Y-%m-%d %H:%i:%s') FROM DUAL; mysql&gt; SELECT GET_FORMAT(DATE, 'USA'); +-------------------------+ | GET_FORMAT(DATE, 'USA') | +-------------------------+ | %m.%d.%Y | +-------------------------+ 1 row in set (0.00 sec) SELECT DATE_FORMAT(NOW(),GET_FORMAT(DATE,'USA')), FROM DUAL; mysql&gt; SELECT STR_TO_DATE('2020-01-01 00:00:00','%Y-%m-%d'); +-----------------------------------------------+ | STR_TO_DATE('2020-01-01 00:00:00','%Y-%m-%d') | +-----------------------------------------------+ | 2020-01-01 | +-----------------------------------------------+ 1 row in set, 1 warning (0.00 sec) 5. 流程控制函数流程处理函数可以根据不同的条件，执行不同的处理流程，可以在SQL语句中实现不同的条件选择。MySQL中的流程处理函数主要包括IF()、IFNULL()和CASE()函数。 函数 用法 IF(value,value1,value2) 如果value的值为TRUE，返回value1，否则返回value2 IFNULL(value1, value2) 如果value1不为NULL，返回value1，否则返回value2 CASE WHEN 条件1 THEN 结果1 WHEN 条件2 THEN 结果2 …. [ELSE resultn] END 相当于Java的if…else if…else… CASE expr WHEN 常量值1 THEN 值1 WHEN 常量值1 THEN 值1 …. [ELSE 值n] END 相当于Java的switch…case… SELECT IF(1 &gt; 0,'正确','错误') -&gt;正确 SELECT IFNULL(null,'Hello Word') -&gt;Hello Word SELECT CASE WHEN 1 &gt; 0 THEN '1 &gt; 0' WHEN 2 &gt; 0 THEN '2 &gt; 0' ELSE '3 &gt; 0' END -&gt;1 &gt; 0 SELECT CASE 1 WHEN 1 THEN '我是1' WHEN 2 THEN '我是2' ELSE '你是谁' SELECT employee_id,salary, CASE WHEN salary&gt;=15000 THEN '高薪' WHEN salary&gt;=10000 THEN '潜力股' WHEN salary&gt;=8000 THEN '屌丝' ELSE '草根' END \"描述\" FROM employees; SELECT oid,`status`, CASE `status` WHEN 1 THEN '未付款' WHEN 2 THEN '已付款' WHEN 3 THEN '已发货' WHEN 4 THEN '确认收货' ELSE '无效订单' END FROM t_order; mysql&gt; SELECT CASE WHEN 1 &gt; 0 THEN 'yes' WHEN 1 &lt;= 0 THEN 'no' ELSE 'unknown' END; +---------------------------------------------------------------------+ | CASE WHEN 1 &gt; 0 THEN 'yes' WHEN 1 &lt;= 0 THEN 'no' ELSE 'unknown' END | +---------------------------------------------------------------------+ | yes | +---------------------------------------------------------------------+ 1 row in set (0.00 sec) mysql&gt; SELECT CASE WHEN 1 &lt; 0 THEN 'yes' WHEN 1 = 0 THEN 'no' ELSE 'unknown' END; +--------------------------------------------------------------------+ | CASE WHEN 1 &lt; 0 THEN 'yes' WHEN 1 = 0 THEN 'no' ELSE 'unknown' END | +--------------------------------------------------------------------+ | unknown | +--------------------------------------------------------------------+ 1 row in set (0.00 sec) mysql&gt; SELECT CASE 1 WHEN 0 THEN 0 WHEN 1 THEN 1 ELSE -1 END; +------------------------------------------------+ | CASE 1 WHEN 0 THEN 0 WHEN 1 THEN 1 ELSE -1 END | +------------------------------------------------+ | 1 | +------------------------------------------------+ 1 row in set (0.00 sec) mysql&gt; SELECT CASE -1 WHEN 0 THEN 0 WHEN 1 THEN 1 ELSE -1 END; +-------------------------------------------------+ | CASE -1 WHEN 0 THEN 0 WHEN 1 THEN 1 ELSE -1 END | +-------------------------------------------------+ | -1 | +-------------------------------------------------+ 1 row in set (0.00 sec) SELECT employee_id,12 * salary * (1 + IFNULL(commission_pct,0)) FROM employees; SELECT last_name, job_id, salary, CASE job_id WHEN 'IT_PROG' THEN 1.10*salary WHEN 'ST_CLERK' THEN 1.15*salary WHEN 'SA_REP' THEN 1.20*salary ELSE salary END \"REVISED_SALARY\" FROM employees; 练习：查询部门号为 10,20, 30 的员工信息, 若部门号为 10, 则打印其工资的 1.1 倍, 20 号部门, 则打印其工资的 1.2 倍, 30 号部门打印其工资的 1.3 倍数。 6. 加密与解密函数加密与解密函数主要用于对数据库中的数据进行加密和解密处理，以防止数据被他人窃取。这些函数在保证数据库安全时非常有用。 函数 用法 PASSWORD(str) 返回字符串str的加密版本，41位长的字符串。加密结果不可逆，常用于用户的密码加密 MD5(str) 返回字符串str的md5加密后的值，也是一种加密方式。若参数为NULL，则会返回NULL SHA(str) 从原明文密码str计算并返回加密后的密码字符串，当参数为NULL时，返回NULL。SHA加密算法比MD5更加安全。 ENCODE(value,password_seed) 返回使用password_seed作为加密密码加密value DECODE(value,password_seed) 返回使用password_seed作为加密密码解密value 可以看到，ENCODE(value,password_seed)函数与DECODE(value,password_seed)函数互为反函数。 举例： mysql&gt; SELECT PASSWORD('mysql'), PASSWORD(NULL); +-------------------------------------------+----------------+ | PASSWORD('mysql') | PASSWORD(NULL) | +-------------------------------------------+----------------+ | *E74858DB86EBA20BC33D0AECAE8A8108C56B17FA | | +-------------------------------------------+----------------+ 1 row in set, 1 warning (0.00 sec) SELECT md5('123') -&gt;202cb962ac59075b964b07152d234b70 SELECT SHA('Tom123') -&gt;c7c506980abc31cc390a2438c90861d0f1216d50 mysql&gt; SELECT ENCODE('mysql', 'mysql'); +--------------------------+ | ENCODE('mysql', 'mysql') | +--------------------------+ | íg ¼ ìÉ | +--------------------------+ 1 row in set, 1 warning (0.01 sec) mysql&gt; SELECT DECODE(ENCODE('mysql','mysql'),'mysql'); +-----------------------------------------+ | DECODE(ENCODE('mysql','mysql'),'mysql') | +-----------------------------------------+ | mysql | +-----------------------------------------+ 1 row in set, 2 warnings (0.00 sec) 7. MySQL信息函数MySQL中内置了一些可以查询MySQL信息的函数，这些函数主要用于帮助数据库开发或运维人员更好地对数据库进行维护工作。 函数 用法 VERSION() 返回当前MySQL的版本号 CONNECTION_ID() 返回当前MySQL服务器的连接数 DATABASE()，SCHEMA() 返回MySQL命令行当前所在的数据库 USER()，CURRENT_USER()、SYSTEM_USER()，SESSION_USER() 返回当前连接MySQL的用户名，返回结果格式为“主机名@用户名” CHARSET(value) 返回字符串value自变量的字符集 COLLATION(value) 返回字符串value的比较规则 举例： mysql&gt; SELECT DATABASE(); +------------+ | DATABASE() | +------------+ | test | +------------+ 1 row in set (0.00 sec) mysql&gt; SELECT DATABASE(); +------------+ | DATABASE() | +------------+ | test | +------------+ 1 row in set (0.00 sec) mysql&gt; SELECT USER(), CURRENT_USER(), SYSTEM_USER(),SESSION_USER(); +----------------+----------------+----------------+----------------+ | USER() | CURRENT_USER() | SYSTEM_USER() | SESSION_USER() | +----------------+----------------+----------------+----------------+ | root@localhost | root@localhost | root@localhost | root@localhost | +----------------+----------------+----------------+----------------+ mysql&gt; SELECT CHARSET('ABC'); +----------------+ | CHARSET('ABC') | +----------------+ | utf8mb4 | +----------------+ 1 row in set (0.00 sec) mysql&gt; SELECT COLLATION('ABC'); +--------------------+ | COLLATION('ABC') | +--------------------+ | utf8mb4_general_ci | +--------------------+ 1 row in set (0.00 sec) 8. 其他函数MySQL中有些函数无法对其进行具体的分类，但是这些函数在MySQL的开发和运维过程中也是不容忽视的。 函数 用法 FORMAT(value,n) 返回对数字value进行格式化后的结果数据。n表示四舍五入后保留到小数点后n位 CONV(value,from,to) 将value的值进行不同进制之间的转换 INET_ATON(ipvalue) 将以点分隔的IP地址转化为一个数字 INET_NTOA(value) 将数字形式的IP地址转化为以点分隔的IP地址 BENCHMARK(n,expr) 将表达式expr重复执行n次。用于测试MySQL处理expr表达式所耗费的时间 CONVERT(value USING char_code) 将value所使用的字符编码修改为char_code 举例： # 如果n的值小于或者等于0，则只保留整数部分 mysql&gt; SELECT FORMAT(123.123, 2), FORMAT(123.523, 0), FORMAT(123.123, -2); +--------------------+--------------------+---------------------+ | FORMAT(123.123, 2) | FORMAT(123.523, 0) | FORMAT(123.123, -2) | +--------------------+--------------------+---------------------+ | 123.12 | 124 | 123 | +--------------------+--------------------+---------------------+ 1 row in set (0.00 sec) mysql&gt; SELECT CONV(16, 10, 2), CONV(8888,10,16), CONV(NULL, 10, 2); +-----------------+------------------+-------------------+ | CONV(16, 10, 2) | CONV(8888,10,16) | CONV(NULL, 10, 2) | +-----------------+------------------+-------------------+ | 10000 | 22B8 | NULL | +-----------------+------------------+-------------------+ 1 row in set (0.00 sec) mysql&gt; SELECT INET_ATON('192.168.1.100'); +----------------------------+ | INET_ATON('192.168.1.100') | +----------------------------+ | 3232235876 | +----------------------------+ 1 row in set (0.00 sec) # 以“192.168.1.100”为例，计算方式为192乘以256的3次方，加上168乘以256的2次方，加上1乘以256，再加上100。 mysql&gt; SELECT INET_NTOA(3232235876); +-----------------------+ | INET_NTOA(3232235876) | +-----------------------+ | 192.168.1.100 | +-----------------------+ 1 row in set (0.00 sec) mysql&gt; SELECT BENCHMARK(1, MD5('mysql')); +----------------------------+ | BENCHMARK(1, MD5('mysql')) | +----------------------------+ | 0 | +----------------------------+ 1 row in set (0.00 sec) mysql&gt; SELECT BENCHMARK(1000000, MD5('mysql')); +----------------------------------+ | BENCHMARK(1000000, MD5('mysql')) | +----------------------------------+ | 0 | +----------------------------------+ 1 row in set (0.20 sec) mysql&gt; SELECT CHARSET('mysql'), CHARSET(CONVERT('mysql' USING 'utf8')); +------------------+----------------------------------------+ | CHARSET('mysql') | CHARSET(CONVERT('mysql' USING 'utf8')) | +------------------+----------------------------------------+ | utf8mb4 | utf8 | +------------------+----------------------------------------+ 1 row in set, 1 warning (0.00 sec)","categories":[{"name":"Mysql基础篇","slug":"Mysql基础篇","permalink":"https://bowonqin.github.io/categories/Mysql%E5%9F%BA%E7%A1%80%E7%AF%87/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"https://bowonqin.github.io/tags/Mysql/"},{"name":"数据库","slug":"数据库","permalink":"https://bowonqin.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"author":"qxd"},{"title":"Mysql(多表查询)","slug":"mysql/第06章-多表查询","date":"2021-12-21T04:38:51.000Z","updated":"2021-12-21T03:47:31.402Z","comments":true,"path":"posts/mysql6.html","link":"","permalink":"https://bowonqin.github.io/posts/mysql6.html","excerpt":"","text":"第06章_多表查询康师傅（宋红康老师）听课笔记 BILIBILI听课网址：[宋红康]MySQL数据库（安装/基础/高级/优化）_哔哩哔哩_bilibili 多表查询，也称为关联查询，指两个或更多个表一起完成查询操作。 前提条件：这些一起查询的表之间是有关系的（一对一、一对多），它们之间一定是有关联字段，这个关联字段可能建立了外键，也可能没有建立外键。比如：员工表和部门表，这两个表依靠“部门编号”进行关联。 1. 一个案例引发的多表连接1.1 案例说明 从多个表中获取数据： #案例：查询员工的姓名及其部门名称 SELECT last_name, department_name FROM employees, departments; 查询结果： +-----------+----------------------+ | last_name | department_name | +-----------+----------------------+ | King | Administration | | King | Marketing | | King | Purchasing | | King | Human Resources | | King | Shipping | | King | IT | | King | Public Relations | | King | Sales | | King | Executive | | King | Finance | | King | Accounting | | King | Treasury | ... | Gietz | IT Support | | Gietz | NOC | | Gietz | IT Helpdesk | | Gietz | Government Sales | | Gietz | Retail Sales | | Gietz | Recruiting | | Gietz | Payroll | +-----------+----------------------+ 2889 rows in set (0.01 sec) 分析错误情况： SELECT COUNT(employee_id) FROM employees; #输出107行 SELECT COUNT(department_id)FROM departments; #输出27行 SELECT 107*27 FROM dual; 我们把上述多表查询中出现的问题称为：笛卡尔积的错误。 1.2 笛卡尔积（或交叉连接）的理解笛卡尔乘积是一个数学运算。假设我有两个集合 X 和 Y，那么 X 和 Y 的笛卡尔积就是 X 和 Y 的所有可能组合，也就是第一个对象来自于 X，第二个对象来自于 Y 的所有可能。组合的个数即为两个集合中元素个数的乘积数。 SQL92中，笛卡尔积也称为交叉连接，英文是 CROSS JOIN。在 SQL99 中也是使用 CROSS JOIN表示交叉连接。它的作用就是可以把任意表进行连接，即使这两张表不相关。在MySQL中如下情况会出现笛卡尔积： #查询员工姓名和所在部门名称 SELECT last_name,department_name FROM employees,departments; SELECT last_name,department_name FROM employees CROSS JOIN departments; SELECT last_name,department_name FROM employees INNER JOIN departments; SELECT last_name,department_name FROM employees JOIN departments; 1.3 案例分析与问题解决 笛卡尔积的错误会在下面条件下产生： 省略多个表的连接条件（或关联条件） 连接条件（或关联条件）无效 所有表中的所有行互相连接 为了避免笛卡尔积， 可以在 WHERE 加入有效的连接条件。 加入连接条件后，查询语法： SELECT table1.column, table2.column FROM table1, table2 WHERE table1.column1 = table2.column2; #连接条件 在 WHERE子句中写入连接条件。 正确写法： #案例：查询员工的姓名及其部门名称 SELECT last_name, department_name FROM employees, departments WHERE employees.department_id = departments.department_id; 在表中有相同列时，在列名之前加上表名前缀。 2. 多表查询分类讲解分类1：等值连接 vs 非等值连接等值连接 SELECT employees.employee_id, employees.last_name, employees.department_id, departments.department_id, departments.location_id FROM employees, departments WHERE employees.department_id = departments.department_id; 拓展1：多个连接条件与 AND 操作符 拓展2：区分重复的列名 多个表中有相同列时，必须在列名之前加上表名前缀。 在不同表中具有相同列名的列可以用表名加以区分。 SELECT employees.last_name, departments.department_name,employees.department_id FROM employees, departments WHERE employees.department_id = departments.department_id; 拓展3：表的别名 使用别名可以简化查询。 列名前使用表名前缀可以提高查询效率。 SELECT e.employee_id, e.last_name, e.department_id, d.department_id, d.location_id FROM employees e , departments d WHERE e.department_id = d.department_id; 需要注意的是，如果我们使用了表的别名，在查询字段中、过滤条件中就只能使用别名进行代替，不能使用原有的表名，否则就会报错。 阿里开发规范： 【强制】对于数据库中表记录的查询和变更，只要涉及多个表，都需要在列名前加表的别名（或 表名）进行限定。 说明：对多表进行查询记录、更新记录、删除记录时，如果对操作列没有限定表的别名（或表名），并且操作列在多个表中存在时，就会抛异常。 正例：select t1.name from table_first as t1 , table_second as t2 where t1.id=t2.id; 反例：在某业务中，由于多表关联查询语句没有加表的别名（或表名）的限制，正常运行两年后，最近在 某个表中增加一个同名字段，在预发布环境做数据库变更后，线上查询语句出现出 1052 异常：Column ‘name’ in field list is ambiguous。 拓展4：连接多个表 总结：连接 n个表,至少需要n-1个连接条件。比如，连接三个表，至少需要两个连接条件。 练习：查询出公司员工的 last_name,department_name, city 非等值连接 SELECT e.last_name, e.salary, j.grade_level FROM employees e, job_grades j WHERE e.salary BETWEEN j.lowest_sal AND j.highest_sal; 分类2：自连接 vs 非自连接 当table1和table2本质上是同一张表，只是用取别名的方式虚拟成两张表以代表不同的意义。然后两个表再进行内连接，外连接等查询。 题目：查询employees表，返回“Xxx works for Xxx” SELECT CONCAT(worker.last_name ,' works for ' , manager.last_name) FROM employees worker, employees manager WHERE worker.manager_id = manager.employee_id ; 练习：查询出last_name为 ‘Chen’ 的员工的 manager 的信息。 分类3：内连接 vs 外连接除了查询满足条件的记录以外，外连接还可以查询某一方不满足条件的记录。 内连接: 合并具有同一列的两个以上的表的行, 结果集中不包含一个表与另一个表不匹配的行 外连接: 两个表在连接过程中除了返回满足连接条件的行以外还返回左（或右）表中不满足条件的行 ，这种连接称为左（或右） 外连接。没有匹配的行时, 结果表中相应的列为空(NULL)。 如果是左外连接，则连接条件中左边的表也称为主表，右边的表称为从表。 如果是右外连接，则连接条件中右边的表也称为主表，左边的表称为从表。 SQL92：使用(+)创建连接 在 SQL92 中采用（+）代表从表所在的位置。即左或右外连接中，(+) 表示哪个是从表。 Oracle 对 SQL92 支持较好，而 MySQL 则不支持 SQL92 的外连接。 #左外连接 SELECT last_name,department_name FROM employees ,departments WHERE employees.department_id = departments.department_id(+); #右外连接 SELECT last_name,department_name FROM employees ,departments WHERE employees.department_id(+) = departments.department_id; 而且在 SQL92 中，只有左外连接和右外连接，没有满（或全）外连接。 3. SQL99语法实现多表查询3.1 基本语法 使用JOIN…ON子句创建连接的语法结构： SELECT table1.column, table2.column,table3.column FROM table1 JOIN table2 ON table1 和 table2 的连接条件 JOIN table3 ON table2 和 table3 的连接条件 它的嵌套逻辑类似我们使用的 FOR 循环： for t1 in table1: for t2 in table2: if condition1: for t3 in table3: if condition2: output t1 + t2 + t3 SQL99 采用的这种嵌套结构非常清爽、层次性更强、可读性更强，即使再多的表进行连接也都清晰可见。如果你采用 SQL92，可读性就会大打折扣。 语法说明： 可以使用 ON 子句指定额外的连接条件。 这个连接条件是与其它条件分开的。 ON 子句使语句具有更高的易读性。 关键字 JOIN、INNER JOIN、CROSS JOIN 的含义是一样的，都表示内连接 3.2 内连接(INNER JOIN)的实现 语法： SELECT 字段列表 FROM A表 INNER JOIN B表 ON 关联条件 WHERE 等其他子句; 题目1： SELECT e.employee_id, e.last_name, e.department_id, d.department_id, d.location_id FROM employees e JOIN departments d ON (e.department_id = d.department_id); 题目2： SELECT employee_id, city, department_name FROM employees e JOIN departments d ON d.department_id = e.department_id JOIN locations l ON d.location_id = l.location_id; 3.3 外连接(OUTER JOIN)的实现3.3.1 左外连接(LEFT OUTER JOIN) 语法： #实现查询结果是A SELECT 字段列表 FROM A表 LEFT JOIN B表 ON 关联条件 WHERE 等其他子句; 举例： SELECT e.last_name, e.department_id, d.department_name FROM employees e LEFT OUTER JOIN departments d ON (e.department_id = d.department_id) ; 3.3.2 右外连接(RIGHT OUTER JOIN) 语法： #实现查询结果是B SELECT 字段列表 FROM A表 RIGHT JOIN B表 ON 关联条件 WHERE 等其他子句; 举例： SELECT e.last_name, e.department_id, d.department_name FROM employees e RIGHT OUTER JOIN departments d ON (e.department_id = d.department_id) ; 需要注意的是，LEFT JOIN 和 RIGHT JOIN 只存在于 SQL99 及以后的标准中，在 SQL92 中不存在，只能用 (+) 表示。 3.3.3 满外连接(FULL OUTER JOIN) 满外连接的结果 = 左右表匹配的数据 + 左表没有匹配到的数据 + 右表没有匹配到的数据。 SQL99是支持满外连接的。使用FULL JOIN 或 FULL OUTER JOIN来实现。 需要注意的是，MySQL不支持FULL JOIN，但是可以用 LEFT JOIN UNION RIGHT join代替。 4. UNION的使用合并查询结果利用UNION关键字，可以给出多条SELECT语句，并将它们的结果组合成单个结果集。合并时，两个表对应的列数和数据类型必须相同，并且相互对应。各个SELECT语句之间使用UNION或UNION ALL关键字分隔。 语法格式： SELECT column,... FROM table1 UNION [ALL] SELECT column,... FROM table2 UNION操作符 UNION 操作符返回两个查询的结果集的并集，去除重复记录。 UNION ALL操作符 UNION ALL操作符返回两个查询的结果集的并集。对于两个结果集的重复部分，不去重。 注意：执行UNION ALL语句时所需要的资源比UNION语句少。如果明确知道合并数据后的结果数据不存在重复数据，或者不需要去除重复的数据，则尽量使用UNION ALL语句，以提高数据查询的效率。 举例：查询部门编号&gt;90或邮箱包含a的员工信息 #方式1 SELECT * FROM employees WHERE email LIKE '%a%' OR department_id&gt;90; #方式2 SELECT * FROM employees WHERE email LIKE '%a%' UNION SELECT * FROM employees WHERE department_id&gt;90; 举例：查询中国用户中男性的信息以及美国用户中年男性的用户信息 SELECT id,cname FROM t_chinamale WHERE csex='男' UNION ALL SELECT id,tname FROM t_usmale WHERE tGender='male'; 5. 7种SQL JOINS的实现 5.7.1 代码实现#中图：内连接 A∩B SELECT employee_id,last_name,department_name FROM employees e JOIN departments d ON e.`department_id` = d.`department_id`; #左上图：左外连接 SELECT employee_id,last_name,department_name FROM employees e LEFT JOIN departments d ON e.`department_id` = d.`department_id`; #右上图：右外连接 SELECT employee_id,last_name,department_name FROM employees e RIGHT JOIN departments d ON e.`department_id` = d.`department_id`; #左中图：A - A∩B SELECT employee_id,last_name,department_name FROM employees e LEFT JOIN departments d ON e.`department_id` = d.`department_id` WHERE d.`department_id` IS NULL #右中图：B-A∩B SELECT employee_id,last_name,department_name FROM employees e RIGHT JOIN departments d ON e.`department_id` = d.`department_id` WHERE e.`department_id` IS NULL #左下图：满外连接 # 左中图 + 右上图 A∪B SELECT employee_id,last_name,department_name FROM employees e LEFT JOIN departments d ON e.`department_id` = d.`department_id` WHERE d.`department_id` IS NULL UNION ALL #没有去重操作，效率高 SELECT employee_id,last_name,department_name FROM employees e RIGHT JOIN departments d ON e.`department_id` = d.`department_id`; #右下图 #左中图 + 右中图 A ∪B- A∩B 或者 (A - A∩B) ∪ （B - A∩B） SELECT employee_id,last_name,department_name FROM employees e LEFT JOIN departments d ON e.`department_id` = d.`department_id` WHERE d.`department_id` IS NULL UNION ALL SELECT employee_id,last_name,department_name FROM employees e RIGHT JOIN departments d ON e.`department_id` = d.`department_id` WHERE e.`department_id` IS NULL 5.7.2 语法格式小结 左中图 #实现A - A∩B select 字段列表 from A表 left join B表 on 关联条件 where 从表关联字段 is null and 等其他子句; 右中图 #实现B - A∩B select 字段列表 from A表 right join B表 on 关联条件 where 从表关联字段 is null and 等其他子句; 左下图 #实现查询结果是A∪B #用左外的A，union 右外的B select 字段列表 from A表 left join B表 on 关联条件 where 等其他子句 union select 字段列表 from A表 right join B表 on 关联条件 where 等其他子句; 右下图 #实现A∪B - A∩B 或 (A - A∩B) ∪ （B - A∩B） #使用左外的 (A - A∩B) union 右外的（B - A∩B） select 字段列表 from A表 left join B表 on 关联条件 where 从表关联字段 is null and 等其他子句 union select 字段列表 from A表 right join B表 on 关联条件 where 从表关联字段 is null and 等其他子句 6. SQL99语法新特性6.1 自然连接SQL99 在 SQL92 的基础上提供了一些特殊语法，比如 NATURAL JOIN 用来表示自然连接。我们可以把自然连接理解为 SQL92 中的等值连接。它会帮你自动查询两张连接表中所有相同的字段，然后进行等值连接。 在SQL92标准中： SELECT employee_id,last_name,department_name FROM employees e JOIN departments d ON e.`department_id` = d.`department_id` AND e.`manager_id` = d.`manager_id`; 在 SQL99 中你可以写成： SELECT employee_id,last_name,department_name FROM employees e NATURAL JOIN departments d; 6.2 USING连接当我们进行连接的时候，SQL99还支持使用 USING 指定数据表里的同名字段进行等值连接。但是只能配合JOIN一起使用。比如： SELECT employee_id,last_name,department_name FROM employees e JOIN departments d USING (department_id); 你能看出与自然连接 NATURAL JOIN 不同的是，USING 指定了具体的相同的字段名称，你需要在 USING 的括号 () 中填入要指定的同名字段。同时使用 JOIN...USING 可以简化 JOIN ON 的等值连接。它与下面的 SQL 查询结果是相同的： SELECT employee_id,last_name,department_name FROM employees e ,departments d WHERE e.department_id = d.department_id; 7. 章节小结表连接的约束条件可以有三种方式：WHERE, ON, USING WHERE：适用于所有关联查询 ON：只能和JOIN一起使用，只能写关联条件。虽然关联条件可以并到WHERE中和其他条件一起写，但分开写可读性更好。 USING：只能和JOIN一起使用，而且要求两个关联字段在关联表中名称一致，而且只能表示关联字段值相等 #关联条件 #把关联条件写在where后面 SELECT last_name,department_name FROM employees,departments WHERE employees.department_id = departments.department_id; #把关联条件写在on后面，只能和JOIN一起使用 SELECT last_name,department_name FROM employees INNER JOIN departments ON employees.department_id = departments.department_id; SELECT last_name,department_name FROM employees CROSS JOIN departments ON employees.department_id = departments.department_id; SELECT last_name,department_name FROM employees JOIN departments ON employees.department_id = departments.department_id; #把关联字段写在using()中，只能和JOIN一起使用 #而且两个表中的关联字段必须名称相同，而且只能表示= #查询员工姓名与基本工资 SELECT last_name,job_title FROM employees INNER JOIN jobs USING(job_id); #n张表关联，需要n-1个关联条件 #查询员工姓名，基本工资，部门名称 SELECT last_name,job_title,department_name FROM employees,departments,jobs WHERE employees.department_id = departments.department_id AND employees.job_id = jobs.job_id; SELECT last_name,job_title,department_name FROM employees INNER JOIN departments INNER JOIN jobs ON employees.department_id = departments.department_id AND employees.job_id = jobs.job_id; 注意： 我们要控制连接表的数量。多表连接就相当于嵌套 for 循环一样，非常消耗资源，会让 SQL 查询性能下降得很严重，因此不要连接不必要的表。在许多 DBMS 中，也都会有最大连接表的限制。 【强制】超过三个表禁止 join。需要 join 的字段，数据类型保持绝对一致；多表关联查询时， 保证被关联的字段需要有索引。 说明：即使双表 join 也要注意表索引、SQL 性能。 来源：阿里巴巴《Java开发手册》 附录：常用的 SQL 标准有哪些在正式开始讲连接表的种类时，我们首先需要知道 SQL 存在不同版本的标准规范，因为不同规范下的表连接操作是有区别的。 SQL 有两个主要的标准，分别是 SQL92 和 SQL99。92 和 99 代表了标准提出的时间，SQL92 就是 92 年提出的标准规范。当然除了 SQL92 和 SQL99 以外，还存在 SQL-86、SQL-89、SQL:2003、SQL:2008、SQL:2011 和 SQL:2016 等其他的标准。 这么多标准，到底该学习哪个呢？实际上最重要的 SQL 标准就是 SQL92 和 SQL99。一般来说 SQL92 的形式更简单，但是写的 SQL 语句会比较长，可读性较差。而 SQL99 相比于 SQL92 来说，语法更加复杂，但可读性更强。我们从这两个标准发布的页数也能看出，SQL92 的标准有 500 页，而 SQL99 标准超过了 1000 页。实际上从 SQL99 之后，很少有人能掌握所有内容，因为确实太多了。就好比我们使用 Windows、Linux 和 Office 的时候，很少有人能掌握全部内容一样。我们只需要掌握一些核心的功能，满足日常工作的需求即可。 SQL92 和 SQL99 是经典的 SQL 标准，也分别叫做 SQL-2 和 SQL-3 标准。也正是在这两个标准发布之后，SQL 影响力越来越大，甚至超越了数据库领域。现如今 SQL 已经不仅仅是数据库领域的主流语言，还是信息领域中信息处理的主流语言。在图形检索、图像检索以及语音检索中都能看到 SQL 语言的使用。","categories":[{"name":"Mysql基础篇","slug":"Mysql基础篇","permalink":"https://bowonqin.github.io/categories/Mysql%E5%9F%BA%E7%A1%80%E7%AF%87/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"https://bowonqin.github.io/tags/Mysql/"},{"name":"数据库","slug":"数据库","permalink":"https://bowonqin.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"author":"qxd"},{"title":"Mysql(排序与分页)","slug":"mysql/第05章-排序与分页","date":"2021-12-20T11:39:51.000Z","updated":"2021-12-21T09:44:44.525Z","comments":true,"path":"posts/mysql5.html","link":"","permalink":"https://bowonqin.github.io/posts/mysql5.html","excerpt":"","text":"第05章_排序与分页康师傅（宋红康老师）听课笔记 BILIBILI听课网址：[宋红康]MySQL数据库（安装/基础/高级/优化）_哔哩哔哩_bilibili 1. 排序数据1.1 排序规则 使用 ORDER BY 子句排序 ASC（ascend）: 升序 DESC（descend）:降序 ORDER BY 子句在SELECT语句的结尾。 1.2 单列排序SELECT last_name, job_id, department_id, hire_date FROM employees ORDER BY hire_date ; SELECT last_name, job_id, department_id, hire_date FROM employees ORDER BY hire_date DESC ; SELECT employee_id, last_name, salary*12 annsal FROM employees ORDER BY annsal; 1.3 多列排序SELECT last_name, department_id, salary FROM employees ORDER BY department_id, salary DESC; 可以使用不在SELECT列表中的列排序。 在对多列进行排序的时候，首先排序的第一列必须有相同的列值，才会对第二列进行排序。如果第一列数据中所有值都是唯一的，将不再对第二列进行排序。 2. 分页2.1 背景背景1：查询返回的记录太多了，查看起来很不方便，怎么样能够实现分页查询呢？ 背景2：表里有 4 条数据，我们只想要显示第 2、3 条数据怎么办呢？ 2.2 实现规则 分页原理 所谓分页显示，就是将数据库中的结果集，一段一段显示出来需要的条件。 MySQL中使用 LIMIT 实现分页 格式： LIMIT [位置偏移量,] 行数 第一个“位置偏移量”参数指示MySQL从哪一行开始显示，是一个可选参数，如果不指定“位置偏移量”，将会从表中的第一条记录开始（第一条记录的位置偏移量是0，第二条记录的位置偏移量是1，以此类推）；第二个参数“行数”指示返回的记录条数。 举例 --前10条记录： SELECT * FROM 表名 LIMIT 0,10; 或者 SELECT * FROM 表名 LIMIT 10; --第11至20条记录： SELECT * FROM 表名 LIMIT 10,10; --第21至30条记录： SELECT * FROM 表名 LIMIT 20,10; MySQL 8.0中可以使用“LIMIT 3 OFFSET 4”，意思是获取从第5条记录开始后面的3条记录，和“LIMIT 4,3;”返回的结果相同。 分页显式公式：（当前页数-1）*每页条数，每页条数** SELECT * FROM table LIMIT(PageNo - 1)*PageSize,PageSize; 注意：LIMIT 子句必须放在整个SELECT语句的最后！ 使用 LIMIT 的好处 约束返回结果的数量可以减少数据表的网络传输量，也可以提升查询效率。如果我们知道返回结果只有 1 条，就可以使用LIMIT 1，告诉 SELECT 语句只需要返回一条记录即可。这样的好处就是 SELECT 不需要扫描完整的表，只需要检索到一条符合条件的记录即可返回。 2.3 拓展在不同的 DBMS 中使用的关键字可能不同。在 MySQL、PostgreSQL、MariaDB 和 SQLite 中使用 LIMIT 关键字，而且需要放到 SELECT 语句的最后面。 如果是 SQL Server 和 Access，需要使用 TOP 关键字，比如： SELECT TOP 5 name, hp_max FROM heros ORDER BY hp_max DESC 如果是 DB2，使用FETCH FIRST 5 ROWS ONLY这样的关键字： SELECT name, hp_max FROM heros ORDER BY hp_max DESC FETCH FIRST 5 ROWS ONLY 如果是 Oracle，你需要基于 ROWNUM 来统计行数： SELECT rownum,last_name,salary FROM employees WHERE rownum &lt; 5 ORDER BY salary DESC; 需要说明的是，这条语句是先取出来前 5 条数据行，然后再按照 hp_max 从高到低的顺序进行排序。但这样产生的结果和上述方法的并不一样。我会在后面讲到子查询，你可以使用 SELECT rownum, last_name,salary FROM ( SELECT last_name,salary FROM employees ORDER BY salary DESC) WHERE rownum &lt; 10; 得到与上述方法一致的结果。","categories":[{"name":"Mysql基础篇","slug":"Mysql基础篇","permalink":"https://bowonqin.github.io/categories/Mysql%E5%9F%BA%E7%A1%80%E7%AF%87/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"https://bowonqin.github.io/tags/Mysql/"},{"name":"数据库","slug":"数据库","permalink":"https://bowonqin.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"author":"qxd"},{"title":"Mysql(运算符)","slug":"mysql/第04章-运算符","date":"2021-12-20T09:50:51.000Z","updated":"2021-12-21T09:44:35.970Z","comments":true,"path":"posts/mysql4.html","link":"","permalink":"https://bowonqin.github.io/posts/mysql4.html","excerpt":"","text":"第04章_运算符康师傅（宋红康老师）听课笔记 BILIBILI听课网址：[宋红康]MySQL数据库（安装/基础/高级/优化）_哔哩哔哩_bilibili 1. 算术运算符算术运算符主要用于数学运算，其可以连接运算符前后的两个数值或表达式，对数值或表达式进行加（+）、减（-）、乘（*）、除（/）和取模（%）运算。 1．加法与减法运算符 mysql&gt; SELECT 100, 100 + 0, 100 - 0, 100 + 50, 100 + 50 -30, 100 + 35.5, 100 - 35.5 FROM dual; +-----+---------+---------+----------+--------------+------------+------------+ | 100 | 100 + 0 | 100 - 0 | 100 + 50 | 100 + 50 -30 | 100 + 35.5 | 100 - 35.5 | +-----+---------+---------+----------+--------------+------------+------------+ | 100 | 100 | 100 | 150 | 120 | 135.5 | 64.5 | +-----+---------+---------+----------+--------------+------------+------------+ 1 row in set (0.00 sec) 由运算结果可以得出如下结论： 一个整数类型的值对整数进行加法和减法操作，结果还是一个整数； 一个整数类型的值对浮点数进行加法和减法操作，结果是一个浮点数； 加法和减法的优先级相同，进行先加后减操作与进行先减后加操作的结果是一样的； 在Java中，+的左右两边如果有字符串，那么表示字符串的拼接。但是在MySQL中+只表示数值相加。如果遇到非数值类型，先尝试转成数值，如果转失败，就按0计算。（补充：MySQL中字符串拼接要使用字符串函数CONCAT()实现） 2．乘法与除法运算符 mysql&gt; SELECT 100, 100 * 1, 100 * 1.0, 100 / 1.0, 100 / 2,100 + 2 * 5 / 2,100 /3, 100 DIV 0 FROM dual; +-----+---------+-----------+-----------+---------+-----------------+---------+-----------+ | 100 | 100 * 1 | 100 * 1.0 | 100 / 1.0 | 100 / 2 | 100 + 2 * 5 / 2 | 100 /3 | 100 DIV 0 | +-----+---------+-----------+-----------+---------+-----------------+---------+-----------+ | 100 | 100 | 100.0 | 100.0000 | 50.0000 | 105.0000 | 33.3333 | NULL | +-----+---------+-----------+-----------+---------+-----------------+---------+-----------+ 1 row in set (0.00 sec) #计算出员工的年基本工资 SELECT employee_id,salary,salary * 12 annual_sal FROM employees; 由运算结果可以得出如下结论： 一个数乘以整数1和除以整数1后仍得原数； 一个数乘以浮点数1和除以浮点数1后变成浮点数，数值与原数相等； 一个数除以整数后，不管是否能除尽，结果都为一个浮点数； 一个数除以另一个数，除不尽时，结果为一个浮点数，并保留到小数点后4位； 乘法和除法的优先级相同，进行先乘后除操作与先除后乘操作，得出的结果相同。 在数学运算中，0不能用作除数，在MySQL中，一个数除以0为NULL。 3．求模（求余）运算符将t22表中的字段i对3和5进行求模（求余）运算。 mysql&gt; SELECT 12 % 3, 12 MOD 5 FROM dual; +--------+----------+ | 12 % 3 | 12 MOD 5 | +--------+----------+ | 0 | 2 | +--------+----------+ 1 row in set (0.00 sec) #筛选出employee_id是偶数的员工 SELECT * FROM employees WHERE employee_id MOD 2 = 0; 可以看到，100对3求模后的结果为3，对5求模后的结果为0。 2. 比较运算符比较运算符用来对表达式左边的操作数和右边的操作数进行比较，比较的结果为真则返回1，比较的结果为假则返回0，其他情况则返回NULL。 比较运算符经常被用来作为SELECT查询语句的条件来使用，返回符合条件的结果记录。 1．等号运算符 等号运算符（=）判断等号两边的值、字符串或表达式是否相等，如果相等则返回1，不相等则返回0。 在使用等号运算符时，遵循如下规则： 如果等号两边的值、字符串或表达式都为字符串，则MySQL会按照字符串进行比较，其比较的是每个字符串中字符的ANSI编码是否相等。 如果等号两边的值都是整数，则MySQL会按照整数来比较两个值的大小。 如果等号两边的值一个是整数，另一个是字符串，则MySQL会将字符串转化为数字进行比较。 如果等号两边的值、字符串或表达式中有一个为NULL，则比较结果为NULL。 对比：SQL中赋值符号使用 := mysql&gt; SELECT 1 = 1, 1 = '1', 1 = 0, 'a' = 'a', (5 + 3) = (2 + 6), '' = NULL , NULL = NULL; +-------+---------+-------+-----------+-------------------+-----------+-------------+ | 1 = 1 | 1 = '1' | 1 = 0 | 'a' = 'a' | (5 + 3) = (2 + 6) | '' = NULL | NULL = NULL | +-------+---------+-------+-----------+-------------------+-----------+-------------+ | 1 | 1 | 0 | 1 | 1 | NULL | NULL | +-------+---------+-------+-----------+-------------------+-----------+-------------+ 1 row in set (0.00 sec) mysql&gt; SELECT 1 = 2, 0 = 'abc', 1 = 'abc' FROM dual; +-------+-----------+-----------+ | 1 = 2 | 0 = 'abc' | 1 = 'abc' | +-------+-----------+-----------+ | 0 | 1 | 0 | +-------+-----------+-----------+ 1 row in set, 2 warnings (0.00 sec) #查询salary=10000，注意在Java中比较是== SELECT employee_id,salary FROM employees WHERE salary = 10000; 2．安全等于运算符安全等于运算符（&lt;=&gt;）与等于运算符（=）的作用是相似的，唯一的区别是‘&lt;=&gt;’可以用来对NULL进行判断。在两个操作数均为NULL时，其返回值为1，而不为NULL；当一个操作数为NULL时，其返回值为0，而不为NULL。 mysql&gt; SELECT 1 &lt;=&gt; '1', 1 &lt;=&gt; 0, 'a' &lt;=&gt; 'a', (5 + 3) &lt;=&gt; (2 + 6), '' &lt;=&gt; NULL,NULL &lt;=&gt; NULL FROM dual; +-----------+---------+-------------+---------------------+-------------+---------------+ | 1 &lt;=&gt; '1' | 1 &lt;=&gt; 0 | 'a' &lt;=&gt; 'a' | (5 + 3) &lt;=&gt; (2 + 6) | '' &lt;=&gt; NULL | NULL &lt;=&gt; NULL | +-----------+---------+-------------+---------------------+-------------+---------------+ | 1 | 0 | 1 | 1 | 0 | 1 | +-----------+---------+-------------+---------------------+-------------+---------------+ 1 row in set (0.00 sec) #查询commission_pct等于0.40 SELECT employee_id,commission_pct FROM employees WHERE commission_pct = 0.40; SELECT employee_id,commission_pct FROM employees WHERE commission_pct &lt;=&gt; 0.40; #如果把0.40改成 NULL 呢？ 可以看到，使用安全等于运算符时，两边的操作数的值都为NULL时，返回的结果为1而不是NULL，其他返回结果与等于运算符相同。 3．不等于运算符不等于运算符（&lt;&gt;和!=）用于判断两边的数字、字符串或者表达式的值是否不相等，如果不相等则返回1，相等则返回0。不等于运算符不能判断NULL值。如果两边的值有任意一个为NULL，或两边都为NULL，则结果为NULL。SQL语句示例如下： mysql&gt; SELECT 1 &lt;&gt; 1, 1 != 2, 'a' != 'b', (3+4) &lt;&gt; (2+6), 'a' != NULL, NULL &lt;&gt; NULL; +--------+--------+------------+----------------+-------------+--------------+ | 1 &lt;&gt; 1 | 1 != 2 | 'a' != 'b' | (3+4) &lt;&gt; (2+6) | 'a' != NULL | NULL &lt;&gt; NULL | +--------+--------+------------+----------------+-------------+--------------+ | 0 | 1 | 1 | 1 | NULL | NULL | +--------+--------+------------+----------------+-------------+--------------+ 1 row in set (0.00 sec) 此外，还有非符号类型的运算符： 4. 空运算符空运算符（IS NULL或者ISNULL）判断一个值是否为NULL，如果为NULL则返回1，否则返回0。SQL语句示例如下： mysql&gt; SELECT NULL IS NULL, ISNULL(NULL), ISNULL('a'), 1 IS NULL; +--------------+--------------+-------------+-----------+ | NULL IS NULL | ISNULL(NULL) | ISNULL('a') | 1 IS NULL | +--------------+--------------+-------------+-----------+ | 1 | 1 | 0 | 0 | +--------------+--------------+-------------+-----------+ 1 row in set (0.00 sec) #查询commission_pct等于NULL。比较如下的四种写法 SELECT employee_id,commission_pct FROM employees WHERE commission_pct IS NULL; SELECT employee_id,commission_pct FROM employees WHERE commission_pct &lt;=&gt; NULL; SELECT employee_id,commission_pct FROM employees WHERE ISNULL(commission_pct); SELECT employee_id,commission_pct FROM employees WHERE commission_pct = NULL; SELECT last_name, manager_id FROM employees WHERE manager_id IS NULL; 5. 非空运算符非空运算符（IS NOT NULL）判断一个值是否不为NULL，如果不为NULL则返回1，否则返回0。SQL语句示例如下： mysql&gt; SELECT NULL IS NOT NULL, 'a' IS NOT NULL, 1 IS NOT NULL; +------------------+-----------------+---------------+ | NULL IS NOT NULL | 'a' IS NOT NULL | 1 IS NOT NULL | +------------------+-----------------+---------------+ | 0 | 1 | 1 | +------------------+-----------------+---------------+ 1 row in set (0.01 sec) #查询commission_pct不等于NULL SELECT employee_id,commission_pct FROM employees WHERE commission_pct IS NOT NULL; SELECT employee_id,commission_pct FROM employees WHERE NOT commission_pct &lt;=&gt; NULL; SELECT employee_id,commission_pct FROM employees WHERE NOT ISNULL(commission_pct); 6. 最小值运算符语法格式为：LEAST(值1，值2，…，值n)。其中，“值n”表示参数列表中有n个值。在有两个或多个参数的情况下，返回最小值。 mysql&gt; SELECT LEAST (1,0,2), LEAST('b','a','c'), LEAST(1,NULL,2); +---------------+--------------------+-----------------+ | LEAST (1,0,2) | LEAST('b','a','c') | LEAST(1,NULL,2) | +---------------+--------------------+-----------------+ | 0 | a | NULL | +---------------+--------------------+-----------------+ 1 row in set (0.00 sec) 由结果可以看到，当参数是整数或者浮点数时，LEAST将返回其中最小的值；当参数为字符串时，返回字母表中顺序最靠前的字符；当比较值列表中有NULL时，不能判断大小，返回值为NULL。 7. 最大值运算符语法格式为：GREATEST(值1，值2，…，值n)。其中，n表示参数列表中有n个值。当有两个或多个参数时，返回值为最大值。假如任意一个自变量为NULL，则GREATEST()的返回值为NULL。 mysql&gt; SELECT GREATEST(1,0,2), GREATEST('b','a','c'), GREATEST(1,NULL,2); +-----------------+-----------------------+--------------------+ | GREATEST(1,0,2) | GREATEST('b','a','c') | GREATEST(1,NULL,2) | +-----------------+-----------------------+--------------------+ | 2 | c | NULL | +-----------------+-----------------------+--------------------+ 1 row in set (0.00 sec) 由结果可以看到，当参数中是整数或者浮点数时，GREATEST将返回其中最大的值；当参数为字符串时，返回字母表中顺序最靠后的字符；当比较值列表中有NULL时，不能判断大小，返回值为NULL。 8. BETWEEN AND运算符BETWEEN运算符使用的格式通常为SELECT D FROM TABLE WHERE C BETWEEN A AND B，此时，当C大于或等于A，并且C小于或等于B时，结果为1，否则结果为0。 mysql&gt; SELECT 1 BETWEEN 0 AND 1, 10 BETWEEN 11 AND 12, 'b' BETWEEN 'a' AND 'c'; +-------------------+----------------------+-------------------------+ | 1 BETWEEN 0 AND 1 | 10 BETWEEN 11 AND 12 | 'b' BETWEEN 'a' AND 'c' | +-------------------+----------------------+-------------------------+ | 1 | 0 | 1 | +-------------------+----------------------+-------------------------+ 1 row in set (0.00 sec) SELECT last_name, salary FROM employees WHERE salary BETWEEN 2500 AND 3500; 9. IN运算符IN运算符用于判断给定的值是否是IN列表中的一个值，如果是则返回1，否则返回0。如果给定的值为NULL，或者IN列表中存在NULL，则结果为NULL。 mysql&gt; SELECT 'a' IN ('a','b','c'), 1 IN (2,3), NULL IN ('a','b'), 'a' IN ('a', NULL); +----------------------+------------+-------------------+--------------------+ | 'a' IN ('a','b','c') | 1 IN (2,3) | NULL IN ('a','b') | 'a' IN ('a', NULL) | +----------------------+------------+-------------------+--------------------+ | 1 | 0 | NULL | 1 | +----------------------+------------+-------------------+--------------------+ 1 row in set (0.00 sec) SELECT employee_id, last_name, salary, manager_id FROM employees WHERE manager_id IN (100, 101, 201); 10. NOT IN运算符NOT IN运算符用于判断给定的值是否不是IN列表中的一个值，如果不是IN列表中的一个值，则返回1，否则返回0。 mysql&gt; SELECT 'a' NOT IN ('a','b','c'), 1 NOT IN (2,3); +--------------------------+----------------+ | 'a' NOT IN ('a','b','c') | 1 NOT IN (2,3) | +--------------------------+----------------+ | 0 | 1 | +--------------------------+----------------+ 1 row in set (0.00 sec) 11. LIKE运算符LIKE运算符主要用来匹配字符串，通常用于模糊匹配，如果满足条件则返回1，否则返回0。如果给定的值或者匹配条件为NULL，则返回结果为NULL。 LIKE运算符通常使用如下通配符： “%”：匹配0个或多个字符。 “_”：只能匹配一个字符。 SQL语句示例如下： mysql&gt; SELECT NULL LIKE 'abc', 'abc' LIKE NULL; +-----------------+-----------------+ | NULL LIKE 'abc' | 'abc' LIKE NULL | +-----------------+-----------------+ | NULL | NULL | +-----------------+-----------------+ 1 row in set (0.00 sec) SELECT first_name FROM employees WHERE first_name LIKE 'S%'; SELECT last_name FROM employees WHERE last_name LIKE '_o%'; ESCAPE 回避特殊符号的：使用转义符。例如：将[%]转为[$%]、[]转为[$]，然后再加上[ESCAPE‘$’]即可。 SELECT job_id FROM jobs WHERE job_id LIKE ‘IT\\_%‘; 如果使用\\表示转义，要省略ESCAPE。如果不是\\，则要加上ESCAPE。 SELECT job_id FROM jobs WHERE job_id LIKE ‘IT$_%‘ escape ‘$‘; 12. REGEXP运算符 REGEXP运算符用来匹配字符串，语法格式为：expr REGEXP 匹配条件。如果expr满足匹配条件，返回1；如果不满足，则返回0。若expr或匹配条件任意一个为NULL，则结果为NULL。 REGEXP运算符在进行匹配时，常用的有下面几种通配符： （1）‘^’匹配以该字符后面的字符开头的字符串。 （2）‘$’匹配以该字符前面的字符结尾的字符串。 （3）‘.’匹配任何一个单字符。 （4）“[...]”匹配在方括号内的任何字符。例如，“[abc]”匹配“a”或“b”或“c”。为了命名字符的范围，使用一个‘-’。“[a-z]”匹配任何字母，而“[0-9]”匹配任何数字。 （5）‘*’匹配零个或多个在它前面的字符。例如，“x*”匹配任何数量的‘x’字符，“[0-9]*”匹配任何数量的数字，而“*”匹配任何数量的任何字符。 SQL语句示例如下： mysql&gt; SELECT 'shkstart' REGEXP '^s', 'shkstart' REGEXP 't$', 'shkstart' REGEXP 'hk'; +------------------------+------------------------+-------------------------+ | 'shkstart' REGEXP '^s' | 'shkstart' REGEXP 't$' | 'shkstart' REGEXP 'hk' | +------------------------+------------------------+-------------------------+ | 1 | 1 | 1 | +------------------------+------------------------+-------------------------+ 1 row in set (0.01 sec) mysql&gt; SELECT 'atguigu' REGEXP 'gu.gu', 'atguigu' REGEXP '[ab]'; +--------------------------+-------------------------+ | 'atguigu' REGEXP 'gu.gu' | 'atguigu' REGEXP '[ab]' | +--------------------------+-------------------------+ | 1 | 1 | +--------------------------+-------------------------+ 1 row in set (0.00 sec) 3. 逻辑运算符逻辑运算符主要用来判断表达式的真假，在MySQL中，逻辑运算符的返回结果为1、0或者NULL。 MySQL中支持4种逻辑运算符如下： 1．逻辑非运算符逻辑非（NOT或!）运算符表示当给定的值为0时返回1；当给定的值为非0值时返回0；当给定的值为NULL时，返回NULL。 mysql&gt; SELECT NOT 1, NOT 0, NOT(1+1), NOT !1, NOT NULL; +-------+-------+----------+--------+----------+ | NOT 1 | NOT 0 | NOT(1+1) | NOT !1 | NOT NULL | +-------+-------+----------+--------+----------+ | 0 | 1 | 0 | 1 | NULL | +-------+-------+----------+--------+----------+ 1 row in set, 1 warning (0.00 sec) SELECT last_name, job_id FROM employees WHERE job_id NOT IN ('IT_PROG', 'ST_CLERK', 'SA_REP'); 2．逻辑与运算符逻辑与（AND或&amp;&amp;）运算符是当给定的所有值均为非0值，并且都不为NULL时，返回1；当给定的一个值或者多个值为0时则返回0；否则返回NULL。 mysql&gt; SELECT 1 AND -1, 0 AND 1, 0 AND NULL, 1 AND NULL; +----------+---------+------------+------------+ | 1 AND -1 | 0 AND 1 | 0 AND NULL | 1 AND NULL | +----------+---------+------------+------------+ | 1 | 0 | 0 | NULL | +----------+---------+------------+------------+ 1 row in set (0.00 sec) SELECT employee_id, last_name, job_id, salary FROM employees WHERE salary &gt;=10000 AND job_id LIKE '%MAN%'; 3．逻辑或运算符逻辑或（OR或||）运算符是当给定的值都不为NULL，并且任何一个值为非0值时，则返回1，否则返回0；当一个值为NULL，并且另一个值为非0值时，返回1，否则返回NULL；当两个值都为NULL时，返回NULL。 mysql&gt; SELECT 1 OR -1, 1 OR 0, 1 OR NULL, 0 || NULL, NULL || NULL; +---------+--------+-----------+-----------+--------------+ | 1 OR -1 | 1 OR 0 | 1 OR NULL | 0 || NULL | NULL || NULL | +---------+--------+-----------+-----------+--------------+ | 1 | 1 | 1 | NULL | NULL | +---------+--------+-----------+-----------+--------------+ 1 row in set, 2 warnings (0.00 sec) #查询基本薪资不在9000-12000之间的员工编号和基本薪资 SELECT employee_id,salary FROM employees WHERE NOT (salary &gt;= 9000 AND salary &lt;= 12000); SELECT employee_id,salary FROM employees WHERE salary &lt;9000 OR salary &gt; 12000; SELECT employee_id,salary FROM employees WHERE salary NOT BETWEEN 9000 AND 12000; SELECT employee_id, last_name, job_id, salary FROM employees WHERE salary &gt;= 10000 OR job_id LIKE '%MAN%'; 注意： OR可以和AND一起使用，但是在使用时要注意两者的优先级，由于AND的优先级高于OR，因此先对AND两边的操作数进行操作，再与OR中的操作数结合。 4．逻辑异或运算符逻辑异或（XOR）运算符是当给定的值中任意一个值为NULL时，则返回NULL；如果两个非NULL的值都是0或者都不等于0时，则返回0；如果一个值为0，另一个值不为0时，则返回1。 mysql&gt; SELECT 1 XOR -1, 1 XOR 0, 0 XOR 0, 1 XOR NULL, 1 XOR 1 XOR 1, 0 XOR 0 XOR 0; +----------+---------+---------+------------+---------------+---------------+ | 1 XOR -1 | 1 XOR 0 | 0 XOR 0 | 1 XOR NULL | 1 XOR 1 XOR 1 | 0 XOR 0 XOR 0 | +----------+---------+---------+------------+---------------+---------------+ | 0 | 1 | 0 | NULL | 1 | 0 | +----------+---------+---------+------------+---------------+---------------+ 1 row in set (0.00 sec) select last_name,department_id,salary from employees where department_id in (10,20) XOR salary &gt; 8000; 4. 位运算符位运算符是在二进制数上进行计算的运算符。位运算符会先将操作数变成二进制数，然后进行位运算，最后将计算结果从二进制变回十进制数。 MySQL支持的位运算符如下： 1．按位与运算符按位与（&amp;）运算符将给定值对应的二进制数逐位进行逻辑与运算。当给定值对应的二进制位的数值都为1时，则该位返回1，否则返回0。 mysql&gt; SELECT 1 &amp; 10, 20 &amp; 30; +--------+---------+ | 1 &amp; 10 | 20 &amp; 30 | +--------+---------+ | 0 | 20 | +--------+---------+ 1 row in set (0.00 sec) 1的二进制数为0001，10的二进制数为1010，所以1 &amp; 10的结果为0000，对应的十进制数为0。20的二进制数为10100，30的二进制数为11110，所以20 &amp; 30的结果为10100，对应的十进制数为20。 2. 按位或运算符按位或（|）运算符将给定的值对应的二进制数逐位进行逻辑或运算。当给定值对应的二进制位的数值有一个或两个为1时，则该位返回1，否则返回0。 mysql&gt; SELECT 1 | 10, 20 | 30; +--------+---------+ | 1 | 10 | 20 | 30 | +--------+---------+ | 11 | 30 | +--------+---------+ 1 row in set (0.00 sec) 1的二进制数为0001，10的二进制数为1010，所以1 | 10的结果为1011，对应的十进制数为11。20的二进制数为10100，30的二进制数为11110，所以20 | 30的结果为11110，对应的十进制数为30。 3. 按位异或运算符按位异或（^）运算符将给定的值对应的二进制数逐位进行逻辑异或运算。当给定值对应的二进制位的数值不同时，则该位返回1，否则返回0。 mysql&gt; SELECT 1 ^ 10, 20 ^ 30; +--------+---------+ | 1 ^ 10 | 20 ^ 30 | +--------+---------+ | 11 | 10 | +--------+---------+ 1 row in set (0.00 sec) 1的二进制数为0001，10的二进制数为1010，所以1 ^ 10的结果为1011，对应的十进制数为11。20的二进制数为10100，30的二进制数为11110，所以20 ^ 30的结果为01010，对应的十进制数为10。 再举例： mysql&gt; SELECT 12 &amp; 5, 12 | 5,12 ^ 5 FROM DUAL; +--------+--------+--------+ | 12 &amp; 5 | 12 | 5 | 12 ^ 5 | +--------+--------+--------+ | 4 | 13 | 9 | +--------+--------+--------+ 1 row in set (0.00 sec) 4. 按位取反运算符按位取反（~）运算符将给定的值的二进制数逐位进行取反操作，即将1变为0，将0变为1。 mysql&gt; SELECT 10 &amp; ~1; +---------+ | 10 &amp; ~1 | +---------+ | 10 | +---------+ 1 row in set (0.00 sec) 由于按位取反（~）运算符的优先级高于按位与（&amp;）运算符的优先级，所以10 &amp; ~1，首先，对数字1进行按位取反操作，结果除了最低位为0，其他位都为1，然后与10进行按位与操作，结果为10。 5. 按位右移运算符按位右移（&gt;&gt;）运算符将给定的值的二进制数的所有位右移指定的位数。右移指定的位数后，右边低位的数值被移出并丢弃，左边高位空出的位置用0补齐。 mysql&gt; SELECT 1 &gt;&gt; 2, 4 &gt;&gt; 2; +--------+--------+ | 1 &gt;&gt; 2 | 4 &gt;&gt; 2 | +--------+--------+ | 0 | 1 | +--------+--------+ 1 row in set (0.00 sec) 1的二进制数为0000 0001，右移2位为0000 0000，对应的十进制数为0。4的二进制数为0000 0100，右移2位为0000 0001，对应的十进制数为1。 6. 按位左移运算符按位左移（&lt;&lt;）运算符将给定的值的二进制数的所有位左移指定的位数。左移指定的位数后，左边高位的数值被移出并丢弃，右边低位空出的位置用0补齐。 mysql&gt; SELECT 1 &lt;&lt; 2, 4 &lt;&lt; 2; +--------+--------+ | 1 &lt;&lt; 2 | 4 &lt;&lt; 2 | +--------+--------+ | 4 | 16 | +--------+--------+ 1 row in set (0.00 sec) 1的二进制数为0000 0001，左移两位为0000 0100，对应的十进制数为4。4的二进制数为0000 0100，左移两位为0001 0000，对应的十进制数为16。 5. 运算符的优先级 数字编号越大，优先级越高，优先级高的运算符先进行计算。可以看到，赋值运算符的优先级最低，使用“()”括起来的表达式的优先级最高。 拓展：使用正则表达式查询正则表达式通常被用来检索或替换那些符合某个模式的文本内容，根据指定的匹配模式匹配文本中符合要求的特殊字符串。例如，从一个文本文件中提取电话号码，查找一篇文章中重复的单词或者替换用户输入的某些敏感词语等，这些地方都可以使用正则表达式。正则表达式强大而且灵活，可以应用于非常复杂的查询。 MySQL中使用REGEXP关键字指定正则表达式的字符匹配模式。下表列出了REGEXP操作符中常用字符匹配列表。 1. 查询以特定字符或字符串开头的记录字符‘^’匹配以特定字符或者字符串开头的文本。 在fruits表中，查询f_name字段以字母‘b’开头的记录，SQL语句如下： mysql&gt; SELECT * FROM fruits WHERE f_name REGEXP '^b'; 2. 查询以特定字符或字符串结尾的记录字符‘$’匹配以特定字符或者字符串结尾的文本。 在fruits表中，查询f_name字段以字母‘y’结尾的记录，SQL语句如下： mysql&gt; SELECT * FROM fruits WHERE f_name REGEXP 'y$'; 3. 用符号”.”来替代字符串中的任意一个字符字符‘.’匹配任意一个字符。在fruits表中，查询f_name字段值包含字母‘a’与‘g’且两个字母之间只有一个字母的记录，SQL语句如下： mysql&gt; SELECT * FROM fruits WHERE f_name REGEXP 'a.g'; *4. 使用”“和”+”来匹配多个字符**星号‘*’匹配前面的字符任意多次，包括0次。加号‘+’匹配前面的字符至少一次。 在fruits表中，查询f_name字段值以字母‘b’开头且‘b’后面出现字母‘a’的记录，SQL语句如下： mysql&gt; SELECT * FROM fruits WHERE f_name REGEXP '^ba*'; 在fruits表中，查询f_name字段值以字母‘b’开头且‘b’后面出现字母‘a’至少一次的记录，SQL语句如下： mysql&gt; SELECT * FROM fruits WHERE f_name REGEXP '^ba+'; 5. 匹配指定字符串正则表达式可以匹配指定字符串，只要这个字符串在查询文本中即可，如要匹配多个字符串，多个字符串之间使用分隔符‘|’隔开。 在fruits表中，查询f_name字段值包含字符串“on”的记录，SQL语句如下： mysql&gt; SELECT * FROM fruits WHERE f_name REGEXP 'on'; 在fruits表中，查询f_name字段值包含字符串“on”或者“ap”的记录，SQL语句如下： mysql&gt; SELECT * FROM fruits WHERE f_name REGEXP 'on|ap'; 之前介绍过，LIKE运算符也可以匹配指定的字符串，但与REGEXP不同，LIKE匹配的字符串如果在文本中间出现，则找不到它，相应的行也不会返回。REGEXP在文本内进行匹配，如果被匹配的字符串在文本中出现，REGEXP将会找到它，相应的行也会被返回。对比结果如下所示。 在fruits表中，使用LIKE运算符查询f_name字段值为“on”的记录，SQL语句如下： mysql&gt; SELECT * FROM fruits WHERE f_name like 'on'; Empty set(0.00 sec) 6. 匹配指定字符中的任意一个方括号“[]”指定一个字符集合，只匹配其中任何一个字符，即为所查找的文本。 在fruits表中，查找f_name字段中包含字母‘o’或者‘t’的记录，SQL语句如下： mysql&gt; SELECT * FROM fruits WHERE f_name REGEXP '[ot]'; 在fruits表中，查询s_id字段中包含4、5或者6的记录，SQL语句如下： mysql&gt; SELECT * FROM fruits WHERE s_id REGEXP '[456]'; 7. 匹配指定字符以外的字符“[^字符集合]”匹配不在指定集合中的任何字符。 在fruits表中，查询f_id字段中包含字母ae和数字12以外字符的记录，SQL语句如下： mysql&gt; SELECT * FROM fruits WHERE f_id REGEXP '[^a-e1-2]'; 8. 使用{n,}或者{n,m}来指定字符串连续出现的次数“字符串{n,}”表示至少匹配n次前面的字符；“字符串{n,m}”表示匹配前面的字符串不少于n次，不多于m次。例如，a{2,}表示字母a连续出现至少2次，也可以大于2次；a{2,4}表示字母a连续出现最少2次，最多不能超过4次。 在fruits表中，查询f_name字段值出现字母‘x’至少2次的记录，SQL语句如下： mysql&gt; SELECT * FROM fruits WHERE f_name REGEXP 'x{2,}'; 在fruits表中，查询f_name字段值出现字符串“ba”最少1次、最多3次的记录，SQL语句如下： mysql&gt; SELECT * FROM fruits WHERE f_name REGEXP 'ba{1,3}';","categories":[{"name":"Mysql基础篇","slug":"Mysql基础篇","permalink":"https://bowonqin.github.io/categories/Mysql%E5%9F%BA%E7%A1%80%E7%AF%87/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"https://bowonqin.github.io/tags/Mysql/"},{"name":"数据库","slug":"数据库","permalink":"https://bowonqin.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"author":"qxd"},{"title":"Mysql(基本的SELECT语句)","slug":"mysql/第03章-基本的SELECT语句","date":"2021-12-20T07:40:51.000Z","updated":"2021-12-21T09:44:29.702Z","comments":true,"path":"posts/mysql3.html","link":"","permalink":"https://bowonqin.github.io/posts/mysql3.html","excerpt":"","text":"第03章_基本的SELECT语句康师傅（宋红康老师）听课笔记 BILIBILI听课网址：[宋红康]MySQL数据库（安装/基础/高级/优化）_哔哩哔哩_bilibili 1. SQL概述1.1 SQL背景知识 1946 年，世界上第一台电脑诞生，如今，借由这台电脑发展起来的互联网已经自成江湖。在这几十年里，无数的技术、产业在这片江湖里沉浮，有的方兴未艾，有的已经几幕兴衰。但在这片浩荡的波动里，有一门技术从未消失，甚至“老当益壮”，那就是 SQL。 45 年前，也就是 1974 年，IBM 研究员发布了一篇揭开数据库技术的论文《SEQUEL：一门结构化的英语查询语言》，直到今天这门结构化的查询语言并没有太大的变化，相比于其他语言，SQL 的半衰期可以说是非常长了。 不论是前端工程师，还是后端算法工程师，都一定会和数据打交道，都需要了解如何又快又准确地提取自己想要的数据。更别提数据分析师了，他们的工作就是和数据打交道，整理不同的报告，以便指导业务决策。 SQL（Structured Query Language，结构化查询语言）是使用关系模型的数据库应用语言，与数据直接打交道，由IBM上世纪70年代开发出来。后由美国国家标准局（ANSI）开始着手制定SQL标准，先后有SQL-86，SQL-89，SQL-92，SQL-99等标准。 SQL 有两个重要的标准，分别是 SQL92 和 SQL99，它们分别代表了 92 年和 99 年颁布的 SQL 标准，我们今天使用的 SQL 语言依然遵循这些标准。 不同的数据库生产厂商都支持SQL语句，但都有特有内容。 1.2 SQL语言排行榜自从 SQL 加入了 TIOBE 编程语言排行榜，就一直保持在 Top 10。 1.3 SQL 分类SQL语言在功能上主要分为如下3大类： DDL（Data Definition Languages、数据定义语言），这些语句定义了不同的数据库、表、视图、索引等数据库对象，还可以用来创建、删除、修改数据库和数据表的结构。 主要的语句关键字包括CREATE、DROP、ALTER等。 DML（Data Manipulation Language、数据操作语言），用于添加、删除、更新和查询数据库记录，并检查数据完整性。 主要的语句关键字包括INSERT、DELETE、UPDATE、SELECT等。 SELECT是SQL语言的基础，最为重要。 DCL（Data Control Language、数据控制语言），用于定义数据库、表、字段、用户的访问权限和安全级别。 主要的语句关键字包括GRANT、REVOKE、COMMIT、ROLLBACK、SAVEPOINT等。 因为查询语句使用的非常的频繁，所以很多人把查询语句单拎出来一类：DQL（数据查询语言）。 还有单独将COMMIT、ROLLBACK 取出来称为TCL （Transaction Control Language，事务控制语言）。 2. SQL语言的规则与规范2.1 基本规则 SQL 可以写在一行或者多行。为了提高可读性，各子句分行写，必要时使用缩进 每条命令以 ; 或 \\g 或 \\G 结束 关键字不能被缩写也不能分行 关于标点符号 必须保证所有的()、单引号、双引号是成对结束的 必须使用英文状态下的半角输入方式 字符串型和日期时间类型的数据可以使用单引号（’ ‘）表示 列的别名，尽量使用双引号（” “），而且不建议省略as 2.2 SQL大小写规范 （建议遵守） MySQL 在 Windows 环境下是大小写不敏感的 MySQL 在 Linux 环境下是大小写敏感的 数据库名、表名、表的别名、变量名是严格区分大小写的 关键字、函数名、列名(或字段名)、列的别名(字段的别名) 是忽略大小写的。 推荐采用统一的书写规范： 数据库名、表名、表别名、字段名、字段别名等都小写 SQL 关键字、函数名、绑定变量等都大写 2.3 注 释可以使用如下格式的注释结构 单行注释：#注释文字(MySQL特有的方式) 单行注释：-- 注释文字(--后面必须包含一个空格。) 多行注释：/* 注释文字 */ 2.4 命名规则（暂时了解） 数据库、表名不得超过30个字符，变量名限制为29个 必须只能包含 A–Z, a–z, 0–9, _共63个字符 数据库名、表名、字段名等对象名中间不要包含空格 同一个MySQL软件中，数据库不能同名；同一个库中，表不能重名；同一个表中，字段不能重名 必须保证你的字段没有和保留字、数据库系统或常用方法冲突。如果坚持使用，请在SQL语句中使用`（着重号）引起来 保持字段名和类型的一致性，在命名字段并为其指定数据类型的时候一定要保证一致性。假如数据类型在一个表里是整数，那在另一个表里可就别变成字符型了 举例： #以下两句是一样的，不区分大小写 show databases; SHOW DATABASES; #创建表格 #create table student info(...); #表名错误，因为表名有空格 create table student_info(...); #其中order使用``飘号，因为order和系统关键字或系统函数名等预定义标识符重名了 CREATE TABLE `order`( id INT, lname VARCHAR(20) ); select id as \"编号\", `name` as \"姓名\" from t_stu; #起别名时，as都可以省略 select id as 编号, `name` as 姓名 from t_stu; #如果字段别名中没有空格，那么可以省略\"\" select id as 编 号, `name` as 姓 名 from t_stu; #错误，如果字段别名中有空格，那么不能省略\"\" 2.5 数据导入指令在命令行客户端登录mysql，使用source指令导入 mysql&gt; source d:\\mysqldb.sql mysql&gt; desc employees; +----------------+-------------+------+-----+---------+-------+ | Field | Type | Null | Key | Default | Extra | +----------------+-------------+------+-----+---------+-------+ | employee_id | int(6) | NO | PRI | 0 | | | first_name | varchar(20) | YES | | NULL | | | last_name | varchar(25) | NO | | NULL | | | email | varchar(25) | NO | UNI | NULL | | | phone_number | varchar(20) | YES | | NULL | | | hire_date | date | NO | | NULL | | | job_id | varchar(10) | NO | MUL | NULL | | | salary | double(8,2) | YES | | NULL | | | commission_pct | double(2,2) | YES | | NULL | | | manager_id | int(6) | YES | MUL | NULL | | | department_id | int(4) | YES | MUL | NULL | | +----------------+-------------+------+-----+---------+-------+ 11 rows in set (0.00 sec) 3. 基本的SELECT语句3.0 SELECT…SELECT 1; #没有任何子句 SELECT 9/2; #没有任何子句 3.1 SELECT … FROM 语法： SELECT 标识选择哪些列 FROM 标识从哪个表中选择 选择全部列： SELECT * FROM departments; 一般情况下，除非需要使用表中所有的字段数据，最好不要使用通配符‘*’。使用通配符虽然可以节省输入查询语句的时间，但是获取不需要的列数据通常会降低查询和所使用的应用程序的效率。通配符的优势是，当不知道所需要的列的名称时，可以通过它获取它们。 在生产环境下，不推荐你直接使用SELECT *进行查询。 选择特定的列： SELECT department_id, location_id FROM departments; MySQL中的SQL语句是不区分大小写的，因此SELECT和select的作用是相同的，但是，许多开发人员习惯将关键字大写、数据列和表名小写，读者也应该养成一个良好的编程习惯，这样写出来的代码更容易阅读和维护。 3.2 列的别名 重命名一个列 便于计算 紧跟列名，也可以在列名和别名之间加入关键字AS，别名使用双引号，以便在别名中包含空格或特殊的字符并区分大小写。 AS 可以省略 建议别名简短，见名知意 举例 SELECT last_name AS name, commission_pct comm FROM employees; SELECT last_name \"Name\", salary*12 \"Annual Salary\" FROM employees; 3.3 去除重复行默认情况下，查询会返回全部行，包括重复行。 SELECT department_id FROM employees; 在SELECT语句中使用关键字DISTINCT去除重复行 SELECT DISTINCT department_id FROM employees; 针对于： SELECT DISTINCT department_id,salary FROM employees; 这里有两点需要注意： DISTINCT 需要放到所有列名的前面，如果写成SELECT salary, DISTINCT department_id FROM employees会报错。 DISTINCT 其实是对后面所有列名的组合进行去重，你能看到最后的结果是 74 条，因为这 74 个部门id不同，都有 salary 这个属性值。如果你想要看都有哪些不同的部门（department_id），只需要写DISTINCT department_id即可，后面不需要再加其他的列名了。 3.4 空值参与运算 所有运算符或列值遇到null值，运算的结果都为null SELECT employee_id,salary,commission_pct, 12 * salary * (1 + commission_pct) \"annual_sal\" FROM employees; 这里你一定要注意，在 MySQL 里面， 空值不等于空字符串。一个空字符串的长度是 0，而一个空值的长度是空。而且，在 MySQL 里面，空值是占用空间的。 3.5 着重号 错误的 mysql&gt; SELECT * FROM ORDER; ERROR 1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near 'ORDER' at line 1 正确的 mysql&gt; SELECT * FROM `ORDER`; +----------+------------+ | order_id | order_name | +----------+------------+ | 1 | shkstart | | 2 | tomcat | | 3 | dubbo | +----------+------------+ 3 rows in set (0.00 sec) mysql&gt; SELECT * FROM `order`; +----------+------------+ | order_id | order_name | +----------+------------+ | 1 | shkstart | | 2 | tomcat | | 3 | dubbo | +----------+------------+ 3 rows in set (0.00 sec) 结论 我们需要保证表中的字段、表名等没有和保留字、数据库系统或常用方法冲突。如果真的相同，请在SQL语句中使用一对``（着重号）引起来。 3.6 5、查询常数SELECT 查询还可以对常数进行查询。对的，就是在 SELECT 查询结果中增加一列固定的常数列。这列的取值是我们指定的，而不是从数据表中动态取出的。 你可能会问为什么我们还要对常数进行查询呢？ SQL 中的 SELECT 语法的确提供了这个功能，一般来说我们只从一个表中查询数据，通常不需要增加一个固定的常数列，但如果我们想整合不同的数据源，用常数列作为这个表的标记，就需要查询常数。 比如说，我们想对 employees 数据表中的员工姓名进行查询，同时增加一列字段corporation，这个字段固定值为“尚硅谷”，可以这样写： SELECT '尚硅谷' as corporation, last_name FROM employees; 4. 显示表结构使用DESCRIBE 或 DESC 命令，表示表结构。 DESCRIBE employees; 或 DESC employees; mysql&gt; desc employees; +----------------+-------------+------+-----+---------+-------+ | Field | Type | Null | Key | Default | Extra | +----------------+-------------+------+-----+---------+-------+ | employee_id | int(6) | NO | PRI | 0 | | | first_name | varchar(20) | YES | | NULL | | | last_name | varchar(25) | NO | | NULL | | | email | varchar(25) | NO | UNI | NULL | | | phone_number | varchar(20) | YES | | NULL | | | hire_date | date | NO | | NULL | | | job_id | varchar(10) | NO | MUL | NULL | | | salary | double(8,2) | YES | | NULL | | | commission_pct | double(2,2) | YES | | NULL | | | manager_id | int(6) | YES | MUL | NULL | | | department_id | int(4) | YES | MUL | NULL | | +----------------+-------------+------+-----+---------+-------+ 11 rows in set (0.00 sec) 其中，各个字段的含义分别解释如下： Field：表示字段名称。 Type：表示字段类型，这里 barcode、goodsname 是文本型的，price 是整数类型的。 Null：表示该列是否可以存储NULL值。 Key：表示该列是否已编制索引。PRI表示该列是表主键的一部分；UNI表示该列是UNIQUE索引的一部分；MUL表示在列中某个给定值允许出现多次。 Default：表示该列是否有默认值，如果有，那么值是多少。 Extra：表示可以获取的与给定列有关的附加信息，例如AUTO_INCREMENT等。 5. 过滤数据 背景： 语法： SELECT 字段1,字段2 FROM 表名 WHERE 过滤条件 使用WHERE 子句，将不满足条件的行过滤掉 WHERE子句紧随 FROM子句 举例 SELECT employee_id, last_name, job_id, department_id FROM employees WHERE department_id = 90 ;","categories":[{"name":"Mysql基础篇","slug":"Mysql基础篇","permalink":"https://bowonqin.github.io/categories/Mysql%E5%9F%BA%E7%A1%80%E7%AF%87/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"https://bowonqin.github.io/tags/Mysql/"},{"name":"数据库","slug":"数据库","permalink":"https://bowonqin.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"author":"qxd"},{"title":"Mysql(MySQL环境搭建)","slug":"mysql/第02章-MySQL环境搭建","date":"2021-12-20T05:38:51.000Z","updated":"2021-12-21T09:44:23.720Z","comments":true,"path":"posts/mysql2.html","link":"","permalink":"https://bowonqin.github.io/posts/mysql2.html","excerpt":"","text":"第02章_MySQL环境搭建康师傅（宋红康老师）听课笔记 BILIBILI听课网址：[宋红康]MySQL数据库（安装/基础/高级/优化）_哔哩哔哩_bilibili 1. MySQL的卸载步骤1：停止MySQL服务在卸载之前，先停止MySQL8.0的服务。按键盘上的“Ctrl + Alt + Delete”组合键，打开“任务管理器”对话框，可以在“服务”列表找到“MySQL8.0”的服务，如果现在“正在运行”状态，可以右键单击服务，选择“停止”选项停止MySQL8.0的服务，如图所示。 步骤2：软件的卸载方式1：通过控制面板方式 卸载MySQL8.0的程序可以和其他桌面应用程序一样直接在“控制面板”选择“卸载程序”，并在程序列表中找到MySQL8.0服务器程序，直接双击卸载即可，如图所示。这种方式删除，数据目录下的数据不会跟着删除。 方式2：通过360或电脑管家等软件卸载 略 方式3：通过安装包提供的卸载功能卸载 你也可以通过安装向导程序进行MySQL8.0服务器程序的卸载。 ① 再次双击下载的mysql-installer-community-8.0.26.0.msi文件，打开安装向导。安装向导会自动检测已安装的MySQL服务器程序。 ② 选择要卸载的MySQL服务器程序，单击“Remove”（移除），即可进行卸载。 ③ 单击“Next”（下一步）按钮，确认卸载。 ④ 弹出是否同时移除数据目录选择窗口。如果想要同时删除MySQL服务器中的数据，则勾选“Remove the data directory”，如图所示。 ⑤ 执行卸载。单击“Execute”（执行）按钮进行卸载。 ⑥ 完成卸载。单击“Finish”（完成）按钮即可。如果想要同时卸载MySQL8.0的安装向导程序，勾选“Yes，Uninstall MySQL Installer”即可，如图所示。 步骤3：残余文件的清理如果再次安装不成功，可以卸载后对残余文件进行清理后再安装。 （1）服务目录：mysql服务的安装目录 （2）数据目录：默认在C:\\ProgramData\\MySQL 如果自己单独指定过数据目录，就找到自己的数据目录进行删除即可。 注意：请在卸载前做好数据备份 在操作完以后，需要重启计算机，然后进行安装即可。如果仍然安装失败，需要继续操作如下步骤4。 步骤4：清理注册表（选做）如果前几步做了，再次安装还是失败，那么可以清理注册表。 如何打开注册表编辑器：在系统的搜索框中输入regedit HKEY_LOCAL_MACHINE\\SYSTEM\\ControlSet001\\Services\\Eventlog\\Application\\MySQL服务 目录删除 HKEY_LOCAL_MACHINE\\SYSTEM\\ControlSet001\\Services\\MySQL服务 目录删除 HKEY_LOCAL_MACHINE\\SYSTEM\\ControlSet002\\Services\\Eventlog\\Application\\MySQL服务 目录删除 HKEY_LOCAL_MACHINE\\SYSTEM\\ControlSet002\\Services\\MySQL服务 目录删除 HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Services\\Eventlog\\Application\\MySQL服务目录删除 HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Services\\MySQL服务删除 注册表中的ControlSet001,ControlSet002,不一定是001和002,可能是ControlSet005、006之类 步骤5：删除环境变量配置找到path环境变量，将其中关于mysql的环境变量删除，切记不要全部删除。 例如：删除 D:\\develop_tools\\mysql\\MySQLServer8.0.26\\bin; 这个部分 2. MySQL的下载、安装、配置2.1 MySQL的4大版本 MySQL Community Server 社区版本，开源免费，自由下载，但不提供官方技术支持，适用于大多数普通用户。 MySQL Enterprise Edition 企业版本，需付费，不能在线下载，可以试用30天。提供了更多的功能和更完备的技术支持，更适合于对数据库的功能和可靠性要求较高的企业客户。 MySQL Cluster 集群版，开源免费。用于架设集群服务器，可将几个MySQL Server封装成一个Server。需要在社区版或企业版的基础上使用。 MySQL Cluster CGE 高级集群版，需付费。 目前最新版本为8.0.27，发布时间2021年10月。此前，8.0.0 在 2016.9.12日就发布了。 本课程中使用8.0.26版本。 此外，官方还提供了MySQL Workbench（GUITOOL）一款专为MySQL设计的图形界面管理工具。MySQLWorkbench又分为两个版本，分别是社区版（MySQL Workbench OSS）、商用版（MySQL WorkbenchSE）。 2.2 软件的下载1. 下载地址 官网：https://www.mysql.com 2. 打开官网，点击DOWNLOADS 然后，点击MySQL Community(GPL) Downloads 3. 点击 MySQL Community Server 4. 在General Availability(GA) Releases中选择适合的版本 Windows平台下提供两种安装文件：MySQL二进制分发版（.msi安装文件）和免安装版（.zip压缩文件）。一般来讲，应当使用二进制分发版，因为该版本提供了图形化的安装向导过程，比其他的分发版使用起来要简单，不再需要其他工具启动就可以运行MySQL。 这里在Windows 系统下推荐下载MSI安装程序；点击Go to Download Page进行下载即可 Windows下的MySQL8.0安装有两种安装程序 mysql-installer-web-community-8.0.26.0.msi 下载程序大小：2.4M；安装时需要联网安装组件。 mysql-installer-community-8.0.26.0.msi 下载程序大小：450.7M；安装时离线安装即可。推荐。 如果安装MySQL5.7版本的话，选择Archives，接着选择MySQL5.7的相应版本即可。这里下载最近期的MySQL5.7.34版本。 2.3 MySQL8.0 版本的安装MySQL下载完成后，找到下载文件，双击进行安装，具体操作步骤如下。 步骤1：双击下载的mysql-installer-community-8.0.26.0.msi文件，打开安装向导。 步骤2：打开“Choosing a Setup Type”（选择安装类型）窗口，在其中列出了5种安装类型，分别是Developer Default（默认安装类型）、Server only（仅作为服务器）、Client only（仅作为客户端）、Full（完全安装）、Custom（自定义安装）。这里选择“Custom（自定义安装）”类型按钮，单击“Next(下一步)”按钮。 步骤3：打开“Select Products” （选择产品）窗口，可以定制需要安装的产品清单。例如，选择“MySQL Server 8.0.26-X64”后，单击“→”添加按钮，即可选择安装MySQL服务器，如图所示。采用通用的方法，可以添加其他你需要安装的产品。 此时如果直接“Next”（下一步），则产品的安装路径是默认的。如果想要自定义安装目录，则可以选中对应的产品，然后在下面会出现“Advanced Options”（高级选项）的超链接。 单击“Advanced Options”（高级选项）则会弹出安装目录的选择窗口，如图所示，此时你可以分别设置MySQL的服务程序安装目录和数据存储目录。如果不设置，默认分别在C盘的Program Files目录和ProgramData目录（这是一个隐藏目录）。如果自定义安装目录，请避免“中文”目录。另外，建议服务目录和数据目录分开存放。 步骤4：在上一步选择好要安装的产品之后，单击“Next”（下一步）进入确认窗口，如图所示。单击“Execute”（执行）按钮开始安装。 步骤5：安装完成后在“Status”（状态）列表下将显示“Complete”（安装完成），如图所示。 2.4 配置MySQL8.0MySQL安装之后，需要对服务器进行配置。具体的配置步骤如下。 步骤1：在上一个小节的最后一步，单击“Next”（下一步）按钮，就可以进入产品配置窗口。 步骤2：单击“Next”（下一步）按钮，进入MySQL服务器类型配置窗口，如图所示。端口号一般选择默认端口号3306。 其中，“Config Type”选项用于设置服务器的类型。单击该选项右侧的下三角按钮，即可查看3个选项，如图所示。 Development Machine（开发机器）：该选项代表典型个人用桌面工作站。此时机器上需要运行多个应用程序，那么MySQL服务器将占用最少的系统资源。 Server Machine（服务器）：该选项代表服务器，MySQL服务器可以同其他服务器应用程序一起运行，例如Web服务器等。MySQL服务器配置成适当比例的系统资源。 Dedicated Machine（专用服务器）：该选项代表只运行MySQL服务的服务器。MySQL服务器配置成使用所有可用系统资源。 步骤3：单击“Next”（下一步）按钮，打开设置授权方式窗口。其中，上面的选项是MySQL8.0提供的新的授权方式，采用SHA256基础的密码加密方法；下面的选项是传统授权方法（保留5.x版本兼容性）。 步骤4：单击“Next”（下一步）按钮，打开设置服务器root超级管理员的密码窗口，如图所示，需要输入两次同样的登录密码。也可以通过“Add User”添加其他用户，添加其他用户时，需要指定用户名、允许该用户名在哪台/哪些主机上登录，还可以指定用户角色等。此处暂不添加用户，用户管理在MySQL高级特性篇中讲解。 步骤5：单击“Next”（下一步）按钮，打开设置服务器名称窗口，如图所示。该服务名会出现在Windows服务列表中，也可以在命令行窗口中使用该服务名进行启动和停止服务。本书将服务名设置为“MySQL80”。如果希望开机自启动服务，也可以勾选“Start the MySQL Server at System Startup”选项（推荐）。 下面是选择以什么方式运行服务？可以选择“Standard System Account”(标准系统用户)或者“Custom User”(自定义用户)中的一个。这里推荐前者。 步骤6：单击“Next”（下一步）按钮，打开确认设置服务器窗口，单击“Execute”（执行）按钮。 步骤7：完成配置，如图所示。单击“Finish”（完成）按钮，即可完成服务器的配置。 步骤8：如果还有其他产品需要配置，可以选择其他产品，然后继续配置。如果没有，直接选择“Next”（下一步），直接完成整个安装和配置过程。 步骤9：结束安装和配置。 2.5 配置MySQL8.0 环境变量如果不配置MySQL环境变量，就不能在命令行直接输入MySQL登录命令。下面说如何配置MySQL的环境变量： 步骤1：在桌面上右击【此电脑】图标，在弹出的快捷菜单中选择【属性】菜单命令。步骤2：打开【系统】窗口，单击【高级系统设置】链接。步骤3：打开【系统属性】对话框，选择【高级】选项卡，然后单击【环境变量】按钮。步骤4：打开【环境变量】对话框，在系统变量列表中选择path变量。步骤5：单击【编辑】按钮，在【编辑环境变量】对话框中，将MySQL应用程序的bin目录（C:\\Program Files\\MySQL\\MySQL Server 8.0\\bin）添加到变量值中，用分号将其与其他路径分隔开。步骤6：添加完成之后，单击【确定】按钮，这样就完成了配置path变量的操作，然后就可以直接输入MySQL命令来登录数据库了。 2.6 MySQL5.7 版本的安装、配置 安装 此版本的安装过程与上述过程除了版本号不同之外，其它环节都是相同的。所以这里省略了MySQL5.7.34版本的安装截图。 配置 配置环节与MySQL8.0版本确有细微不同。大部分情况下直接选择“Next”即可，不影响整理使用。 这里配置MySQL5.7时，重点强调：与前面安装好的MySQL8.0不能使用相同的端口号。 2.7 安装失败问题MySQL的安装和配置是一件非常简单的事，但是在操作过程中也可能出现问题，特别是初学者。 问题1：无法打开MySQL8.0软件安装包或者安装过程中失败，如何解决？ 在运行MySQL8.0软件安装包之前，用户需要确保系统中已经安装了.Net Framework相关软件，如果缺少此软件，将不能正常地安装MySQL8.0软件。 解决方案：到这个地址https://www.microsoft.com/en-us/download/details.aspx?id=42642下载Microsoft .NET Framework 4.5并安装后，再去安装MySQL。 另外，还要确保Windows Installer正常安装。windows上安装mysql8.0需要操作系统提前已安装好Microsoft Visual C++ 2015-2019。 解决方案同样是，提前到微软官网https://support.microsoft.com/en-us/topic/the-latest-supported-visual-c-downloads-2647da03-1eea-4433-9aff-95f26a218cc0，下载相应的环境。 问题2：卸载重装MySQL失败？ 该问题通常是因为MySQL卸载时，没有完全清除相关信息导致的。 解决办法是，把以前的安装目录删除。如果之前安装并未单独指定过服务安装目录，则默认安装目录是“C:\\Program Files\\MySQL”，彻底删除该目录。同时删除MySQL的Data目录，如果之前安装并未单独指定过数据目录，则默认安装目录是“C:\\ProgramData\\MySQL”，该目录一般为隐藏目录。删除后，重新安装即可。 问题3：如何在Windows系统删除之前的未卸载干净的MySQL服务列表？ 操作方法如下，在系统“搜索框”中输入“cmd”，按“Enter”（回车）键确认，弹出命令提示符界面。然后输入“sc delete MySQL服务名”,按“Enter”（回车）键，就能彻底删除残余的MySQL服务了。 3. MySQL的登录3.1 服务的启动与停止MySQL安装完毕之后，需要启动服务器进程，不然客户端无法连接数据库。 在前面的配置过程中，已经将MySQL安装为Windows服务，并且勾选当Windows启动、停止时，MySQL也自动启动、停止。 方式1：使用图形界面工具 步骤1：打开windows服务 方式1：计算机（点击鼠标右键）→ 管理（点击）→ 服务和应用程序（点击）→ 服务（点击） 方式2：控制面板（点击）→ 系统和安全（点击）→ 管理工具（点击）→ 服务（点击） 方式3：任务栏（点击鼠标右键）→ 启动任务管理器（点击）→ 服务（点击） 方式4：单击【开始】菜单，在搜索框中输入“services.msc”，按Enter键确认 步骤2：找到MySQL80（点击鼠标右键）→ 启动或停止（点击） 方式2：使用命令行工具# 启动 MySQL 服务命令： net start MySQL服务名 # 停止 MySQL 服务命令： net stop MySQL服务名 说明： start和stop后面的服务名应与之前配置时指定的服务名一致。 如果当你输入命令后，提示“拒绝服务”，请以系统管理员身份打开命令提示符界面重新尝试。 3.2 自带客户端的登录与退出当MySQL服务启动完成后，便可以通过客户端来登录MySQL数据库。注意：确认服务是开启的。 登录方式1：MySQL自带客户端开始菜单 → 所有程序 → MySQL → MySQL 8.0 Command Line Client 说明：仅限于root用户 登录方式2：windows命令行 格式： mysql -h 主机名 -P 端口号 -u 用户名 -p密码 举例： mysql -h localhost -P 3306 -u root -pabc123 # 这里我设置的root用户的密码是abc123 注意： （1）-p与密码之间不能有空格，其他参数名与参数值之间可以有空格也可以没有空格。如： mysql -hlocalhost -P3306 -uroot -pabc123 （2）密码建议在下一行输入，保证安全 mysql -h localhost -P 3306 -u root -p Enter password:**** （3）客户端和服务器在同一台机器上，所以输入localhost或者IP地址127.0.0.1。同时，因为是连接本机：-hlocalhost就可以省略，如果端口号没有修改：-P3306也可以省略 简写成： mysql -u root -p Enter password:**** 连接成功后，有关于MySQL Server服务版本的信息，还有第几次连接的id标识。 也可以在命令行通过以下方式获取MySQL Server服务版本的信息： c:\\&gt; mysql -V c:\\&gt; mysql --version 或登录后，通过以下方式查看当前版本信息： mysql&gt; select version(); 退出登录exit 或 quit 4. MySQL演示使用4.1 MySQL的使用演示1、查看所有的数据库 show databases; “information_schema”是 MySQL 系统自带的数据库，主要保存 MySQL 数据库服务器的系统信息，比如数据库的名称、数据表的名称、字段名称、存取权限、数据文件 所在的文件夹和系统使用的文件夹，等等 “performance_schema”是 MySQL 系统自带的数据库，可以用来监控 MySQL 的各类性能指标。 “sys”数据库是 MySQL 系统自带的数据库，主要作用是以一种更容易被理解的方式展示 MySQL 数据库服务器的各类性能指标，帮助系统管理员和开发人员监控 MySQL 的技术性能。 “mysql”数据库保存了 MySQL 数据库服务器运行时需要的系统信息，比如数据文件夹、当前使用的字符集、约束检查信息，等等 为什么 Workbench 里面我们只能看到“demo”和“sys”这 2 个数据库呢？ 这是因为，Workbench 是图形化的管理工具，主要面向开发人 员，“demo”和“sys”这 2 个数据库已经够用了。如果有特殊需求，比如，需要监控 MySQL 数据库各项性能指标、直接操作 MySQL 数据库系统文件等，可以由 DBA 通过 SQL 语句，查看其它的系统数据库。 2、创建自己的数据库 create database 数据库名; #创建atguigudb数据库，该名称不能与已经存在的数据库重名。 create database atguigudb; 3、使用自己的数据库 use 数据库名; #使用atguigudb数据库 use atguigudb; 说明：如果没有使用use语句，后面针对数据库的操作也没有加“数据名”的限定，那么会报“ERROR 1046 (3D000): No database selected”（没有选择数据库） 使用完use语句之后，如果接下来的SQL都是针对一个数据库操作的，那就不用重复use了，如果要针对另一个数据库操作，那么要重新use。 4、查看某个库的所有表格 show tables; #要求前面有use语句 show tables from 数据库名; 5、创建新的表格 create table 表名称( 字段名 数据类型, 字段名 数据类型 ); 说明：如果是最后一个字段，后面就用加逗号，因为逗号的作用是分割每个字段。 #创建学生表 create table student( id int, name varchar(20) #说名字最长不超过20个字符 ); 6、查看一个表的数据 select * from 数据库表名称; #查看学生表的数据 select * from student; 7、添加一条记录 insert into 表名称 values(值列表); #添加两条记录到student表中 insert into student values(1,'张三'); insert into student values(2,'李四'); 报错： mysql&gt; insert into student values(1,'张三'); ERROR 1366 (HY000): Incorrect string value: '\\xD5\\xC5\\xC8\\xFD' for column 'name' at row 1 mysql&gt; insert into student values(2,'李四'); ERROR 1366 (HY000): Incorrect string value: '\\xC0\\xEE\\xCB\\xC4' for column 'name' at row 1 mysql&gt; show create table student; 字符集的问题。 8、查看表的创建信息 show create table 表名称\\G #查看student表的详细创建信息 show create table student\\G #结果如下 *************************** 1. row *************************** Table: student Create Table: CREATE TABLE `student` ( `id` int(11) DEFAULT NULL, `name` varchar(20) DEFAULT NULL ) ENGINE=InnoDB DEFAULT CHARSET=latin1 1 row in set (0.00 sec) 上面的结果显示student的表格的默认字符集是“latin1”不支持中文。 9、查看数据库的创建信息 show create database 数据库名\\G #查看atguigudb数据库的详细创建信息 show create database atguigudb\\G #结果如下 *************************** 1. row *************************** Database: atguigudb Create Database: CREATE DATABASE `atguigudb` /*!40100 DEFAULT CHARACTER SET latin1 */ 1 row in set (0.00 sec) 上面的结果显示atguigudb数据库也不支持中文，字符集默认是latin1。 10、删除表格 drop table 表名称; #删除学生表 drop table student; 11、删除数据库 drop database 数据库名; #删除atguigudb数据库 drop database atguigudb; 4.2 MySQL的编码设置MySQL5.7中问题再现：命令行操作sql乱码问题 mysql&gt; INSERT INTO t_stu VALUES(1,'张三','男'); ERROR 1366 (HY000): Incorrect string value: '\\xD5\\xC5\\xC8\\xFD' for column 'sname' at row 1 问题解决 步骤1：查看编码命令 show variables like 'character_%'; show variables like 'collation_%'; 步骤2：修改mysql的数据目录下的my.ini配置文件 [mysql] #大概在63行左右，在其下添加 ... default-character-set=utf8 #默认字符集 [mysqld] # 大概在76行左右，在其下添加 ... character-set-server=utf8 collation-server=utf8_general_ci 注意：建议修改配置文件使用notepad++等高级文本编辑器，使用记事本等软件打开修改后可能会导致文件编码修改为“含BOM头”的编码，从而服务重启失败。 步骤3：重启服务 步骤4：查看编码命令 show variables like 'character_%'; show variables like 'collation_%'; 如果是以上配置就说明对了。接着我们就可以新创建数据库、新创建数据表，接着添加包含中文的数据了。 MySQL8.0中在MySQL 8.0版本之前，默认字符集为latin1，utf8字符集指向的是utf8mb3。网站开发人员在数据库设计的时候往往会将编码修改为utf8字符集。如果遗忘修改默认的编码，就会出现乱码的问题。从MySQL 8.0开始，数据库的默认编码改为utf8mb4，从而避免了上述的乱码问题。 5. MySQL图形化管理工具MySQL图形化管理工具极大地方便了数据库的操作与管理，常用的图形化管理工具有：MySQL Workbench、phpMyAdmin、Navicat Preminum、MySQLDumper、SQLyog、dbeaver、MySQL ODBC Connector。 工具1. MySQL WorkbenchMySQL官方提供的图形化管理工具MySQL Workbench完全支持MySQL 5.0以上的版本。MySQL Workbench分为社区版和商业版，社区版完全免费，而商业版则是按年收费。 MySQL Workbench 为数据库管理员、程序开发者和系统规划师提供可视化设计、模型建立、以及数据库管理功能。它包含了用于创建复杂的数据建模ER模型，正向和逆向数据库工程，也可以用于执行通常需要花费大量时间的、难以变更和管理的文档任务。 下载地址：http://dev.mysql.com/downloads/workbench/。 使用： 首先，我们点击 Windows 左下角的“开始”按钮，如果你是 Win10 系统，可以直接看到所有程序。接着，找到“MySQL”，点开，找到“MySQL Workbench 8.0 CE”。点击打开 Workbench，如下图所示： 左下角有个本地连接，点击，录入 Root 的密码，登录本地 MySQL 数据库服务器，如下图所示： 这是一个图形化的界面，我来给你介绍下这个界面。 上方是菜单。左上方是导航栏，这里我们可以看到 MySQL 数据库服务器里面的数据 库，包括数据表、视图、存储过程和函数；左下方是信息栏，可以显示上方选中的数据 库、数据表等对象的信息。 中间上方是工作区，你可以在这里写 SQL 语句，点击上方菜单栏左边的第三个运行按 钮，就可以执行工作区的 SQL 语句了。 中间下方是输出区，用来显示 SQL 语句的运行情况，包括什么时间开始运行的、运行的 内容、运行的输出，以及所花费的时长等信息。 好了，下面我们就用 Workbench 实际创建一个数据库，并且导入一个 Excel 数据文件， 来生成一个数据表。数据表是存储数据的载体，有了数据表以后，我们就能对数据进行操作了。 工具2. NavicatNavicat MySQL是一个强大的MySQL数据库服务器管理和开发工具。它可以与任何3.21或以上版本的MySQL一起工作，支持触发器、存储过程、函数、事件、视图、管理用户等，对于新手来说易学易用。其精心设计的图形用户界面（GUI）可以让用户用一种安全简便的方式来快速方便地创建、组织、访问和共享信息。Navicat支持中文，有免费版本提供。下载地址：http://www.navicat.com/。 工具3. SQLyogSQLyog 是业界著名的 Webyog 公司出品的一款简洁高效、功能强大的图形化 MySQL 数据库管理工具。这款工具是使用C++语言开发的。该工具可以方便地创建数据库、表、视图和索引等，还可以方便地进行插入、更新和删除等操作，同时可以方便地进行数据库、数据表的备份和还原。该工具不仅可以通过SQL文件进行大量文件的导入和导出，还可以导入和导出XML、HTML和CSV等多种格式的数据。下载地址：http://www.webyog.com/，读者也可以搜索中文版的下载地址。 工具4：dbeaverDBeaver是一个通用的数据库管理工具和 SQL 客户端，支持所有流行的数据库：MySQL、PostgreSQL、SQLite、Oracle、DB2、SQL Server、 Sybase、MS Access、Teradata、 Firebird、Apache Hive、Phoenix、Presto等。DBeaver比大多数的SQL管理工具要轻量，而且支持中文界面。DBeaver社区版作为一个免费开源的产品，和其他类似的软件相比，在功能和易用性上都毫不逊色。 唯一需要注意是 DBeaver 是用Java编程语言开发的，所以需要拥有 JDK（Java Development ToolKit）环境。如果电脑上没有JDK，在选择安装DBeaver组件时，勾选“Include Java”即可。 下载地址：https://dbeaver.io/download/ 可能出现连接问题：有些图形界面工具，特别是旧版本的图形界面工具，在连接MySQL8时出现“Authentication plugin ‘caching_sha2_password’ cannot be loaded”错误。 出现这个原因是MySQL8之前的版本中加密规则是mysql_native_password，而在MySQL8之后，加密规则是caching_sha2_password。解决问题方法有两种，第一种是升级图形界面工具版本，第二种是把MySQL8用户登录密码加密规则还原成mysql_native_password。 第二种解决方案如下，用命令行登录MySQL数据库之后，执行如下命令修改用户密码加密规则并更新用户密码，这里修改用户名为“root@localhost”的用户密码规则为“mysql_native_password”，密码值为“123456”，如图所示。 #使用mysql数据库 USE mysql; #修改'root'@'localhost'用户的密码规则和密码 ALTER USER 'root'@'localhost' IDENTIFIED WITH mysql_native_password BY 'abc123'; #刷新权限 FLUSH PRIVILEGES; 6. MySQL目录结构与源码6.1 主要目录结构 MySQL的目录结构 说明 bin目录 所有MySQL的可执行文件。如：mysql.exe MySQLInstanceConfig.exe 数据库的配置向导，在安装时出现的内容 data目录 系统数据库所在的目录 my.ini文件 MySQL的主要配置文件 c:\\ProgramData\\MySQL\\MySQL Server 8.0\\data\\ 用户创建的数据库所在的目录 6.2 MySQL 源代码获取首先，你要进入 MySQL下载界面。 这里你不要选择用默认的“Microsoft Windows”，而是要通过下拉栏，找到“Source Code”，在下面的操作系统版本里面， 选择 Windows（Architecture Independent），然后点击下载。 接下来，把下载下来的压缩文件解压，我们就得到了 MySQL 的源代码。 MySQL 是用 C++ 开发而成的，我简单介绍一下源代码的组成。 mysql-8.0.22 目录下的各个子目录，包含了 MySQL 各部分组件的源代码： sql 子目录是 MySQL 核心代码； libmysql 子目录是客户端程序 API； mysql-test 子目录是测试工具； mysys 子目录是操作系统相关函数和辅助函数； 源代码可以用记事本打开查看，如果你有 C++ 的开发环境，也可以在开发环境中打开查看。 如上图所示，源代码并不神秘，就是普通的 C++ 代码，跟你熟悉的一样，而且有很多注释，可以帮助你理解。阅读源代码就像在跟 MySQL 的开发人员对话一样，十分有趣。 7. 常见问题的解决(课外内容)问题1：root用户密码忘记，重置的操作1: 通过任务管理器或者服务管理，关掉mysqld(服务进程)2: 通过命令行+特殊参数开启mysqldmysqld –defaults-file=”D:\\ProgramFiles\\mysql\\MySQLServer5.7Data\\my.ini” –skip-grant-tables 3: 此时，mysqld服务进程已经打开。并且不需要权限检查4: mysql -uroot 无密码登陆服务器。另启动一个客户端进行5: 修改权限表（1） use mysql;（2）update user set authentication_string=password(‘新密码’) where user=’root’ and Host=’localhost’;（3）flush privileges;6: 通过任务管理器，关掉mysqld服务进程。7: 再次通过服务管理，打开mysql服务。8: 即可用修改后的新密码登陆。 问题2：mysql命令报“不是内部或外部命令”如果输入mysql命令报“不是内部或外部命令”，把mysql安装目录的bin目录配置到环境变量path中。如下： 问题3：错误ERROR ：没有选择数据库就操作表格和数据 ERROR 1046 (3D000): No database selected 解决方案一：就是使用“USE 数据库名;”语句，这样接下来的语句就默认针对这个数据库进行操作 解决方案二：就是所有的表对象前面都加上“数据库.” 问题4：命令行客户端的字符集问题mysql&gt; INSERT INTO t_stu VALUES(1,'张三','男'); ERROR 1366 (HY000): Incorrect string value: '\\xD5\\xC5\\xC8\\xFD' for column 'sname' at row 1 原因：服务器端认为你的客户端的字符集是utf-8，而实际上你的客户端的字符集是GBK。 查看所有字符集：SHOW VARIABLES LIKE ‘character_set_%’; 解决方案，设置当前连接的客户端字符集 “SET NAMES GBK;” 问题5：修改数据库和表的字符编码修改编码： （1)先停止服务，（2）修改my.ini文件（3）重新启动服务 说明： 如果是在修改my.ini之前建的库和表，那么库和表的编码还是原来的Latin1，要么删了重建，要么使用alter语句修改编码。 mysql&gt; create database 0728db charset Latin1; Query OK, 1 row affected (0.00 sec) mysql&gt; use 0728db; Database changed mysql&gt; create table student (id int , name varchar(20)) charset Latin1; Query OK, 0 rows affected (0.02 sec) mysql&gt; show create table student\\G *************************** 1. row *************************** Table: student Create Table: CREATE TABLE `student` ( `id` int(11) NOT NULL, `name` varchar(20) DEFAULT NULL, PRIMARY KEY (`id`) ) ENGINE=InnoDB DEFAULT CHARSET=latin1 1 row in set (0.00 sec) mysql&gt; alter table student charset utf8; #修改表字符编码为UTF8 Query OK, 0 rows affected (0.01 sec) Records: 0 Duplicates: 0 Warnings: 0 mysql&gt; show create table student\\G *************************** 1. row *************************** Table: student Create Table: CREATE TABLE `student` ( `id` int(11) NOT NULL, `name` varchar(20) CHARACTER SET latin1 DEFAULT NULL, #字段仍然是latin1编码 PRIMARY KEY (`id`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8 1 row in set (0.00 sec) mysql&gt; alter table student modify name varchar(20) charset utf8; #修改字段字符编码为UTF8 Query OK, 0 rows affected (0.05 sec) Records: 0 Duplicates: 0 Warnings: 0 mysql&gt; show create table student\\G *************************** 1. row *************************** Table: student Create Table: CREATE TABLE `student` ( `id` int(11) NOT NULL, `name` varchar(20) DEFAULT NULL, PRIMARY KEY (`id`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8 1 row in set (0.00 sec) mysql&gt; show create database 0728db;; +--------+-----------------------------------------------------------------+ |Database| Create Database | +------+-------------------------------------------------------------------+ |0728db| CREATE DATABASE `0728db` /*!40100 DEFAULT CHARACTER SET latin1 */ | +------+-------------------------------------------------------------------+ 1 row in set (0.00 sec) mysql&gt; alter database 0728db charset utf8; #修改数据库的字符编码为utf8 Query OK, 1 row affected (0.00 sec) mysql&gt; show create database 0728db; +--------+-----------------------------------------------------------------+ |Database| Create Database | +--------+-----------------------------------------------------------------+ | 0728db | CREATE DATABASE `0728db` /*!40100 DEFAULT CHARACTER SET utf8 */ | +--------+-----------------------------------------------------------------+ 1 row in set (0.00 sec)","categories":[{"name":"Mysql基础篇","slug":"Mysql基础篇","permalink":"https://bowonqin.github.io/categories/Mysql%E5%9F%BA%E7%A1%80%E7%AF%87/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"https://bowonqin.github.io/tags/Mysql/"},{"name":"数据库","slug":"数据库","permalink":"https://bowonqin.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"author":"qxd"},{"title":"Mysql(数据库概述)","slug":"mysql/第01章_数据库概述","date":"2021-12-18T16:00:00.000Z","updated":"2021-12-21T03:29:34.463Z","comments":true,"path":"posts/18293.html","link":"","permalink":"https://bowonqin.github.io/posts/18293.html","excerpt":"","text":"第01章_数据库概述康师傅（宋红康老师）听课笔记 BILIBILI听课网址：[宋红康]MySQL数据库（安装/基础/高级/优化）_哔哩哔哩_bilibili 1. 为什么要使用数据库 持久化(persistence)：把数据保存到可掉电式存储设备中以供之后使用。大多数情况下，特别是企业级应用，数据持久化意味着将内存中的数据保存到硬盘上加以”固化”，而持久化的实现过程大多通过各种关系数据库来完成。 持久化的主要作用是将内存中的数据存储在关系型数据库中，当然也可以存储在磁盘文件、XML数据文件中。 生活中的例子： 2. 数据库与数据库管理系统2.1 数据库的相关概念 DB：数据库（Database） 即存储数据的“仓库”，其本质是一个文件系统。它保存了一系列有组织的数据。 DBMS：数据库管理系统（Database Management System） 是一种操纵和管理数据库的大型软件，用于建立、使用和维护数据库，对数据库进行统一管理和控制。用户通过数据库管理系统访问数据库中表内的数据。 SQL：结构化查询语言（Structured Query Language） 专门用来与数据库通信的语言。 2.2 数据库与数据库管理系统的关系数据库管理系统(DBMS)可以管理多个数据库，一般开发人员会针对每一个应用创建一个数据库。为保存应用中实体的数据，一般会在数据库创建多个表，以保存程序中实体用户的数据。 数据库管理系统、数据库和表的关系如图所示： 2.3 常见的数据库管理系统排名(DBMS)目前互联网上常见的数据库管理软件有Oracle、MySQL、MS SQL Server、DB2、PostgreSQL、Access、Sybase、Informix这几种。以下是2021年DB-Engines Ranking 对各数据库受欢迎程度进行调查后的统计结果：（查看数据库最新排名:https://db-engines.com/en/ranking） 对应的走势图：（https://db-engines.com/en/ranking_trend） 2.4 常见的数据库介绍Oracle 1979 年，Oracle 2 诞生，它是第一个商用的 RDBMS（关系型数据库管理系统）。随着 Oracle 软件的名气越来越大，公司也改名叫 Oracle 公司。 2007年，总计85亿美金收购BEA Systems。 2009年，总计74亿美金收购SUN。此前的2008年，SUN以10亿美金收购MySQL。意味着Oracle 同时拥有了 MySQL 的管理权，至此 Oracle 在数据库领域中成为绝对的领导者。 2013年，甲骨文超越IBM，成为继Microsoft后全球第二大软件公司。 如今 Oracle 的年收入达到了 400 亿美金，足以证明商用（收费）数据库软件的价值。 SQL Server SQL Server 是微软开发的大型商业数据库，诞生于 1989 年。C#、.net等语言常使用，与WinNT完全集成，也可以很好地与Microsoft BackOffice产品集成。 DB2 IBM公司的数据库产品,收费的。常应用在银行系统中。 PostgreSQL PostgreSQL 的稳定性极强，最符合SQL标准，开放源码，具备商业级DBMS质量。PG对数据量大的文本以及SQL处理较快。 SyBase 已经淡出历史舞台。提供了一个非常专业数据建模的工具PowerDesigner。 SQLite 嵌入式的小型数据库，应用在手机端。 零配置，SQlite3不用安装，不用配置，不用启动，关闭或者配置数据库实例。当系统崩溃后不用做任何恢复操作，再下次使用数据库的时候自动恢复。 informix IBM公司出品，取自Information 和Unix的结合，它是第一个被移植到Linux上的商业数据库产品。仅运行于unix/linux平台，命令行操作。 性能较高，支持集群，适应于安全性要求极高的系统，尤其是银行，证券系统的应用。 3. MySQL介绍 3.1 概述 MySQL是一个开放源代码的关系型数据库管理系统，由瑞典MySQL AB（创始人Michael Widenius）公司1995年开发，迅速成为开源数据库的 No.1。 2008被Sun收购（10亿美金），2009年Sun被Oracle收购。MariaDB应运而生。（MySQL 的创造者担心 MySQL 有闭源的风险，因此创建了 MySQL 的分支项目 MariaDB） MySQL6.x 版本之后分为社区版和商业版。 MySQL是一种关联数据库管理系统，将数据保存在不同的表中，而不是将所有数据放在一个大仓库内，这样就增加了速度并提高了灵活性。 MySQL是开源的，所以你不需要支付额外的费用。 MySQL是可以定制的，采用了GPL（GNU General Public License）协议，你可以修改源码来开发自己的MySQL系统。 MySQL支持大型的数据库。可以处理拥有上千万条记录的大型数据库。 MySQL支持大型数据库，支持5000万条记录的数据仓库，32位系统表文件最大可支持4GB，64位系统支持最大的表文件为8TB。 MySQL使用标准的SQL数据语言形式。 MySQL可以允许运行于多个系统上，并且支持多种语言。这些编程语言包括C、C++、Python、Java、Perl、PHP和Ruby等。 3.2 MySQL发展史重大事件MySQL的历史就是整个互联网的发展史。互联网业务从社交领域、电商领域到金融领域的发展，推动着应用对数据库的需求提升，对传统的数据库服务能力提出了挑战。高并发、高性能、高可用、轻资源、易维护、易扩展的需求，促进了MySQL的长足发展。 1.4 关于MySQL 8.0MySQL从5.7版本直接跳跃发布了8.0版本，可见这是一个令人兴奋的里程碑版本。MySQL 8版本在功能上做了显著的改进与增强，开发者对MySQL的源代码进行了重构，最突出的一点是多MySQL Optimizer优化器进行了改进。不仅在速度上得到了改善，还为用户带来了更好的性能和更棒的体验。 1.5 Why choose MySQL? 为什么如此多的厂商要选用MySQL？大概总结的原因主要有以下几点： 开放源代码，使用成本低。 性能卓越，服务稳定。 软件体积小，使用简单，并且易于维护。 历史悠久，社区用户非常活跃，遇到问题可以寻求帮助。 许多互联网公司在用，经过了时间的验证。 1.6 Oracle vs MySQLOracle 更适合大型跨国企业的使用，因为他们对费用不敏感，但是对性能要求以及安全性有更高的要求。 MySQL 由于其体积小、速度快、总体拥有成本低，可处理上千万条记录的大型数据库，尤其是开放源码这一特点，使得很多互联网公司、中小型网站选择了MySQL作为网站数据库（Facebook，Twitter，YouTube，阿里巴巴/蚂蚁金服，去哪儿，美团外卖，腾讯）。 4. RDBMS 与 非RDBMS从排名中我们能看出来，关系型数据库绝对是 DBMS 的主流，其中使用最多的 DBMS 分别是 Oracle、MySQL 和 SQL Server。这些都是关系型数据库（RDBMS）。 4.1 关系型数据库(RDBMS)4.1.1 实质 这种类型的数据库是最古老的数据库类型，关系型数据库模型是把复杂的数据结构归结为简单的二元关系（即二维表格形式）。 关系型数据库以行(row)和列(column)的形式存储数据，以便于用户理解。这一系列的行和列被称为表(table)，一组表组成了一个库(database)。 表与表之间的数据记录有关系(relationship)。现实世界中的各种实体以及实体之间的各种联系均用关系模型来表示。关系型数据库，就是建立在关系模型基础上的数据库。 SQL 就是关系型数据库的查询语言。 4.1.2 优势 复杂查询可以用SQL语句方便的在一个表以及多个表之间做非常复杂的数据查询。 事务支持使得对于安全性能很高的数据访问要求得以实现。 4.2 非关系型数据库(非RDBMS)4.2.1 介绍非关系型数据库，可看成传统关系型数据库的功能阉割版本，基于键值对存储数据，不需要经过SQL层的解析，性能非常高。同时，通过减少不常用的功能，进一步提高性能。 目前基本上大部分主流的非关系型数据库都是免费的。 4.2.2 有哪些非关系型数据库相比于 SQL，NoSQL 泛指非关系型数据库，包括了榜单上的键值型数据库、文档型数据库、搜索引擎和列存储等，除此以外还包括图形数据库。也只有用 NoSQL 一词才能将这些技术囊括进来。 键值型数据库 键值型数据库通过 Key-Value 键值的方式来存储数据，其中 Key 和 Value 可以是简单的对象，也可以是复杂的对象。Key 作为唯一的标识符，优点是查找速度快，在这方面明显优于关系型数据库，缺点是无法像关系型数据库一样使用条件过滤（比如 WHERE），如果你不知道去哪里找数据，就要遍历所有的键，这就会消耗大量的计算。 键值型数据库典型的使用场景是作为内存缓存。Redis 是最流行的键值型数据库。 文档型数据库 此类数据库可存放并获取文档，可以是XML、JSON等格式。在数据库中文档作为处理信息的基本单位，一个文档就相当于一条记录。文档数据库所存放的文档，就相当于键值数据库所存放的“值”。MongoDB 是最流行的文档型数据库。此外，还有CouchDB等。 搜索引擎数据库 虽然关系型数据库采用了索引提升检索效率，但是针对全文索引效率却较低。搜索引擎数据库是应用在搜索引擎领域的数据存储形式，由于搜索引擎会爬取大量的数据，并以特定的格式进行存储，这样在检索的时候才能保证性能最优。核心原理是“倒排索引”。 典型产品：Solr、Elasticsearch、Splunk 等。 列式数据库 列式数据库是相对于行式存储的数据库，Oracle、MySQL、SQL Server 等数据库都是采用的行式存储（Row-based），而列式数据库是将数据按照列存储到数据库中，这样做的好处是可以大量降低系统的 I/O，适合于分布式文件系统，不足在于功能相对有限。典型产品：HBase等。 图形数据库 图形数据库，利用了图这种数据结构存储了实体（对象）之间的关系。图形数据库最典型的例子就是社交网络中人与人的关系，数据模型主要是以节点和边（关系）来实现，特点在于能高效地解决复杂的关系问题。 图形数据库顾名思义，就是一种存储图形关系的数据库。它利用了图这种数据结构存储了实体（对象）之间的关系。关系型数据用于存储明确关系的数据，但对于复杂关系的数据存储却有些力不从心。如社交网络中人物之间的关系，如果用关系型数据库则非常复杂，用图形数据库将非常简单。典型产品：Neo4J、InfoGrid等。 4.2.3 NoSQL的演变由于 SQL 一直称霸 DBMS，因此许多人在思考是否有一种数据库技术能远离 SQL，于是 NoSQL 诞生了，但是随着发展却发现越来越离不开 SQL。到目前为止 NoSQL 阵营中的 DBMS 都会有实现类似 SQL 的功能。下面是“NoSQL”这个名词在不同时期的诠释，从这些释义的变化中可以看出 NoSQL 功能的演变： 1970：NoSQL = We have no SQL 1980：NoSQL = Know SQL 2000：NoSQL = No SQL! 2005：NoSQL = Not only SQL 2013：NoSQL = No, SQL! NoSQL 对 SQL 做出了很好的补充，比如实际开发中，有很多业务需求，其实并不需要完整的关系型数据库功能，非关系型数据库的功能就足够使用了。这种情况下，使用性能更高、成本更低的非关系型数据库当然是更明智的选择。比如：日志收集、排行榜、定时器等。 4.3 小结NoSQL 的分类很多，即便如此，在 DBMS 排名中，还是 SQL 阵营的比重更大，影响力前 5 的 DBMS 中有 4 个是关系型数据库，而排名前 20 的 DBMS 中也有 12 个是关系型数据库。所以说，掌握 SQL 是非常有必要的。整套课程将围绕 SQL 展开。 5. 关系型数据库设计规则 关系型数据库的典型数据结构就是数据表，这些数据表的组成都是结构化的（Structured）。 将数据放到表中，表再放到库中。 一个数据库中可以有多个表，每个表都有一个名字，用来标识自己。表名具有唯一性。 表具有一些特性，这些特性定义了数据在表中如何存储，类似Java和Python中 “类”的设计。 5.1 表、记录、字段 E-R（entity-relationship，实体-联系）模型中有三个主要概念是：实体集、属性、联系集。 一个实体集（class）对应于数据库中的一个表（table），一个实体（instance）则对应于数据库表中的一行（row），也称为一条记录（record）。一个属性（attribute）对应于数据库表中的一列（column），也称为一个字段（field）。 ORM思想 (Object Relational Mapping)体现： 数据库中的一个表 &lt;---&gt; Java或Python中的一个类 表中的一条数据 &lt;---&gt; 类中的一个对象（或实体） 表中的一个列 &lt;----&gt; 类中的一个字段、属性(field) 5.2 表的关联关系 表与表之间的数据记录有关系(relationship)。现实世界中的各种实体以及实体之间的各种联系均用关系模型来表示。 四种：一对一关联、一对多关联、多对多关联、自我引用 5.2.1 一对一关联（one-to-one） 在实际的开发中应用不多，因为一对一可以创建成一张表。 举例：设计学生表：学号、姓名、手机号码、班级、系别、身份证号码、家庭住址、籍贯、紧急联系人、… 拆为两个表：两个表的记录是一一对应关系。 基础信息表（常用信息）：学号、姓名、手机号码、班级、系别 档案信息表（不常用信息）：学号、身份证号码、家庭住址、籍贯、紧急联系人、… 两种建表原则： 外键唯一：主表的主键和从表的外键（唯一），形成主外键关系，外键唯一。 外键是主键：主表的主键和从表的主键，形成主外键关系。 5.2.2 一对多关系（one-to-many） 常见实例场景：客户表和订单表，分类表和商品表，部门表和员工表。 举例： 员工表：编号、姓名、…、所属部门 部门表：编号、名称、简介 一对多建表原则：在从表(多方)创建一个字段，字段作为外键指向主表(一方)的主键 5.2.3 多对多（many-to-many）要表示多对多关系，必须创建第三个表，该表通常称为联接表，它将多对多关系划分为两个一对多关系。将这两个表的主键都插入到第三个表中。 举例1：学生-课程 学生信息表：一行代表一个学生的信息（学号、姓名、手机号码、班级、系别…） 课程信息表：一行代表一个课程的信息（课程编号、授课老师、简介…） 选课信息表：一个学生可以选多门课，一门课可以被多个学生选择 学号 课程编号 1 1001 2 1001 1 1002 举例2：产品-订单 “订单”表和“产品”表有一种多对多的关系，这种关系是通过与“订单明细”表建立两个一对多关系来定义的。一个订单可以有多个产品，每个产品可以出现在多个订单中。 产品表：“产品”表中的每条记录表示一个产品。 订单表：“订单”表中的每条记录表示一个订单。 订单明细表：每个产品可以与“订单”表中的多条记录对应，即出现在多个订单中。一个订单可以与“产品”表中的多条记录对应，即包含多个产品。 举例3：用户-角色 多对多关系建表原则：需要创建第三张表，中间表中至少两个字段，这两个字段分别作为外键指向各自一方的主键。 5.3.4 自我引用(Self reference)","categories":[{"name":"Mysql基础篇","slug":"Mysql基础篇","permalink":"https://bowonqin.github.io/categories/Mysql%E5%9F%BA%E7%A1%80%E7%AF%87/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"https://bowonqin.github.io/tags/Mysql/"},{"name":"数据库","slug":"数据库","permalink":"https://bowonqin.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"author":"qxd"},{"title":"Mybatis(高级)","slug":"mybatis/Mybatis(高级)","date":"2021-12-18T16:00:00.000Z","updated":"2021-12-20T05:41:38.590Z","comments":true,"path":"posts/333222.html","link":"","permalink":"https://bowonqin.github.io/posts/333222.html","excerpt":"","text":"MyBatis缓存一级缓存1） 在一个sqlSession中，对User表根据id进行两次查询，查看他们发出sql语句的情况 public class CacheTest { private IUserMapper userMapper; private SqlSession sqlSession; @BeforeEach public void before() throws IOException { InputStream resourceAsStream = Resources.getResourceAsStream(\"sqlMapperConfig.xml\"); SqlSessionFactory sqlSessionFactory = new SqlSessionFactoryBuilder().build(resourceAsStream); sqlSession = sqlSessionFactory.openSession(); userMapper = sqlSession.getMapper(IUserMapper.class); } @Test public void firstLevelCache(){ User user1 = userMapper.findById(1); User user2 = userMapper.findById(1); System.out.println(user1 == user2); sqlSession.close(); } } 查看控制台输出情况 ==&gt; Preparing: select * from user where id=? ==&gt; Parameters: 1(Integer) &lt;== Columns: id, username, password, birthday &lt;== Row: 1, liutao, null, null &lt;== Total: 1 true 就是在第一次查询时，发出了上面的sql语句，然后在第二次查询时没有发出查询的sql语句。 2） 同样是对user表进行两次查询，只不过两次查询之间进行了一次update操作 @Test public void firstLevelCache(){ User user1 = userMapper.findById(1); // update User user = new User(); user.setId(1); user.setUsername(\"liutao\"); user.setPassword(user1.getPassword()); user.setBirthday(user1.getBirthday()); userMapper.updateUser(user); sqlSession.commit(); User user2 = userMapper.findById(1); System.out.println(user1 == user2); } 查看控制台输出情况 ==&gt; Preparing: select * from user where id=? ==&gt; Parameters: 1(Integer) &lt;== Columns: id, username, password, birthday &lt;== Row: 1, sss, 123, 2019-12-12 &lt;== Total: 1 ==&gt; Preparing: update user set username=?,password=?,birthday=? where id=? ==&gt; Parameters: liutao(String), 123(String), 2019-12-12(String), 1(Integer) &lt;== Updates: 1 Committing JDBC Connection [com.mysql.jdbc.JDBC4Connection@47f9738] ==&gt; Preparing: select * from user where id=? ==&gt; Parameters: 1(Integer) &lt;== Columns: id, username, password, birthday &lt;== Row: 1, liutao, 123, 2019-12-12 &lt;== Total: 1 false 总结 第一次发起查询用户id为1的用户信息，先去找缓存中是否有id为1的用户信息，如果没有，从 数据库查询用户信息。得到用户信息，将用户信息存储到一级缓存中。 如果中间sqlSession去执行commit操作（执行插入、更新、删除）或者手动关闭缓存，则会清空SqlSession中的一级缓存，这样做的目的为了让缓存中存储的是最新的信息，避免脏读。 第二次发起查询用户id为1的用户信息，先去找缓存中是否有id为1的用户信息，缓存中有，直 接从缓存中获取用户信息。 一级缓存原理探究和源码分析一级缓存到底是什么？一级缓存什么时候被创建、一级缓存的工作流程是怎样的？相信你现在应该会有这几个疑问，那么我们本节就来研究一下一级缓存的本质。 大家可以这样想，上面我们一直提到一级缓存，那么提到一级缓存就绕不开SqlSession,所以索性我们就直接从SqlSession，看看有没有创建缓存或者与缓存有关的属性或者方法。 调研了一圈，发现上述所有方法中，好像只有clearCache()和缓存沾点关系，那么就直接从这个方 法入手吧，分析源码时，我们要看它(此类)是谁，它的父类和子类分别又是谁，对如上关系了解了，你才 会对这个类有更深的认识，分析了一圈，你可能会得到如下这个流程图。 再深入分析，流程走到Perpetualcache中的clear()方法之后，会调用其cache.clear()方法，那 么这个cache是什么东西呢？点进去发现，cache其实就是private Map cache = new HashMap()；也就是一个Map，所以说cache.clear()其实就是map.clear()，也就是说缓存其实就是本地存放的一个map对象，每一个SqISession都会存放一个map对象的引用，那么这个cache是何 时创建的呢？ 你觉得最有可能创建缓存的地方是哪里呢？我觉得是Executor，为什么这么认为？因为Executor是 执行器，用来执行SQL请求，而且清除缓存的方法也在Executor中执行，所以很可能缓存的创建也很 有可能在Executor中，看了一圈发现Executor中有一个createCacheKey方法，这个方法很像是创 建缓存的方法啊，跟进去看看，你发现createCacheKey方法是由BaseExecutor执行的，代码如下 public CacheKey createCacheKey(MappedStatement ms, Object parameterObject, RowBounds rowBounds, BoundSql boundSql) { CacheKey cacheKey = new CacheKey(); //MappedStatement 的 id // id就是Sql语句的所在位置包名+类名+ SQL名称 cacheKey.update(ms.getId()); // offset 就是 0 cacheKey.update(rowBounds.getOffset()); // limit 就是 Integer.MAXVALUE cacheKey.update(rowBounds.getLimit()); //具体的SQL语句 cacheKey.update(boundSql.getSql()); //后面是update 了 sql中带的参数 cacheKey.update(value); cacheKey.update(this.configuration.getEnvironment().getId()); } 创建缓存key会经过一系列的update方法，udate方法由一个CacheKey这个对象来执行的，这个update方法最终由updateList的list来把五个值存进去. 那么我们回归正题，那么创建完缓存之后该用在何处呢？总不会凭空创建一个缓存不使用吧？绝对不会的，经过我们对一级缓存的探究之后，我们发现一级缓存更多是用于查询操作，毕竟一级缓存也叫做查询缓存吧，为什么叫查询缓存我们一会儿说。我们先来看一下这个缓存到底用在哪了，我们跟踪到query方法如下： @Override public &lt;E&gt; List&lt;E&gt; query(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler) throws SQLException { BoundSql boundSql = ms.getBoundSql(parameter); //创建缓存 CacheKey key = createCacheKey(ms, parameter, rowBounds, boundSql); return query(ms, parameter, rowBounds, resultHandler, key, boundSql); } @SuppressWarnings(\"unchecked\") @Override public &lt;E&gt; List&lt;E&gt; query(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, CacheKey key, BoundSql boundSql) throws SQLException { ... list = resultHandler == null ? (List&lt;E&gt;) localCache.getObject(key) : null; if (list != null) { //这个主要是处理存储过程用的。 handleLocallyCachedOutputParameters(ms, key, parameter, boundSql); } else { list = queryFromDatabase(ms, parameter, rowBounds, resultHandler, key, boundSql); } ... } // queryFromDatabase 方法 private &lt;E&gt; List&lt;E&gt; queryFromDatabase(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, CacheKey key, BoundSql boundSql) throws SQLException { List&lt;E&gt; list; localCache.putObject(key, EXECUTION_PLACEHOLDER); try {list = doQuery(ms, parameter, rowBounds, resultHandler, boundSql); } finally { localCache.removeObject(key); } localCache.putObject(key, list); if (ms.getStatementType() == StatementType.CALLABLE) { localOutputParameterCache.putObject(key, parameter); } return list; } 如果查不到的话，就从数据库查，在queryFromDatabase中，会对localcache进行写入。 localcache对象的put方法最终交给Map进行存放。 private Map&lt;Object, Object&gt; cache = new HashMap&lt;Object, Object&gt;(); @Override public void putObject(Object key, Object value) { cache.put(key, value); } 二级缓存二级缓存的原理和一级缓存原理一样，第一次查询，会将数据放入缓存中，然后第二次查询则会直接去缓存中取。但是一级缓存是基于sqlSession的，而二级缓存是基于mapper文件的namespace的，也就是说多个sqlSession可以共享一个mapper中的二级缓存区域，并且如果两个mapper的namespace 相同，即使是两个mapper,那么这两个mapper中执行sql查询到的数据也将存在相同的二级缓存区域 中。 ​ 如何使用二级缓存 和一级缓存默认开启不一样，二级缓存需要我们手动开启首先在全局配置文件sqlMapConfig.xml文件中加入如下代码: &lt;!--开启二级缓存--&gt; &lt;settings&gt; &lt;setting name=\"cacheEnabled\" value=\"true\"/&gt; &lt;/settings&gt; 其次在UserMapper.xml文件中开启缓存 &lt;!--开启二级缓存--&gt; &lt;cache&gt;&lt;/cache&gt; 或者在UserMapper接口中添加注解 @CacheNamespace(implementation = PerpetualCache.class) 我们可以看到mapper.xml文件中就这么一个空标签，其实这里可以配置,PerpetualCache这个类是mybatis默认实现缓存功能的类。我们不写type就使用mybatis默认的缓存，也可以去实现Cache接口来自定义缓存。","categories":[{"name":"SSM篇","slug":"SSM篇","permalink":"https://bowonqin.github.io/categories/SSM%E7%AF%87/"}],"tags":[{"name":"Mybatis","slug":"Mybatis","permalink":"https://bowonqin.github.io/tags/Mybatis/"}],"author":"qxd"},{"title":"牛客高频面试题","slug":"常见面试题总结/牛客100","date":"2021-12-16T16:00:00.000Z","updated":"2021-12-20T05:26:16.303Z","comments":true,"path":"posts/niuke100.html","link":"","permalink":"https://bowonqin.github.io/posts/niuke100.html","excerpt":"","text":"字符串搜索-BF和RK 给定两个字符串A、B，判断B在A中是否存在，存在返回A中的下标，不存在返回-1 例如： A：ABCABCABCCCAAA ​ B: BCCCA 返回值 6 java中的String.indexOf()方法可以实现 BF暴力算法逐字符地进行匹配（比较A[i]和B[j]）,如果当前字符匹配成功（A[i] == B[j]），就匹配下一个字符（++i,++j），如果失配，i回溯，j置为0（i = i-j+1,j=0） 时间复杂度为O(n*m)，与主串和模式串的长度正相关 // pat匹配串 // txt原串 int search(String pat, String txt) { if (pat == null || txt == null) { return -1; } int M = pat.length(); int N = txt.length(); for (int i = 0; i &lt; N - M; i++) { int j; for (j = 0; j &lt; M; j++) { if (pat.charAt(j) != txt.charAt(i + j)) { break; } } // pat全部匹配了 if (j == M) return i; } return -1; } RK算法：hash算法基于BF进行优化，将A字符按顺序和B串的长度进行截取。两者hash值比对。时间复杂度为O(m*n),hash算法参与的字符位数（模式串的长度）、及主串长度正相关 优化：hash算法：按26位进制取和，abc=1+2+3=6 则每一个字符串的hash值是前一个子串的hash值减去子串最小下标值、加上本串的最大下标值 bcd=abc-a+d=6-1+4=9 时间复杂度变为：O（N）,只与主串长度相关，但是hash冲突极端情况下会退化为BF","categories":[{"name":"面试篇","slug":"面试篇","permalink":"https://bowonqin.github.io/categories/%E9%9D%A2%E8%AF%95%E7%AF%87/"}],"tags":[{"name":"牛客","slug":"牛客","permalink":"https://bowonqin.github.io/tags/%E7%89%9B%E5%AE%A2/"},{"name":"面试","slug":"面试","permalink":"https://bowonqin.github.io/tags/%E9%9D%A2%E8%AF%95/"}],"author":"qxd"},{"title":"java基础(面经)","slug":"常见面试题总结/java基础-面经","date":"2021-12-16T16:00:00.000Z","updated":"2021-12-20T14:45:18.467Z","comments":true,"path":"posts/javabase.html","link":"","permalink":"https://bowonqin.github.io/posts/javabase.html","excerpt":"","text":"Java基础部分 一个”.java”源文件中是否可以包括多个类（不是内部类）？有什么限制？ 可以有多个类，但只能有一个public的类，并且public的类名必须与文件名相一致。 Java有没有goto? java中的保留字，现在没有在java中使用。 说说&amp;和&amp;&amp;的区别。 ① &amp;和&amp;&amp;都可以用作逻辑与的运算符，表示逻辑与（and），当运算符两边的表达式的结true时，整个运算结果才为true，否则，只要有一方为false，则结果为false。 ② &amp;&amp;还具有短路的功能，即如果第一个表达式为false，则不再计算第二个表达式。例如，对于if(str != null &amp;&amp; !str.equals(“”))表达式，当str为null时，后面的表达式不会执行，所以不会出现NullPointerException如果将&amp;&amp;改为&amp;，则会抛出NullPointerException异常。If(x==33 &amp; ++y&gt;0) y会增长，If(x==33 &amp;&amp; ++y&gt;0)不会增长。 ③ &amp;还可以用作位运算符，当&amp;操作符两边的表达式不是boolean类型时，&amp;表示按位与操作，我们通常使用0x0f来与一个整数进行&amp;运算，来获取该整数的最低4个bit位，例如，0x31 &amp; 0x0f的结果为0x01。 switch语句能否作用在byte上，能否作用在long上，能否作用在String上? 在switch（expr1）中，expr1只能是一个整数表达式或者枚举常量（更大字体），整数表达式可以是int基本类型或Integer包装类型，由于，byte,short,char都可以隐含转换为int，所以，这些类型以及这些类型的包装类型也是可以的。显然，long和String类型都不符合switch的语法规定，并且不能被隐式转换成int类型，所以，它们不能作用于swtich语句中。 注： 自java 1.7以后, java switch开始支持String类型。String可以通过hashcode和equals共同判断。 switch 对应的 JVM 字节码 lookupswitch、tableswitch 指令只支持 int 类型。因此long类似不能作用于swtich上。 short s1 = 1; s1 = s1 + 1;有什么错? short s1 = 1; s1 += 1;有什么错? 对于short s1 = 1; s1 = s1 + 1; 由于s1+1运算时会自动提升表达式的类型，所以结果是int型，再赋值给short类型s1时，编译器将报告需要强制转换类型的错误。 对于short s1 = 1; s1 += 1;由于 += 是java语言规定的运算符，java编译器会对它进行特殊处理，因此可以正确编译。 char型变量中能不能存贮一个中文汉字?为什么？ char型变量是用来存储Unicode编码的字符的，unicode编码字符集中包含了汉字，所以，char型变量中当然可以存储汉字啦。不过，如果某个特殊的汉字没有被包含在unicode编码字符集中，那么，这个char型变量中就不能存储这个特殊汉字。补充说明：unicode编码占用两个字节，所以，char类型的变量也是占用两个字节。 备注：后面一部分回答虽然不是在正面回答题目，但是，为了展现自己的学识和表现自己对问题理解的透彻深入，可以回答一些相关的知识，做到知无不言，言无不尽。 java基本数据类型相关 用最有效率的方法算出2乘以8等于几? 2 &lt;&lt; 3 因为将一个数左移n位，就相当于乘以了2的n次方，那么，一个数乘以8只要将其左移3位即可，而位运算cpu直接支持的，效率最高，所以，2乘以8等於几的最效率的方法是2 &lt;&lt; 3。 左移运算符： 左移运算符用“&lt;&lt;”表示，是将运算符左边的对象，向左移动运算符右边指定的位数，并且在低位补零。其实，向左移n 位，就相当于乘上2 的n 次方： 2&lt;&lt;3 = 2*2^3=16 3&lt;&lt;3 = 3*2^3=24 4&lt;&lt;2 = 4*2^2=16 无符号右移运算符：右移运算符无符号用“&gt;&gt;&gt;”表示，是将运算符左边的对象向右移动运算符右边指定的位数，并且在高位补0，其实右移n 位，就相当于除上2 的n 次方： 16&gt;&gt;&gt;3 = 16/(2^3) =2 16&gt;&gt;&gt;5 = 16/(2^5) = 0 带符号右移运算符用“&gt;&gt;”表示，是将运算符左边的运算对象，向右移动运算符右边指定的位数。如果是正数，在高位补零，如果是负数，则在高位补1。 16&gt;&gt;3 = 16/(2^3) = 2 -16&gt;&gt;3= -16/(2^3) = -2 使用final关键字修饰一个变量时，是引用不能变，还是引用的对象不能变？ 使用final关键字修饰一个变量时，是指引用变量不能变，引用变量所指向的对象中的内容还是可以改变的。例如，对于如下语句： final StringBuffer a=new StringBuffer(\"immutable\"); 执行如下语句将报告编译期错误： a=new StringBuffer(\"\"); 但是，执行如下语句则可以通过编译： a.append(\" broken!\"); 有人在定义方法的参数时，可能想采用如下形式来阻止方法内部修改传进来的参数对象： public void method(final StringBuffer param){ } 实际上，这是办不到的，在该方法内部仍然可以增加如下代码来修改参数对象： param.append(\"a\");","categories":[{"name":"面试篇","slug":"面试篇","permalink":"https://bowonqin.github.io/categories/%E9%9D%A2%E8%AF%95%E7%AF%87/"}],"tags":[{"name":"面试","slug":"面试","permalink":"https://bowonqin.github.io/tags/%E9%9D%A2%E8%AF%95/"},{"name":"java基础","slug":"java基础","permalink":"https://bowonqin.github.io/tags/java%E5%9F%BA%E7%A1%80/"}],"author":"qxd"},{"title":"Mybatis(基础)","slug":"mybatis/Mybatis(基础)","date":"2021-12-16T16:00:00.000Z","updated":"2021-12-20T05:19:10.173Z","comments":true,"path":"posts/1111222.html","link":"","permalink":"https://bowonqin.github.io/posts/1111222.html","excerpt":"","text":"Mybatis相关概念ORM(对象关系数据库映射) ORM全称Object/Relation Mapping：表示对象-关系映射的缩写 ORM完成面向对象的编程语言到关系数据库的映射。当ORM框架完成映射后，程序员既可以利用面向对象程序设计语言的简单易用性，又可以利用关系数据库的技术优势。ORM把关系数据库包装成面向对象的模型。ORM框架是面向对象设计语言与关系数据库发展不同步时的中间解决方案。采用ORM框架后，应用程序不再直接访问底层数据库，而是以面向对象的放松来操作持久化对象，而ORM框架则将这些面向对象的操作转换成底层SQL操作。ORM框架实现的效果：把对持久化对象的保存、修改、删除等操作，转换为对数据库的操作 Mybatis简介 MyBatis是一款优秀的基于ORM的半自动轻量级持久层框架，它支持定制化SQL、存储过程以及高级映射。MyBatis避免了几乎所有的JDBC代码和手动设置参数以及获取结果集。MyBatis可以使用简单的XML或注解来配置和映射原生类型、接口和Java的POJO （Plain Old Java Objects,普通老式Java对 象）为数据库中的记录。 Mybatis历史 原是apache的一个开源项目iBatis, 2010年6月这个项目由apache software foundation 迁移到了google code，随着开发团队转投Google Code旗下，ibatis3.x正式更名为Mybatis ，代码于2013年11月迁移到Github。 iBATIS一词来源于“internet”和“abatis”的组合，是一个基于Java的持久层框架。iBATIS提供的持久层框架包括SQL Maps和Data Access Objects(DAO) Mybatis优势 Mybatis是一个半自动化的持久层框架，对开发人员开说，核心sql还是需要自己进行优化，sql和java编码进行分离，功能边界清晰，一个专注业务，一个专注数据。 Mybatis基本应用 Mybatis官网地址：http://www.mybatis.org/mybatis-3/ 快速入门开发步骤： 添加Mybatis坐标 创建user数据表 编写User实体类 编写映射文件UserMapper.xml 编写核心文件SqlMapperConfig.xml 编写测试类 环境搭建1）导入MyBatis的坐标和其他相关坐标 &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;maven.compiler.encoding&gt;UTF-8&lt;/maven.compiler.encoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;!--mybatis坐标--&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis&lt;/artifactId&gt; &lt;version&gt;3.4.5&lt;/version&gt; &lt;/dependency&gt; &lt;!--mysql驱动坐标--&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.6&lt;/version&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; &lt;!--单元测试坐标--&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.12&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!--日志坐标--&gt; &lt;dependency&gt; &lt;groupId&gt;log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j&lt;/artifactId&gt; &lt;version&gt;1.2.12&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.junit.jupiter&lt;/groupId&gt; &lt;artifactId&gt;junit-jupiter&lt;/artifactId&gt; &lt;version&gt;RELEASE&lt;/version&gt; &lt;scope&gt;compile&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 2） 创建数据库表 3）编写User实体 public class User { private Integer id; private String username; public Integer getId() { return id; } public void setId(Integer id) { this.id = id; } public String getUsername() { return username; } public void setUsername(String username) { this.username = username; } @Override public String toString() { return \"User{\" + \"id=\" + id + \", username='\" + username + '\\'' + '}'; } } 4） 编写UserMapper映射文件 &lt;?xml version=\"1.0\" encoding=\"UTF-8\" ?&gt; &lt;!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\"&gt; &lt;mapper namespace=\"user\"&gt; &lt;!-- namespace命名空间，与id组成sql的唯一标识 resultType: 返回值类型 --&gt; &lt;select id=\"findAll\" resultType=\"com.qxd.pojo.User\"&gt; select * from user &lt;/select&gt; &lt;/mapper&gt; 5） 编写Mybatis核心配置文件 &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;!DOCTYPE configuration PUBLIC \"-//mybatis.org//DTD Config 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-config.dtd\"&gt; &lt;configuration&gt; &lt;!--默认运行环境--&gt; &lt;environments default=\"development\"&gt; &lt;environment id=\"development\"&gt; &lt;!--当前事务交由jdbc管理--&gt; &lt;transactionManager type=\"JDBC\"/&gt; &lt;!--当前使用mybatis提供的连接池--&gt; &lt;dataSource type=\"POOLED\"&gt; &lt;property name=\"driver\" value=\"com.mysql.jdbc.Driver\"/&gt; &lt;property name=\"url\" value=\"jdbc:mysql:///zdy_mybatis\"/&gt; &lt;property name=\"username\" value=\"root\"/&gt; &lt;property name=\"password\" value=\"123456\"/&gt; &lt;/dataSource&gt; &lt;/environment&gt; &lt;/environments&gt; &lt;mappers&gt; &lt;mapper resource=\"UserMapper.xml\"/&gt; &lt;/mappers&gt; &lt;/configuration&gt; 6） 编写测试类 public class MybatisTest { @Test public void test1() throws IOException { // 加载核心配置文件 InputStream resourceAsStream = Resources.getResourceAsStream(\"sqlMapperConfig.xml\"); //获得sqlSession工厂对象 SqlSessionFactory sqlSessionFactory = new SqlSessionFactoryBuilder().build(resourceAsStream); //获得sqlSession对象 SqlSession sqlSession = sqlSessionFactory.openSession(); //执行sql语句 List&lt;User&gt; users = sqlSession.selectList(\"user.findAll\"); // 打印结果 for (User : users) { System.out.println(user); } // 释放资源 sqlSession.close(); } } 打印结果为： User{id=1, username='qqq'} User{id=2, username='zhangsan'} User{id=4, username='null'} Mybatis的增删改查操作Mybatis的插入数据操作1） 编写UserMapper映射文件 &lt;!-- 插入--&gt; &lt;mapper&gt; &lt;insert id=\"saveUser\" parameterType=\"com.qxd.pojo.User\"&gt; insert into user values (#{id},#{username}) &lt;/insert&gt; &lt;/mapper&gt; 2） 编写测试类 @Test public void test2() throws IOException { InputStream resourceAsStream = Resources.getResourceAsStream(\"sqlMapperConfig.xml\"); SqlSessionFactory sqlSessionFactory = new SqlSessionFactoryBuilder().build(resourceAsStream); SqlSession sqlSession = sqlSessionFactory.openSession(); User user = new User(); user.setId(3); user.setUsername(\"sd\"); sqlSession.insert(\"user.saveUser\",user); sqlSession.commit(); sqlSession.close(); } 3） 插入操作注意问题 插入语句使用insert标签 在映射文件中使用parameterType属性指定要插入的数据类型 Sql语句中使用#{实体属性名}方式引用实体中的属性值 插入操作使用的API是sqlSession.insert(“命名空间.id”,实体对象); 插入操作涉及数据库数据变化，所以要使用sqlSession对象显示的提交事务，即sqlSession.commit() Mybatis的修改数据操作1） 编写UserMapper映射文件 &lt;!-- 修改--&gt; &lt;mapper&gt; &lt;update id=\"update\" parameterType=\"com.qxd.pojo.User\"&gt; update user set username=#{username} where id = #{id} &lt;/update&gt; &lt;/mapper&gt; 2） 编写测试类 @Test public void test3() throws IOException { InputStream resourceAsStream = Resources.getResourceAsStream(\"sqlMapperConfig.xml\"); SqlSessionFactory sqlSessionFactory = new SqlSessionFactoryBuilder().build(resourceAsStream); SqlSession sqlSession = sqlSessionFactory.openSession(); User user = new User(); user.setId(1); user.setUsername(\"xxx\"); int update = sqlSession.update(\"user.update\", user); System.out.println(update); sqlSession.commit(); sqlSession.close(); } 3） 修改操作注意问题 修改语句使用update标签 修改操作使用的API是sqlSession.update(“命名空间.id”,实体对象); Mybatis的删除数据操作1） 编写UserMapper映射文件 &lt;mapper&gt; &lt;!-- 删除--&gt; &lt;delete id=\"delete\" parameterType=\"java.lang.Integer\"&gt; delete from user where id = #{id} &lt;/delete&gt; &lt;/mapper&gt; 2） 编写测试类 // 删除 public void test4() throws IOException { InputStream resourceAsStream = Resources.getResourceAsStream(\"sqlMapperConfig.xml\"); SqlSessionFactory sqlSessionFactory = new SqlSessionFactoryBuilder().build(resourceAsStream); SqlSession sqlSession = sqlSessionFactory.openSession(); int delete = sqlSession.delete(\"user.delete\", 5); System.out.println(delete); sqlSession.commit(); sqlSession.close(); } 3） 删除操作注意问题 删除语句使用delete标签 Sql语句中使用#{任意字符串}方式引用传递的单个参数 删除操作使用的API是sqlSession.delete(“命名空间.id”,Object); Mybatis的映射文件概述 &lt;?xml version=\"1.0\" encoding=\"UTF-8\" ?&gt; &lt;!--映射文件DTD约束头--&gt; &lt;!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\"&gt; &lt;!--mapper为根标签--&gt; &lt;mapper namespace=\"user\"&gt; &lt;!-- namespace命名空间，与id组成sql的唯一标识 resultType: 返回值类型 --&gt; &lt;select id=\"findAll\" resultType=\"com.qxd.pojo.User\"&gt; select * from user &lt;/select&gt; &lt;/mapper&gt; Mybatis常用映射文件解析1） environments标签 &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;!DOCTYPE configuration PUBLIC \"-//mybatis.org//DTD Config 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-config.dtd\"&gt; &lt;configuration&gt; &lt;!--默认运行环境--&gt; &lt;environments default=\"development\"&gt; &lt;!--当前运行环境--&gt; &lt;environment id=\"development\"&gt; &lt;!--当前事务交由jdbc管理--&gt; &lt;transactionManager type=\"JDBC\"/&gt; &lt;!--当前使用mybatis提供的连接池--&gt; &lt;dataSource type=\"POOLED\"&gt; &lt;!--数据源配置的基本餐宿--&gt; &lt;property name=\"driver\" value=\"com.mysql.jdbc.Driver\"/&gt; &lt;property name=\"url\" value=\"jdbc:mysql:///zdy_mybatis\"/&gt; &lt;property name=\"username\" value=\"root\"/&gt; &lt;property name=\"password\" value=\"123456\"/&gt; &lt;/dataSource&gt; &lt;/environment&gt; &lt;/environments&gt; &lt;/configuration&gt; 其中，事务管理器（transactionManager）类型有两种： JDBC：这个配置就是直接使用了JDBC 的提交和回滚设置，它依赖于从数据源得到的连接来管理事务作用域。 MANAGED：这个配置几乎没做什么。它从来不提交或回滚一个连接，而是让容器来管理事务的整个生命周期（比如 JEE 应用服务器的上下文）。 默认情况下它会关闭连接，然而一些容器并不希望这样，因此需要将 closeConnection 属性设置为 false 来阻止它默认的关闭行为。 其中，数据源（dataSource）类型有三种： UNPOOLED：这个数据源的实现只是每次被请求时打开和关闭连接。 POOLED：这种数据源的实现利用“池”的概念将 JDBC 连接对象组织起来。 JNDI：这个数据源的实现是为了能在如 EJB 或应用服务器这类容器中使用，容器可以集中或在外部配置数据源，然后放置一个 JNDI 上下文的引用。 2） mapper标签 该标签的作用是加载映射的，加载方式有如下几种： &lt;!--使用相对于类路径的资源引用，例如：--&gt; &lt;mapper resource=\"org/mybatis/builder/AuthorMapper.xml\"/&gt; &lt;!--使用完全限定资源定位符（URL），例如： --&gt; &lt;mapper url=\"file:///var/mappers/AuthorMapper.xml\"/&gt; &lt;!--使用映射器接口实现类的完全限定类名，例如： --&gt; &lt;mapper class=\"org.mybatis.builder.AuthorMapper\"/&gt; &lt;!--将包内的映射器接口实现全部注册为映射器，例如：--&gt; &lt;mapper name=\"org.mybatis.builder\"/&gt; Mybatis相应API SqlSession工厂构建器SqlSessionFactoryBuilder 常用API：SqlSessionFactory build(InputStream inputStream) 通过加载mybatis的核心文件的输入流的形式构建一个SqlSessionFactory对象 InputStream resourceAsStream = Resources.getResourceAsStream(\"sqlMapperConfig.xml\"); SqlSessionFactory sqlSessionFactory = new SqlSessionFactoryBuilder().build(resourceAsStream); 其中， Resources 工具类，这个类在 org.apache.ibatis.io 包中。Resources 类帮助你从类路径下、文件系统或一个 web URL 中加载资源文件。 SqlSession工厂对象SqlSessionFactory SqlSessionFactory 有多个个方法创建SqlSession 实例。常用的有如下两个： // 默认为false,需要手动开启事务 SqlSession sqlSession = sqlSessionFactory.openSession(); // 手动提交事务 sqlSession.commit() // -----------------------------------------------------------------------------// // 自动开启事务，无需手动提交事务 SqlSession sqlSession = sqlSessionFactory.openSession(true); SqlSession会话对象 SqlSession 实例在 MyBatis 中是非常强大的一个类。在这里你会看到所有执行语句、提交或回滚事务和获取映射器实例的方法。 执行语句的方法主要有 &lt;T&gt; T selectOne(String statement, Object parameter); &lt;E&gt; List&lt;E&gt; selectList(String statement, Object parameter); int insert(String statement, Object parameter); int update(String statement, Object parameter); int delete(String statement, Object parameter); 操作事务的方法主要有： void commit() void rollback() Mybatis的Dao层实现传统开发方式 编写UserDao接口 public interface IUserDao { // 查询所有用户 public List&lt;User&gt; findAll() throws IOException; } 编写UserDaoImpl实现 public class UserDaoImpl implements IUserDao { @Override public List&lt;User&gt; findAll() throws IOException { InputStream resourceAsStream = Resources.getResourceAsStream(\"sqlMapperConfig.xml\"); SqlSessionFactory sqlSessionFactory = new SqlSessionFactoryBuilder().build(resourceAsStream); SqlSession sqlSession = sqlSessionFactory.openSession(); List&lt;User&gt; users = sqlSession.selectList(\"user.findAll\"); sqlSession.close(); return users; } } 测试传统方式 @Test public void test5() throws IOException { IUserDao userDao = new UserDaoImpl(); List&lt;User&gt; all = userDao.findAll(); for (User user : all) { System.out.println(user); } } 代理开发方式 采用 Mybatis 的代理开发方式实现 DAO 层的开发，这种方式是我们后面进入企业的主流。 Mapper 接口开发方法只需要程序员编写Mapper 接口（相当于Dao 接口），由Mybatis 框架根据接口定义创建接口的动态代理对象，代理对象的方法体同上边Dao接口实现类方法。 Mapper 接口开发需要遵循以下规范：、 1） Mapper.xml中的namespace与mapper接口的全限类名相同。 2） Mapper接口方法名和Mapper.xm中定义的每个statemen的id相同 3） Mapper接口方法的输入参数类型和mapper.xml中定义的每个sql的parameterType的类型相同 4） Mapper接口方法的输出参数类型和mapper.xml中定义的每个sql的resultType的类型相同 测试代理方法 @Test public void test6() throws IOException { InputStream resourceAsStream = Resources.getResourceAsStream(\"sqlMapperConfig.xml\"); SqlSessionFactory sqlSessionFactory = new SqlSessionFactoryBuilder().build(resourceAsStream); SqlSession sqlSession = sqlSessionFactory.openSession(); IUserDao userDao = sqlSession.getMapper(IUserDao.class); List&lt;User&gt; all = userDao.findAll(); for (User user : all) { System.out.println(user); } sqlSession.close(); } Mybatis配置文件深入核心配置文件environments标签&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;!DOCTYPE configuration PUBLIC \"-//mybatis.org//DTD Config 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-config.dtd\"&gt; &lt;configuration&gt; &lt;!--默认运行环境--&gt; &lt;environments default=\"development\"&gt; &lt;!--当前运行环境--&gt; &lt;environment id=\"development\"&gt; &lt;!--当前事务交由jdbc管理--&gt; &lt;transactionManager type=\"JDBC\"/&gt; &lt;!--当前使用mybatis提供的连接池--&gt; &lt;dataSource type=\"POOLED\"&gt; &lt;!--数据源配置的基本餐宿--&gt; &lt;property name=\"driver\" value=\"com.mysql.jdbc.Driver\"/&gt; &lt;property name=\"url\" value=\"jdbc:mysql:///zdy_mybatis\"/&gt; &lt;property name=\"username\" value=\"root\"/&gt; &lt;property name=\"password\" value=\"123456\"/&gt; &lt;/dataSource&gt; &lt;/environment&gt; &lt;/environments&gt; &lt;/configuration&gt; 其中，事务管理器（transactionManager）类型有两种： JDBC：这个配置就是直接使用了JDBC 的提交和回滚设置，它依赖于从数据源得到的连接来管理事务作用域。 MANAGED：这个配置几乎没做什么。它从来不提交或回滚一个连接，而是让容器来管理事务的整个生命周期（比如 JEE 应用服务器的上下文）。 默认情况下它会关闭连接，然而一些容器并不希望这样，因此需要将 closeConnection 属性设置为 false 来阻止它默认的关闭行为。 其中，数据源（dataSource）类型有三种： UNPOOLED：这个数据源的实现只是每次被请求时打开和关闭连接。 POOLED：这种数据源的实现利用“池”的概念将 JDBC 连接对象组织起来。 JNDI：这个数据源的实现是为了能在如 EJB 或应用服务器这类容器中使用，容器可以集中或在外部配置数据源，然后放置一个 JNDI 上下文的引用。 mapper标签该标签的作用是加载映射的，加载方式有如下几种： &lt;!--使用相对于类路径的资源引用，例如：--&gt; &lt;mapper resource=\"org/mybatis/builder/AuthorMapper.xml\"/&gt; &lt;!--使用完全限定资源定位符（URL），例如： --&gt; &lt;mapper url=\"file:///var/mappers/AuthorMapper.xml\"/&gt; &lt;!--使用映射器接口实现类的完全限定类名，例如： --&gt; &lt;mapper class=\"org.mybatis.builder.AuthorMapper\"/&gt; &lt;!--将包内的映射器接口实现全部注册为映射器，例如：--&gt; &lt;mapper name=\"org.mybatis.builder\"/&gt; Properties标签实际开发中，习惯将数据源的配置信息单独抽取成一个properties文件，该标签可以加载额外配置的properties文件 &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;!DOCTYPE configuration PUBLIC \"-//mybatis.org//DTD Config 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-config.dtd\"&gt; &lt;configuration&gt; &lt;!-- 加载外部properties --&gt; &lt;properties resource=\"jdbc.properties\"&gt;&lt;/properties&gt; &lt;!--默认运行环境--&gt; &lt;environments default=\"development\"&gt; &lt;environment id=\"development\"&gt; &lt;!--当前事务交由jdbc管理--&gt; &lt;transactionManager type=\"JDBC\"/&gt; &lt;!--当前使用mybatis提供的连接池--&gt; &lt;dataSource type=\"POOLED\"&gt; &lt;property name=\"driver\" value=\"${jdbc.driver}\"/&gt; &lt;property name=\"url\" value=\"${jdbc.url}\"/&gt; &lt;property name=\"username\" value=\"${jdbc.username}\"/&gt; &lt;property name=\"password\" value=\"${jdbc.password}\"/&gt; &lt;/dataSource&gt; &lt;/environment&gt; &lt;/environments&gt; &lt;mappers&gt; &lt;mapper resource=\"UserMapper.xml\"/&gt; &lt;/mappers&gt; &lt;/configuration&gt; typeAliases标签类型别名是为Java 类型设置一个短的名字。原来的类型名称配置如下 &lt;!-- 插入--&gt; &lt;mapper&gt; &lt;insert id=\"saveUser\" parameterType=\"com.qxd.pojo.User\"&gt; insert into user values (#{id},#{username}) &lt;/insert&gt; &lt;/mapper&gt; 配置typeAliases，为com.lagou.domain.User定义别名为user &lt;typeAliases&gt; &lt;!-- 单独实体起别名 --&gt; &lt;typeAlias type=\"com.qxd.pojo.User\" alias=\"user\"&gt;&lt;/typeAlias&gt; &lt;/typeAliases&gt; &lt;!-- 插入--&gt; &lt;mapper&gt; &lt;insert id=\"saveUser\" parameterType=\"user\"&gt; insert into user values (#{id},#{username}) &lt;/insert&gt; &lt;/mapper&gt; 批量起别名:该包下所有类的本身的类名：别名不区分大小写 &lt;!-- 给实体类的全限定类名起别名 --&gt; &lt;typeAliases&gt; &lt;!-- 批量起别名：该包下所有类的本身的类名：别名不区分大小写--&gt; &lt;package name=\"com.qxd.pojo\"/&gt; &lt;/typeAliases&gt; 上面我们是自定义的别名，mybatis框架已经为我们设置好的一些常用的类型的别名 别名 数据类型 string String long Long int Integer double Double boolean Boolean …… …… 映射配置文件mapper.xml动态sql语句动态 SQL 之 我们根据实体类的不同取值，使用不同的 SQL语句来进行查询。比如在 id如果不为空时可以根据id查询，如果username 不同空时还要加入用户名作为条件。这种情况在我们的多条件组合查询中经常会碰到。 &lt;!-- 多条件组合查询--&gt; &lt;select id=\"findByCondition\" resultType=\"user\" parameterType=\"user\"&gt; select * from user &lt;where&gt; &lt;if test=\"id != null\"&gt; and id = #{id} &lt;/if&gt; &lt;if test=\"username !=null\"&gt; and username = #{username} &lt;/if&gt; &lt;/where&gt; &lt;/select&gt; 动态 SQL 之 循环执行sql的拼接操作，例如：SELECT * FROM USER WHERE id IN (1,2,5)。 &lt;select id=\"findByIds\" parameterType=\"list\" resultType=\"user\"&gt; &lt;include refid=\"selectUser\"&gt;&lt;/include&gt; &lt;where&gt; &lt;foreach collection=\"array\" open=\"id in (\" close=\")\" item=\"id\" separator=\",\"&gt; #{id} &lt;/foreach&gt; &lt;/where&gt; &lt;/select&gt; foreach标签的属性含义如下： 标签用于遍历集合，它的属性： collection: 代表要遍历的集合元素，注意编写时不要写#{}。 open：代表语句的开始部分。 close：代表结束部分。 item：代表遍历集合的每个元素，生成的变量名 sperator：代表分隔符 SQL片段抽取 Sql 中可将重复的 sql 提取出来，使用时用 include 引用即可，最终达到 sql 重用的目的 &lt;!-- 抽取mysql片段--&gt; &lt;sql id=\"selectUser\"&gt; select * from User &lt;/sql&gt; &lt;select id=\"findAll\" resultType=\"user\"&gt; &lt;include refid=\"selectUser\"&gt;&lt;/include&gt; &lt;/select&gt; Mybatis复杂映射开发一对一查询一对一查询模型用户表和订单表的关系为，一个用户有多个订单，一个订单只从属于一个用户。一对一查询的需求：查询一个订单，与此同时查询出该订单所属的用户 一对一查询语句对应的sql语句： select * from orders o,user u where o.uid=u.id; 查询的结果如下： 创建Order和User实体public class Order { private Integer id; private String ordertime; private Double total; //代表当前订单从属于哪一个客户 private User user; get() set() } public class User { private Integer id; private String username; private String password; private String birthday; get() set() } 创建IUserMapper接口public interface IUserMapper { // 查询订单的同时还查询该订单所属的用户 public List&lt;Order&gt; findOrderAndUser(); } 配置IUserMapper.xml&lt;mapper namespace=\"com.qxd.mapper.IUserMapper\"&gt; &lt;!--resultMap:手动配置实体属性和表字段的映射关系 --&gt; &lt;resultMap id=\"orderMap\" type=\"com.qxd.pojo.Order\"&gt; &lt;result property=\"id\" column=\"id\"&gt;&lt;/result&gt; &lt;result property=\"orderTime\" column=\"orderTime\"&gt;&lt;/result&gt; &lt;result property=\"total\" column=\"total\"&gt;&lt;/result&gt; &lt;association property=\"user\" javaType=\"com.qxd.pojo.User\"&gt; &lt;result property=\"id\" column=\"uid\"&gt;&lt;/result&gt; &lt;result property=\"username\" column=\"username\"&gt;&lt;/result&gt; &lt;result property=\"password\" column=\"password\"&gt;&lt;/result&gt; &lt;result property=\"birthday\" column=\"birthday\"&gt;&lt;/result&gt; &lt;/association&gt; &lt;/resultMap&gt; &lt;select id=\"findOrderAndUser\" resultMap=\"orderMap\"&gt; select * from orders o,user u where o.uid=u.id; &lt;/select&gt; &lt;/mapper&gt; 其中，sqlMapperConfig.xml导包的时候可以做如下配置 &lt;mappers&gt; &lt;!--同包同名--&gt; &lt;package name=\"com.qxd.mapper\"/&gt; &lt;/mappers&gt; 其中，使用package标签导包的时候要保证mapper.xml与mapper接口同包同名才能成功。 一对多查询模型一对多查询模型用户表和订单表的关系为，一个用户有多个订单，一个订单只从属于一个用户。一对多查询的需求：查询一个用户，与此同时查询出该用户具有的订单 一对多查询语句对应的sql语句： select *,o.id oid from user u left join orders o on u.id=o.uid; 查询的结果如下： 修改User实体public class User { private Integer id; private String username; private String password; private String birthday; // 表示用户关联的订单 private List&lt;Order&gt; orderList = new ArrayList&lt;&gt;(); } public class Order { private Integer id; private String orderTime; private Double total; //代表当前订单从属于哪一个客户 private User user; } 创建IUserMapper接口public interface IUserMapper { // 查询所有用户拥有的订单 public List&lt;User&gt; findAll(); } 配置IUserMapper.xml&lt;mapper&gt; &lt;resultMap id=\"userMap\" type=\"com.qxd.pojo.User\"&gt; &lt;result property=\"id\" column=\"id\"&gt;&lt;/result&gt; &lt;result property=\"username\" column=\"username\"&gt;&lt;/result&gt; &lt;result property=\"password\" column=\"password\"&gt;&lt;/result&gt; &lt;result property=\"birthday\" column=\"birthday\"&gt;&lt;/result&gt; &lt;!--集合类型+泛型--&gt; &lt;collection property=\"orderList\" ofType=\"com.qxd.pojo.Order\"&gt; &lt;result property=\"id\" column=\"oid\"&gt;&lt;/result&gt; &lt;result property=\"orderTime\" column=\"orderTime\"&gt;&lt;/result&gt; &lt;result property=\"total\" column=\"total\"&gt;&lt;/result&gt; &lt;/collection&gt; &lt;/resultMap&gt; &lt;select id=\"findAll\" resultMap=\"userMap\"&gt; select *,o.id oid from user u left join orders o on u.id=o.uid; &lt;/select&gt; &lt;/mapper&gt; 多对多查询多对多查询模型用户表和角色表的关系为，一个用户有多个角色，一个角色被多个用户使用 多对多查询的需求：查询用户同时查询出该用户的所有角色 多对多查询语句对应的sql语句： SELECT u.*, r.*, r.id rid FROM USER u LEFT JOIN sys_user_role ur ON u.id = ur.userid LEFT JOIN sys_role r ON ur.roleid = r.id; 查询结果如下 创建Role实体，修改User实体public class User { private Integer id; private String username; private String password; private String birthday; // 表示用户关联的订单 private List&lt;Order&gt; orderList = new ArrayList&lt;&gt;(); // 表示用户当前的角色 private List&lt;Role&gt; roleList = new ArrayList&lt;&gt;(); } public class Role { private Integer id; private String roleName; private String roleDesc; } 添加UserMapper接口方法// 查询所有用户拥有的角色 public List&lt;User&gt; findAllUserAndRole(); 配置IUserMapper.xml&lt;mapper&gt; &lt;resultMap id=\"userRoleMap\" type=\"user\"&gt; &lt;result property=\"id\" column=\"id\"&gt;&lt;/result&gt; &lt;result property=\"username\" column=\"username\"&gt;&lt;/result&gt; &lt;result property=\"password\" column=\"password\"&gt;&lt;/result&gt; &lt;result property=\"birthday\" column=\"birthday\"&gt;&lt;/result&gt; &lt;collection property=\"roleList\" ofType=\"Role\"&gt; &lt;result property=\"id\" column=\"rid\"&gt;&lt;/result&gt; &lt;result property=\"roleDesc\" column=\"roleDesc\"&gt;&lt;/result&gt; &lt;result property=\"roleName\" column=\"roleName\"&gt;&lt;/result&gt; &lt;/collection&gt; &lt;/resultMap&gt; &lt;select id=\"findAllUserAndRole\" resultMap=\"userRoleMap\"&gt; SELECT u.*, r.*, r.id rid FROM USER u LEFT JOIN sys_user_role ur ON u.id = ur.userid LEFT JOIN sys_role r ON ur.roleid = r.id; &lt;/select&gt; &lt;/mapper&gt; 知识小结一对一配置： 使用做配置 一对多配置： 使用+做配置 多对多配置： 使用+做配置 Mybatis注解开发MyBatis常用注解这几年来注解开发越来越流行，Mybatis也可以使用注解开发方式，这样我们就可以减少编写Mapper映射文件了。我们先围绕一些基本的CRUD来学习，再学习复杂映射多表操作。 @Insert：实现新增 @Update：实现更新 @Delete：实现删除 @Select：实现查询 @Result：实现结果集封装 @Results：可以与@Result 一起使用，封装多个结果集 @One：实现一对一结果集封装 @Many：实现一对多结果集封装 Mybatis增删改查我们完成简单的user表的增删改查的操作 private IUserMapper userMapper; @BeforeEach public void before() throws IOException { InputStream resourceAsStream = Resources.getResourceAsStream(\"sqlMapperConfig.xml\"); SqlSessionFactory sqlSessionFactory = new SqlSessionFactoryBuilder().build(resourceAsStream); SqlSession sqlSession = sqlSessionFactory.openSession(true); userMapper = sqlSession.getMapper(IUserMapper.class); } @Test public void addUserTest() throws IOException { User user = new User(); user.setId(6); user.setUsername(\"qqq\"); user.setBirthday(\"2021-1-1\"); user.setPassword(\"123321\"); userMapper.addUser(user); } @Test public void selectUserTest(){ List&lt;User&gt; users = userMapper.selectUsers(); for (User user : users) { System.out.println(user); } } @Test public void udpateUserTest(){ User user = new User(); user.setId(6); user.setUsername(\"xxx\"); user.setBirthday(\"2021-11-1\"); user.setPassword(\"1233221\"); userMapper.updateUser(user); } @Test public void deleteUserTest(){ userMapper.delete(6); } MyBatis的注解实现复杂映射开发实现复杂关系映射之前我们可以在映射文件中通过配置来实现，使用注解开发后，我们可以使用@Results注解，@Result注解，@One注解，@Many注解组合完成复杂关系的配置 一对一查询一对一查询的模型用户表和订单表的关系为，一个用户有多个订单，一个订单只从属于一个用户 一对一查询的需求：查询一个订单，与此同时查询出该订单所属的用户 一对一查询的语句select * from orders; select * from user where id=查询出订单的uid; 创建Order和User实体public class Order { private Integer id; private String orderTime; private Double total; //代表当前订单从属于哪一个客户 private User user; get set toString() } public class User { private Integer id; private String username; private String password; private String birthday; get set toString() } 创建OrderMapper接口public interface IOrderMapper { public List&lt;Order&gt;findAll(); } 使用注解配置Mapperpublic interface IOrderMapper { @Select(\"select * from orders\") @Results({ @Result(property = \"id\",column = \"id\"), @Result(property = \"orderTime\",column = \"ordertime\"), @Result(property = \"total\",column = \"total\"), @Result(property = \"user\",column = \"uid\",javaType = User.class,one = @One(select = \"com.qxd.mapper.IUserMapper.findById\")), }) public List&lt;Order&gt;findAll(); } public interface IUserMapper{ @Select(\"select * from user where id=#{id}\") public User findById(Integer id); } 测试结果 @Test public void testSelectOrderAndUser() { List&lt;Order&gt; all = orderMapper.findAll(); for (Order order : all) { System.out.println(order); } } // 打印结果 Order{id=1, orderTime=2019-12-12, total=3000.0, user=User{id=1, username='lucy', password='123', birthday='2019-12-12} Order{id=2, orderTime=2019-12-12, total=4000.0, user=User{id=1, username='lucy', password='123', birthday='2019-12-12} Order{id=3, orderTime=2019-12-12, total=5000.0, user=User{id=2, username='tom', password='123', birthday='2019-12-12} 一对多查询一对多查询模型用户表和订单表的关系为，一个用户有多个订单，一个订单只从属于一个用户 一对多查询的需求：查询一个用户，与此同时查询出该用户具有的订单 一对多查询的语句对应的sql语句： select * from user; select * from orders where uid=查询出用户的id; 修改Order和User实体public class Order { private Integer id; private String orderTime; private Double total; //代表当前订单从属于哪一个客户 private User user; get set toString() } public class User { private Integer id; private String username; private String password; private String birthday; // 表示用户关联的订单 private List&lt;Order&gt; orderList = new ArrayList&lt;&gt;(); get set toString() } 创建UserMapper接口public interface IUserMapper { public List&lt;User&gt; findOrderAndUserByAnnotation(); } 使用注解配置Mapperpublic interface IUserMapper { // 查询订单的同时还查询该订单所属的用户 @Select(\"select * from user\") @Results({ @Result(property = \"id\",column = \"id\"), @Result(property = \"username\",column = \"username\"), @Result(property = \"password\",column = \"password\"), @Result(property = \"birthday\",column = \"birthday\"), @Result(property = \"orderList\",column = \"id\",javaType = List.class,many = @Many(select = \"com.qxd.mapper.IOrderMapper.findByUid\")), }) public List&lt;User&gt; findOrderAndUserByAnnotation(); } public interface IOrderMapper { @Select(\"select * from orders where uid=#{uid}\") public Order findByUid(Integer uid); } 测试结果 @Test public void testSelectUserAndOrder(){ List&lt;User&gt; orderAndUserByAnnotation = userMapper.findOrderAndUserByAnnotation(); for (User user : orderAndUserByAnnotation) { System.out.println(user); } } // 打印结果 User{id=1, username='lucy', password='123', birthday='2019-12-12', orderList=[Order{id=1, orderTime='2019-12-12', total=3000.0}, Order{id=2, orderTime='2019-12-12', total=4000.0}]} User{id=2, username='tom', password='123', birthday='2019-12-12', orderList=[Order{id=3, orderTime='2019-12-12', total=5000.0}]} User{id=3, username='jack', password='123', birthday='2017-1-1', orderList=[]} User{id=5, username='qqq', password='123321', birthday='2021-1-1', orderList=[]} 多对多查询多对多查询模型用户表和角色表的关系为，一个用户有多个角色，一个角色被多个用户使用 多对多查询的需求：查询用户同时查询出该用户的所有角色 多对多查询语句select * from user; select * from role r, sys_user_role ur where r.id=ur.roleid and ur.userid=用户的id 创建Role实体，修改User实体public class User { private Integer id; private String username; private String password; private String birthday; // 表示用户关联的订单 // private List&lt;Order&gt; orderList = new ArrayList&lt;&gt;(); // 表示用户当前的角色 private List&lt;Role&gt; roleList = new ArrayList&lt;&gt;(); get set toString } public class Role { private Integer id; private String roleName; private String roleDesc; get set toString } 添加UserMapper接口方法public interface IUserMapper { public List&lt;User&gt; findOrderAndUserByAnnotation(); } 使用注解配置Mapperpublic interface IUserMapper{ @Select(\"select * from user\") @Results({ @Result(property = \"id\",column = \"id\"), @Result(property = \"username\",column = \"username\"), @Result(property = \"password\",column = \"password\"), @Result(property = \"birthday\",column = \"birthday\"), @Result(property = \"roleList\",column = \"id\",javaType = List.class,many = @Many(select = \"com.qxd.mapper.IRoleMapper.findRoleByUid\")), }) public List&lt;User&gt; findUserAndRoleByAnnotation(); } public interface IRoleMapper{ @Select(\"select * from sys_role r, sys_user_role ur where r.id=ur.roleid and ur.userid=#{uid}\") public Role findRoleByUid(Integer uid); } 测试结果 @Test public void testUserAndRole(){ List&lt;User&gt; userAndRoleByAnnotation = userMapper.findUserAndRoleByAnnotation(); for (User user : userAndRoleByAnnotation) { System.out.println(user); } } // 打印结果 User{id=1, username='lucy', password='123', birthday='2019-12-12', roleList=[Role{id=1, roleName='CTO', roleDesc='CTO'}, Role{id=2, roleName='CEO', roleDesc='CEO'}]} User{id=2, username='tom', password='123', birthday='2019-12-12', roleList=[Role{id=1, roleName='CTO', roleDesc='CTO'}, Role{id=2, roleName='CEO', roleDesc='CEO'}]} User{id=3, username='jack', password='123', birthday='2017-1-1', roleList=[]} User{id=5, username='qqq', password='123321', birthday='2021-1-1', roleList=[]}","categories":[{"name":"SSM篇","slug":"SSM篇","permalink":"https://bowonqin.github.io/categories/SSM%E7%AF%87/"}],"tags":[{"name":"Mybatis","slug":"Mybatis","permalink":"https://bowonqin.github.io/tags/Mybatis/"}],"author":"qxd"}],"categories":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://bowonqin.github.io/categories/SpringCloud/"},{"name":"消息中间件","slug":"SpringCloud/消息中间件","permalink":"https://bowonqin.github.io/categories/SpringCloud/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"多线程","slug":"多线程","permalink":"https://bowonqin.github.io/categories/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"},{"name":"java业务","slug":"java业务","permalink":"https://bowonqin.github.io/categories/java%E4%B8%9A%E5%8A%A1/"},{"name":"mongoDB","slug":"mongoDB","permalink":"https://bowonqin.github.io/categories/mongoDB/"},{"name":"Redis","slug":"Redis","permalink":"https://bowonqin.github.io/categories/Redis/"},{"name":"MySQL思考篇","slug":"java业务/MySQL思考篇","permalink":"https://bowonqin.github.io/categories/java%E4%B8%9A%E5%8A%A1/MySQL%E6%80%9D%E8%80%83%E7%AF%87/"},{"name":"java基础","slug":"java基础","permalink":"https://bowonqin.github.io/categories/java%E5%9F%BA%E7%A1%80/"},{"name":"Mysql运维篇","slug":"Mysql运维篇","permalink":"https://bowonqin.github.io/categories/Mysql%E8%BF%90%E7%BB%B4%E7%AF%87/"},{"name":"Mysql进阶篇","slug":"Mysql进阶篇","permalink":"https://bowonqin.github.io/categories/Mysql%E8%BF%9B%E9%98%B6%E7%AF%87/"},{"name":"常见问题","slug":"常见问题","permalink":"https://bowonqin.github.io/categories/%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/"},{"name":"Mysql基础篇","slug":"Mysql基础篇","permalink":"https://bowonqin.github.io/categories/Mysql%E5%9F%BA%E7%A1%80%E7%AF%87/"},{"name":"SSM篇","slug":"SSM篇","permalink":"https://bowonqin.github.io/categories/SSM%E7%AF%87/"},{"name":"面试篇","slug":"面试篇","permalink":"https://bowonqin.github.io/categories/%E9%9D%A2%E8%AF%95%E7%AF%87/"}],"tags":[{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"https://bowonqin.github.io/tags/RabbitMQ/"},{"name":"网关","slug":"网关","permalink":"https://bowonqin.github.io/tags/%E7%BD%91%E5%85%B3/"},{"name":"多线程","slug":"多线程","permalink":"https://bowonqin.github.io/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"},{"name":"java基础","slug":"java基础","permalink":"https://bowonqin.github.io/tags/java%E5%9F%BA%E7%A1%80/"},{"name":"java业务","slug":"java业务","permalink":"https://bowonqin.github.io/tags/java%E4%B8%9A%E5%8A%A1/"},{"name":"服务消息治理","slug":"服务消息治理","permalink":"https://bowonqin.github.io/tags/%E6%9C%8D%E5%8A%A1%E6%B6%88%E6%81%AF%E6%B2%BB%E7%90%86/"},{"name":"数据库","slug":"数据库","permalink":"https://bowonqin.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"NoSql","slug":"NoSql","permalink":"https://bowonqin.github.io/tags/NoSql/"},{"name":"mongoDB","slug":"mongoDB","permalink":"https://bowonqin.github.io/tags/mongoDB/"},{"name":"Redis","slug":"Redis","permalink":"https://bowonqin.github.io/tags/Redis/"},{"name":"MySQL","slug":"MySQL","permalink":"https://bowonqin.github.io/tags/MySQL/"},{"name":"jvm","slug":"jvm","permalink":"https://bowonqin.github.io/tags/jvm/"},{"name":"Mysql","slug":"Mysql","permalink":"https://bowonqin.github.io/tags/Mysql/"},{"name":"MyCat","slug":"MyCat","permalink":"https://bowonqin.github.io/tags/MyCat/"},{"name":"git","slug":"git","permalink":"https://bowonqin.github.io/tags/git/"},{"name":"常见问题","slug":"常见问题","permalink":"https://bowonqin.github.io/tags/%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/"},{"name":"docker","slug":"docker","permalink":"https://bowonqin.github.io/tags/docker/"},{"name":"idea","slug":"idea","permalink":"https://bowonqin.github.io/tags/idea/"},{"name":"java集合","slug":"java集合","permalink":"https://bowonqin.github.io/tags/java%E9%9B%86%E5%90%88/"},{"name":"jdk","slug":"jdk","permalink":"https://bowonqin.github.io/tags/jdk/"},{"name":"Mybatis","slug":"Mybatis","permalink":"https://bowonqin.github.io/tags/Mybatis/"},{"name":"牛客","slug":"牛客","permalink":"https://bowonqin.github.io/tags/%E7%89%9B%E5%AE%A2/"},{"name":"面试","slug":"面试","permalink":"https://bowonqin.github.io/tags/%E9%9D%A2%E8%AF%95/"}]}